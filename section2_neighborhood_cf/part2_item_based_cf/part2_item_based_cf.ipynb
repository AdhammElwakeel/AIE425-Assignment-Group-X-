{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c26265",
   "metadata": {},
   "source": [
    "# Part 2: Item-Based Collaborative Filtering\n",
    "\n",
    "# Adham Mohmed elwakel\n",
    "# 222100195\n",
    "\n",
    "## Case Study 1: Cosine Similarity with Mean-Centering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "108c6028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LIBRARY IMPORTS AND CONFIGURATION\n",
    "# =============================================================================\n",
    "# This section imports all required libraries for item-based collaborative\n",
    "# filtering implementation.\n",
    "\n",
    "# Data manipulation libraries\n",
    "import pandas as pd       # For DataFrames and data manipulation\n",
    "import numpy as np        # For numerical operations and linear algebra\n",
    "\n",
    "# Sparse matrix and similarity computation\n",
    "from scipy.sparse import csr_matrix               # For sparse matrices (memory efficient)\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # For cosine similarity\n",
    "\n",
    "# Standard library imports\n",
    "import warnings           # For suppressing warnings\n",
    "import os                 # For file path operations\n",
    "import sys                # For system-level operations\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add parent directory for utils import (using RELATIVE path)\n",
    "# This allows importing helper functions from the utils folder\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))))\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)           # Show all columns\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)  # 2 decimal places\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84c0b7",
   "metadata": {},
   "source": [
    "## 1. Load Dataset and Target Items from Section 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "784e6f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Digital Music dataset...\n",
      "Ratings shape: (1584082, 4)\n",
      "Unique users: 840,372\n",
      "Unique items: 456,992\n",
      "\n",
      "Items with avg_rating <= 3.0 and num_ratings >= 50: 15\n",
      "\n",
      "============================================================\n",
      "SELECTED TARGET ITEMS (with sufficient ratings)\n",
      "============================================================\n",
      "\n",
      "I1: B00S33PD6W\n",
      "   Average rating: 1.00\n",
      "   Number of ratings: 73\n",
      "\n",
      "I2: B00DO4LN82\n",
      "   Average rating: 1.02\n",
      "   Number of ratings: 64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATASET LOADING AND TARGET ITEM SELECTION\n",
    "# =============================================================================\n",
    "# Load the Amazon Digital Music dataset and select target items for analysis.\n",
    "# Target items are selected as LOW-RATED items with SUFFICIENT ratings.\n",
    "\n",
    "# Define paths using RELATIVE paths (important for portability)\n",
    "\n",
    "DATASET_PATH = '../../dataset'    \n",
    "RESULTS_PATH = '../../results'    \n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "# Load the Digital Music dataset\n",
    "# CSV has no header; columns are: item_id, user_id, rating, timestamp\n",
    "print(\"Loading Digital Music dataset...\")\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(DATASET_PATH, 'Digital_Music.csv'),  # Relative path to data\n",
    "    header=None,                                       # No header in CSV file\n",
    "    names=['item_id', 'user_id', 'rating', 'timestamp']  # Define column names\n",
    ")\n",
    "\n",
    "print(f\"Ratings shape: {ratings.shape}\")\n",
    "print(f\"Unique users: {ratings['user_id'].nunique():,}\")\n",
    "print(f\"Unique items: {ratings['item_id'].nunique():,}\")\n",
    "\n",
    "# Calculate item statistics\n",
    "item_stats = ratings.groupby('item_id').agg(\n",
    "    num_ratings=('rating', 'count'),\n",
    "    avg_rating=('rating', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Select target items: LOW-RATED items but with ENOUGH RATINGS for meaningful similarity\n",
    "# Criteria: avg_rating <= 3.0 (below average) AND num_ratings >= 50\n",
    "MIN_RATINGS = 50\n",
    "MAX_AVG_RATING = 3.0\n",
    "\n",
    "low_rated_items = item_stats[\n",
    "    (item_stats['avg_rating'] <= MAX_AVG_RATING) & \n",
    "    (item_stats['num_ratings'] >= MIN_RATINGS)\n",
    "].sort_values('avg_rating', ascending=True)\n",
    "\n",
    "print(f\"\\nItems with avg_rating <= {MAX_AVG_RATING} and num_ratings >= {MIN_RATINGS}: {len(low_rated_items)}\")\n",
    "\n",
    "# Select I1 (lowest rated with enough ratings) and I2 (second lowest)\n",
    "if len(low_rated_items) >= 2:\n",
    "    I1_row = low_rated_items.iloc[0]\n",
    "    I2_row = low_rated_items.iloc[1]\n",
    "else:\n",
    "    # Fallback: just get items with most ratings\n",
    "    low_rated_items = item_stats.nlargest(100, 'num_ratings').nsmallest(2, 'avg_rating')\n",
    "    I1_row = low_rated_items.iloc[0]\n",
    "    I2_row = low_rated_items.iloc[1]\n",
    "\n",
    "I1_id = I1_row['item_id']\n",
    "I2_id = I2_row['item_id']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SELECTED TARGET ITEMS (with sufficient ratings)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nI1: {I1_id}\")\n",
    "print(f\"   Average rating: {I1_row['avg_rating']:.2f}\")\n",
    "print(f\"   Number of ratings: {int(I1_row['num_ratings'])}\")\n",
    "\n",
    "print(f\"\\nI2: {I2_id}\")\n",
    "print(f\"   Average rating: {I2_row['avg_rating']:.2f}\")\n",
    "print(f\"   Number of ratings: {int(I2_row['num_ratings'])}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f432ba24",
   "metadata": {},
   "source": [
    "## 2. Create User-Item Matrix with Mean-Centering\n",
    "\n",
    "For item-based CF with mean-centering, we subtract each item's mean rating from its ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a950900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mean-centered ratings...\n",
      "✓ Mean-centered ratings computed!\n",
      "Original rating range: 1.00 to 5.00\n",
      "Centered rating range: -3.96 to 3.91\n",
      "\n",
      "Sample of mean-centered ratings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_mean</th>\n",
       "      <th>rating_centered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>A1ZCPG3D3HGRSS</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>AC2PL52NKPL29</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>A1SUZXBDZSDQ3A</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>A3A0W7FZXM0IZW</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>A12R54MKO17TW0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>A25ZT87OMIPLNX</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>A3NVGWKHLULDHR</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>-3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>AT7OB43GHKIUA</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>A1H3X1TW6Y7HD8</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0001388703</td>\n",
       "      <td>AZ3T21W6CW0MW</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.57</td>\n",
       "      <td>-3.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id         user_id  rating  item_mean  rating_centered\n",
       "0  0001388703  A1ZCPG3D3HGRSS    5.00       4.57             0.43\n",
       "1  0001388703   AC2PL52NKPL29    5.00       4.57             0.43\n",
       "2  0001388703  A1SUZXBDZSDQ3A    5.00       4.57             0.43\n",
       "3  0001388703  A3A0W7FZXM0IZW    5.00       4.57             0.43\n",
       "4  0001388703  A12R54MKO17TW0    5.00       4.57             0.43\n",
       "5  0001388703  A25ZT87OMIPLNX    5.00       4.57             0.43\n",
       "6  0001388703  A3NVGWKHLULDHR    1.00       4.57            -3.57\n",
       "7  0001388703   AT7OB43GHKIUA    5.00       4.57             0.43\n",
       "8  0001388703  A1H3X1TW6Y7HD8    5.00       4.57             0.43\n",
       "9  0001388703   AZ3T21W6CW0MW    1.00       4.57            -3.57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate mean rating for each item (for mean-centering)\n",
    "item_means = ratings.groupby('item_id')['rating'].mean()\n",
    "\n",
    "# Apply mean-centering using vectorized merge (much faster than apply)\n",
    "print(\"Computing mean-centered ratings...\")\n",
    "ratings = ratings.merge(\n",
    "    item_means.reset_index().rename(columns={'rating': 'item_mean'}),\n",
    "    on='item_id',\n",
    "    how='left'\n",
    ")\n",
    "ratings['rating_centered'] = ratings['rating'] - ratings['item_mean']\n",
    "\n",
    "print(\"✓ Mean-centered ratings computed!\")\n",
    "print(f\"Original rating range: {ratings['rating'].min():.2f} to {ratings['rating'].max():.2f}\")\n",
    "print(f\"Centered rating range: {ratings['rating_centered'].min():.2f} to {ratings['rating_centered'].max():.2f}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample of mean-centered ratings:\")\n",
    "display(ratings[['item_id', 'user_id', 'rating', 'item_mean', 'rating_centered']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421afa7",
   "metadata": {},
   "source": [
    "## 3. Task 1: Apply Item-Based CF using Cosine Similarity with Mean-Centering\n",
    "\n",
    "Compute cosine similarity between target items and all other items that share common raters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "088f08bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity function defined!\n"
     ]
    }
   ],
   "source": [
    "# Get users who rated each item\n",
    "item_users = ratings.groupby('item_id')['user_id'].apply(set).to_dict()\n",
    "\n",
    "# Create item-user rating lookup (aggregating duplicates with mean)\n",
    "item_user_centered_ratings = ratings.groupby(['item_id', 'user_id'])['rating_centered'].mean().reset_index()\n",
    "\n",
    "def compute_item_similarity_cosine_mean_centered(target_item_id, item_user_ratings_df, item_users_dict):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between target item and all co-rated items\n",
    "    using mean-centered ratings.\n",
    "    \"\"\"\n",
    "    # Get users who rated the target item\n",
    "    target_users = item_users_dict.get(target_item_id, set())\n",
    "    \n",
    "    if len(target_users) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Find items that share at least one common rater\n",
    "    candidate_items = set()\n",
    "    for item_id, users in item_users_dict.items():\n",
    "        if item_id != target_item_id and len(target_users & users) > 0:\n",
    "            candidate_items.add(item_id)\n",
    "    \n",
    "    print(f\"Target item {target_item_id} has {len(target_users)} raters\")\n",
    "    print(f\"Found {len(candidate_items)} items with common raters\")\n",
    "    \n",
    "    if len(candidate_items) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get ratings for target item (mean-centered, aggregated)\n",
    "    target_ratings = item_user_ratings_df[item_user_ratings_df['item_id'] == target_item_id].set_index('user_id')['rating_centered']\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for candidate_id in candidate_items:\n",
    "        # Get ratings for candidate item (aggregated)\n",
    "        candidate_ratings = item_user_ratings_df[item_user_ratings_df['item_id'] == candidate_id].set_index('user_id')['rating_centered']\n",
    "        \n",
    "        # Find common users\n",
    "        common_users = list(set(target_ratings.index) & set(candidate_ratings.index))\n",
    "        \n",
    "        if len(common_users) < 1:\n",
    "            continue\n",
    "        \n",
    "        # Get ratings vectors for common users (properly aligned)\n",
    "        target_vec = target_ratings.loc[common_users].values\n",
    "        candidate_vec = candidate_ratings.loc[common_users].values\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        dot_product = np.dot(target_vec, candidate_vec)\n",
    "        norm_target = np.linalg.norm(target_vec)\n",
    "        norm_candidate = np.linalg.norm(candidate_vec)\n",
    "        \n",
    "        if norm_target > 0 and norm_candidate > 0:\n",
    "            similarity = dot_product / (norm_target * norm_candidate)\n",
    "        else:\n",
    "            similarity = 0\n",
    "        \n",
    "        similarities.append({\n",
    "            'item_id': candidate_id,\n",
    "            'similarity': round(similarity, 4),\n",
    "            'common_users': len(common_users)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(similarities).sort_values('similarity', ascending=False)\n",
    "\n",
    "print(\"Similarity function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e75da0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Computing similarities for I1...\n",
      "============================================================\n",
      "Target item B00S33PD6W has 73 raters\n",
      "Found 4 items with common raters\n",
      "\n",
      "============================================================\n",
      "Computing similarities for I2...\n",
      "============================================================\n",
      "Target item B00DO4LN82 has 62 raters\n",
      "Found 3 items with common raters\n",
      "\n",
      "============================================================\n",
      "SIMILARITY RESULTS\n",
      "============================================================\n",
      "\n",
      "I1 (B00S33PD6W): 4 similar items found\n",
      "I2 (B00DO4LN82): 3 similar items found\n"
     ]
    }
   ],
   "source": [
    "# Compute similarities for target items I1 and I2\n",
    "print(\"=\" * 60)\n",
    "print(\"Computing similarities for I1...\")\n",
    "print(\"=\" * 60)\n",
    "I1_similarities = compute_item_similarity_cosine_mean_centered(I1_id, item_user_centered_ratings, item_users)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Computing similarities for I2...\")\n",
    "print(\"=\" * 60)\n",
    "I2_similarities = compute_item_similarity_cosine_mean_centered(I2_id, item_user_centered_ratings, item_users)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SIMILARITY RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nI1 ({I1_id}): {len(I1_similarities)} similar items found\")\n",
    "print(f\"I2 ({I2_id}): {len(I2_similarities)} similar items found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f40142",
   "metadata": {},
   "source": [
    "## 4. Task 2: Identify Top 20% of Similar Items for Each Target Item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f93fa941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOP 20% SIMILAR ITEMS FOR I1 (B00S33PD6W)\n",
      "============================================================\n",
      "Total similar items: 4\n",
      "Top 20% count: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S33PKFG</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users\n",
       "0  B00S33PKFG           0             4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP 20% SIMILAR ITEMS FOR I2 (B00DO4LN82)\n",
      "============================================================\n",
      "Total similar items: 3\n",
      "Top 20% count: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users\n",
       "0  B00FMJGZTO        1.00             6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select top 20% of similar items for each target item\n",
    "def get_top_percent_similar_items(similarities_df, top_percent=0.20):\n",
    "    \"\"\"Select top X% of similar items based on similarity score.\"\"\"\n",
    "    if len(similarities_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    n_items = max(1, int(len(similarities_df) * top_percent))\n",
    "    return similarities_df.head(n_items)\n",
    "\n",
    "# Get top 20% for I1\n",
    "I1_top20 = get_top_percent_similar_items(I1_similarities, 0.20)\n",
    "print(\"=\" * 60)\n",
    "print(f\"TOP 20% SIMILAR ITEMS FOR I1 ({I1_id})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total similar items: {len(I1_similarities)}\")\n",
    "print(f\"Top 20% count: {len(I1_top20)}\")\n",
    "if len(I1_top20) > 0:\n",
    "    display(I1_top20)\n",
    "else:\n",
    "    print(\"No similar items found for I1\")\n",
    "\n",
    "# Get top 20% for I2\n",
    "I2_top20 = get_top_percent_similar_items(I2_similarities, 0.20)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"TOP 20% SIMILAR ITEMS FOR I2 ({I2_id})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total similar items: {len(I2_similarities)}\")\n",
    "print(f\"Top 20% count: {len(I2_top20)}\")\n",
    "if len(I2_top20) > 0:\n",
    "    display(I2_top20)\n",
    "else:\n",
    "    print(\"No similar items found for I2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e3d753",
   "metadata": {},
   "source": [
    "## 5. Task 3: Predict Missing Ratings Using Similar Items\n",
    "\n",
    "For item-based CF, the predicted rating for user u on item i is:\n",
    "\n",
    "$$\\hat{r}_{ui} = \\bar{r}_i + \\frac{\\sum_{j \\in N(i)} sim(i,j) \\cdot (r_{uj} - \\bar{r}_j)}{\\sum_{j \\in N(i)} |sim(i,j)|}$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{r}_i$ is the mean rating for item i\n",
    "- $N(i)$ is the set of similar items to i that user u has rated\n",
    "- $sim(i,j)$ is the similarity between items i and j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d618f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction function defined!\n"
     ]
    }
   ],
   "source": [
    "# Create user-item rating dictionaries for efficient lookup\n",
    "user_item_ratings = ratings.set_index(['user_id', 'item_id'])['rating'].to_dict()\n",
    "\n",
    "# Convert item_means to dictionary for fast lookup\n",
    "item_means_dict = item_means.to_dict()\n",
    "\n",
    "def predict_rating_item_based(user_id, target_item_id, similar_items_df, item_means_dict, user_item_ratings):\n",
    "    \"\"\"\n",
    "    Predict rating for a user on target item using item-based CF with mean-centering.\n",
    "    \"\"\"\n",
    "    if len(similar_items_df) == 0:\n",
    "        return item_means_dict.get(target_item_id, 3.0)  # Return item mean or global mean\n",
    "    \n",
    "    # Get target item mean\n",
    "    target_mean = item_means_dict.get(target_item_id, 3.0)\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    for _, row in similar_items_df.iterrows():\n",
    "        similar_item_id = row['item_id']\n",
    "        similarity = row['similarity']\n",
    "        \n",
    "        # Check if user has rated this similar item\n",
    "        rating = user_item_ratings.get((user_id, similar_item_id), None)\n",
    "        \n",
    "        if rating is not None:\n",
    "            similar_item_mean = item_means_dict.get(similar_item_id, 3.0)\n",
    "            numerator += similarity * (rating - similar_item_mean)\n",
    "            denominator += abs(similarity)\n",
    "    \n",
    "    if denominator > 0:\n",
    "        prediction = target_mean + (numerator / denominator)\n",
    "        # Clip to valid rating range [1, 5]\n",
    "        prediction = max(1, min(5, prediction))\n",
    "    else:\n",
    "        prediction = target_mean\n",
    "    \n",
    "    return round(prediction, 2)\n",
    "\n",
    "print(\"Prediction function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca5ba456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users to predict for I1: 13\n",
      "Users to predict for I2: 18\n"
     ]
    }
   ],
   "source": [
    "# Get users who haven't rated target items but have rated similar items\n",
    "def get_users_to_predict(target_item_id, similar_items_df, ratings_df):\n",
    "    \"\"\"Find users who haven't rated target item but have rated at least one similar item.\"\"\"\n",
    "    # Users who rated the target item\n",
    "    users_rated_target = set(ratings_df[ratings_df['item_id'] == target_item_id]['user_id'])\n",
    "    \n",
    "    # Users who rated at least one similar item\n",
    "    if len(similar_items_df) == 0:\n",
    "        return []\n",
    "    \n",
    "    similar_item_ids = similar_items_df['item_id'].tolist()\n",
    "    users_rated_similar = set(ratings_df[ratings_df['item_id'].isin(similar_item_ids)]['user_id'])\n",
    "    \n",
    "    # Users to predict: rated similar but not target\n",
    "    users_to_predict = users_rated_similar - users_rated_target\n",
    "    \n",
    "    return list(users_to_predict)\n",
    "\n",
    "# Get users to predict for I1 and I2\n",
    "I1_users_to_predict = get_users_to_predict(I1_id, I1_top20, ratings)\n",
    "I2_users_to_predict = get_users_to_predict(I2_id, I2_top20, ratings)\n",
    "\n",
    "print(f\"Users to predict for I1: {len(I1_users_to_predict)}\")\n",
    "print(f\"Users to predict for I2: {len(I2_users_to_predict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d62c6f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREDICTED RATINGS FOR I1 (B00S33PD6W)\n",
      "============================================================\n",
      "Number of predictions: 13\n",
      "Mean predicted rating: 1.00\n",
      "Std of predictions: 0.00\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2D15NAO51QH1M</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A22UAYQBS3KQWA</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1HCPG8M6WOV0E</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1O0UYJPK96BKK</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1WFTDD0V5FTNG</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A3VIXQI771ZTCT</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A14OXNXWNX2STM</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1HY6GQ6Y5ERBU</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A3UXLGWN2CX27W</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AXVTOFDNLTHWF</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     item_id  predicted_rating\n",
       "0  A2D15NAO51QH1M  B00S33PD6W              1.00\n",
       "1  A22UAYQBS3KQWA  B00S33PD6W              1.00\n",
       "2  A1HCPG8M6WOV0E  B00S33PD6W              1.00\n",
       "3  A1O0UYJPK96BKK  B00S33PD6W              1.00\n",
       "4  A1WFTDD0V5FTNG  B00S33PD6W              1.00\n",
       "5  A3VIXQI771ZTCT  B00S33PD6W              1.00\n",
       "6  A14OXNXWNX2STM  B00S33PD6W              1.00\n",
       "7  A1HY6GQ6Y5ERBU  B00S33PD6W              1.00\n",
       "8  A3UXLGWN2CX27W  B00S33PD6W              1.00\n",
       "9   AXVTOFDNLTHWF  B00S33PD6W              1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREDICTED RATINGS FOR I2 (B00DO4LN82)\n",
      "============================================================\n",
      "Number of predictions: 18\n",
      "Mean predicted rating: 1.84\n",
      "Std of predictions: 1.41\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1FX5WML2MNIB9</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOFYCGUQ902T8</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1WWBC09BD8HU6</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A37MU45KRK7FRI</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1L8S0K8PYSOAF</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A2X9ZF3P2CGASS</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A3LVZO0IYH7KCL</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1W2AD5O1O92GL</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A1ADGBFYI7ECMD</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A1MQIVLGDBA9XH</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     item_id  predicted_rating\n",
       "0  A1FX5WML2MNIB9  B00DO4LN82              1.00\n",
       "1   AOFYCGUQ902T8  B00DO4LN82              1.00\n",
       "2  A1WWBC09BD8HU6  B00DO4LN82              1.00\n",
       "3  A37MU45KRK7FRI  B00DO4LN82              4.22\n",
       "4  A1L8S0K8PYSOAF  B00DO4LN82              1.00\n",
       "5  A2X9ZF3P2CGASS  B00DO4LN82              4.22\n",
       "6  A3LVZO0IYH7KCL  B00DO4LN82              4.22\n",
       "7  A1W2AD5O1O92GL  B00DO4LN82              3.22\n",
       "8  A1ADGBFYI7ECMD  B00DO4LN82              4.22\n",
       "9  A1MQIVLGDBA9XH  B00DO4LN82              1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict ratings for sample users (limit to avoid long computation)\n",
    "MAX_PREDICTIONS = 100\n",
    "\n",
    "# Predictions for I1\n",
    "I1_predictions = []\n",
    "for user_id in I1_users_to_predict[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_item_based(user_id, I1_id, I1_top20, item_means_dict, user_item_ratings)\n",
    "    I1_predictions.append({\n",
    "        'user_id': user_id,\n",
    "        'item_id': I1_id,\n",
    "        'predicted_rating': pred\n",
    "    })\n",
    "\n",
    "I1_predictions_df = pd.DataFrame(I1_predictions)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"PREDICTED RATINGS FOR I1 ({I1_id})\")\n",
    "print(\"=\" * 60)\n",
    "if len(I1_predictions_df) > 0:\n",
    "    print(f\"Number of predictions: {len(I1_predictions_df)}\")\n",
    "    print(f\"Mean predicted rating: {I1_predictions_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"Std of predictions: {I1_predictions_df['predicted_rating'].std():.2f}\")\n",
    "    print(\"\\nSample predictions:\")\n",
    "    display(I1_predictions_df.head(10))\n",
    "else:\n",
    "    print(\"No predictions possible for I1\")\n",
    "\n",
    "# Predictions for I2\n",
    "I2_predictions = []\n",
    "for user_id in I2_users_to_predict[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_item_based(user_id, I2_id, I2_top20, item_means_dict, user_item_ratings)\n",
    "    I2_predictions.append({\n",
    "        'user_id': user_id,\n",
    "        'item_id': I2_id,\n",
    "        'predicted_rating': pred\n",
    "    })\n",
    "\n",
    "I2_predictions_df = pd.DataFrame(I2_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"PREDICTED RATINGS FOR I2 ({I2_id})\")\n",
    "print(\"=\" * 60)\n",
    "if len(I2_predictions_df) > 0:\n",
    "    print(f\"Number of predictions: {len(I2_predictions_df)}\")\n",
    "    print(f\"Mean predicted rating: {I2_predictions_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"Std of predictions: {I2_predictions_df['predicted_rating'].std():.2f}\")\n",
    "    print(\"\\nSample predictions:\")\n",
    "    display(I2_predictions_df.head(10))\n",
    "else:\n",
    "    print(\"No predictions possible for I2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96526521",
   "metadata": {},
   "source": [
    "## 6. Task 4: Compute DF (Discount Factor) and DS (Discount Similarity)\n",
    "\n",
    "**DF (Discount Factor):** The predicted rating value itself, indicating how likely a user would rate the item.\n",
    "\n",
    "**DS (Discount Similarity):** A confidence-weighted score that combines the prediction with similarity weights.\n",
    "\n",
    "$$DS_i = \\sum_{j \\in N(i)} sim(i,j) \\cdot r_j$$\n",
    "\n",
    "Where $r_j$ is the average rating of similar item j.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d8cf1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DF & DS FOR I1's SIMILAR ITEMS (B00S33PD6W)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>DF</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S33PKFG</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00S5O5E2M</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00S5O5ALM</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00CO0HXN6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users  avg_rating  DF   DS\n",
       "0  B00S33PKFG           0             4        1.65   0 0.00\n",
       "1  B00S5O5E2M           0             2        1.00   0 0.00\n",
       "2  B00S5O5ALM           0            29        1.09   0 0.00\n",
       "3  B00CO0HXN6           0             1        1.00   0 0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DF & DS FOR I2's SIMILAR ITEMS (B00DO4LN82)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>DF</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00DO4LM9C</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B01BO915S6</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.89</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-4.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users  avg_rating    DF    DS\n",
       "0  B00FMJGZTO        1.00             6        1.79  1.00  1.79\n",
       "1  B00DO4LM9C        0.00             2        1.00  0.00  0.00\n",
       "2  B01BO915S6       -1.00             1        4.89 -1.00 -4.89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_df_ds(similar_items_df, item_means_dict):\n",
    "    \"\"\"\n",
    "    Compute Discount Factor (DF) and Discount Similarity (DS) for each similar item.\n",
    "    \n",
    "    DF: Based on similarity (higher = better decision)\n",
    "    DS: Similarity-weighted average rating score\n",
    "    \"\"\"\n",
    "    if len(similar_items_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, row in similar_items_df.iterrows():\n",
    "        item_id = row['item_id']\n",
    "        similarity = row['similarity']\n",
    "        common_users = row['common_users']\n",
    "        \n",
    "        # Get average rating of the similar item\n",
    "        avg_rating = item_means_dict.get(item_id, 3.0)\n",
    "        \n",
    "        # DF: Similarity score (higher similarity = more relevant for decision)\n",
    "        df = similarity\n",
    "        \n",
    "        # DS: Similarity-weighted score\n",
    "        ds = similarity * avg_rating\n",
    "        \n",
    "        results.append({\n",
    "            'item_id': item_id,\n",
    "            'similarity': similarity,\n",
    "            'common_users': common_users,\n",
    "            'avg_rating': round(avg_rating, 2),\n",
    "            'DF': round(df, 4),\n",
    "            'DS': round(ds, 4)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('DS', ascending=False)\n",
    "\n",
    "# Compute DF and DS for I1's similar items\n",
    "I1_df_ds = compute_df_ds(I1_similarities, item_means_dict)\n",
    "print(\"=\" * 60)\n",
    "print(f\"DF & DS FOR I1's SIMILAR ITEMS ({I1_id})\")\n",
    "print(\"=\" * 60)\n",
    "if len(I1_df_ds) > 0:\n",
    "    display(I1_df_ds.head(20))\n",
    "else:\n",
    "    print(\"No similar items found for I1\")\n",
    "\n",
    "# Compute DF and DS for I2's similar items\n",
    "I2_df_ds = compute_df_ds(I2_similarities, item_means_dict)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"DF & DS FOR I2's SIMILAR ITEMS ({I2_id})\")\n",
    "print(\"=\" * 60)\n",
    "if len(I2_df_ds) > 0:\n",
    "    display(I2_df_ds.head(20))\n",
    "else:\n",
    "    print(\"No similar items found for I2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b505b322",
   "metadata": {},
   "source": [
    "## 7. Task 5: Select Top 20% Items Using DS\n",
    "\n",
    "Select the top 20% of similar items based on their Discount Similarity (DS).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb4233a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOP 20% ITEMS BY DS FOR I1 (B00S33PD6W)\n",
      "============================================================\n",
      "Total items: 4\n",
      "Top 20% count: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>DF</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S33PKFG</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users  avg_rating  DF   DS\n",
       "0  B00S33PKFG           0             4        1.65   0 0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP 20% ITEMS BY DS FOR I2 (B00DO4LN82)\n",
      "============================================================\n",
      "Total items: 3\n",
      "Top 20% count: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>DF</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users  avg_rating   DF   DS\n",
       "0  B00FMJGZTO        1.00             6        1.79 1.00 1.79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select top 20% items using DS\n",
    "def get_top_percent_by_ds(df_ds_results, top_percent=0.20):\n",
    "    \"\"\"Select top X% of items based on DS (Discount Similarity).\"\"\"\n",
    "    if len(df_ds_results) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Sort by DS (already sorted in compute_df_ds)\n",
    "    n_items = max(1, int(len(df_ds_results) * top_percent))\n",
    "    return df_ds_results.head(n_items)\n",
    "\n",
    "# Top 20% for I1 by DS\n",
    "I1_top20_ds = get_top_percent_by_ds(I1_df_ds, 0.20)\n",
    "print(\"=\" * 60)\n",
    "print(f\"TOP 20% ITEMS BY DS FOR I1 ({I1_id})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total items: {len(I1_df_ds)}\")\n",
    "print(f\"Top 20% count: {len(I1_top20_ds)}\")\n",
    "if len(I1_top20_ds) > 0:\n",
    "    display(I1_top20_ds)\n",
    "else:\n",
    "    print(\"No items to select for I1\")\n",
    "\n",
    "# Top 20% for I2 by DS\n",
    "I2_top20_ds = get_top_percent_by_ds(I2_df_ds, 0.20)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"TOP 20% ITEMS BY DS FOR I2 ({I2_id})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total items: {len(I2_df_ds)}\")\n",
    "print(f\"Top 20% count: {len(I2_top20_ds)}\")\n",
    "if len(I2_top20_ds) > 0:\n",
    "    display(I2_top20_ds)\n",
    "else:\n",
    "    print(\"No items to select for I2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec19aa",
   "metadata": {},
   "source": [
    "## 8. Task 6: Use Top 20% Items by DS for Updated Rating Predictions\n",
    "\n",
    "Make new predictions using the top 20% items selected by Discount Similarity (DS) instead of raw similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be5ac5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users to predict for I1 (using DS-selected items): 13\n",
      "Users to predict for I2 (using DS-selected items): 18\n",
      "\n",
      "============================================================\n",
      "PREDICTED RATINGS FOR I1 USING DS-SELECTED ITEMS (B00S33PD6W)\n",
      "============================================================\n",
      "Number of predictions: 13\n",
      "Mean predicted rating: 1.00\n",
      "Std of predictions: 0.00\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2D15NAO51QH1M</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A22UAYQBS3KQWA</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1HCPG8M6WOV0E</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1O0UYJPK96BKK</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1WFTDD0V5FTNG</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A3VIXQI771ZTCT</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A14OXNXWNX2STM</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1HY6GQ6Y5ERBU</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A3UXLGWN2CX27W</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AXVTOFDNLTHWF</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     item_id  predicted_rating\n",
       "0  A2D15NAO51QH1M  B00S33PD6W              1.00\n",
       "1  A22UAYQBS3KQWA  B00S33PD6W              1.00\n",
       "2  A1HCPG8M6WOV0E  B00S33PD6W              1.00\n",
       "3  A1O0UYJPK96BKK  B00S33PD6W              1.00\n",
       "4  A1WFTDD0V5FTNG  B00S33PD6W              1.00\n",
       "5  A3VIXQI771ZTCT  B00S33PD6W              1.00\n",
       "6  A14OXNXWNX2STM  B00S33PD6W              1.00\n",
       "7  A1HY6GQ6Y5ERBU  B00S33PD6W              1.00\n",
       "8  A3UXLGWN2CX27W  B00S33PD6W              1.00\n",
       "9   AXVTOFDNLTHWF  B00S33PD6W              1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREDICTED RATINGS FOR I2 USING DS-SELECTED ITEMS (B00DO4LN82)\n",
      "============================================================\n",
      "Number of predictions: 18\n",
      "Mean predicted rating: 1.84\n",
      "Std of predictions: 1.41\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1FX5WML2MNIB9</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOFYCGUQ902T8</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1WWBC09BD8HU6</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A37MU45KRK7FRI</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1L8S0K8PYSOAF</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A2X9ZF3P2CGASS</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A3LVZO0IYH7KCL</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1W2AD5O1O92GL</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A1ADGBFYI7ECMD</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A1MQIVLGDBA9XH</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     item_id  predicted_rating\n",
       "0  A1FX5WML2MNIB9  B00DO4LN82              1.00\n",
       "1   AOFYCGUQ902T8  B00DO4LN82              1.00\n",
       "2  A1WWBC09BD8HU6  B00DO4LN82              1.00\n",
       "3  A37MU45KRK7FRI  B00DO4LN82              4.22\n",
       "4  A1L8S0K8PYSOAF  B00DO4LN82              1.00\n",
       "5  A2X9ZF3P2CGASS  B00DO4LN82              4.22\n",
       "6  A3LVZO0IYH7KCL  B00DO4LN82              4.22\n",
       "7  A1W2AD5O1O92GL  B00DO4LN82              3.22\n",
       "8  A1ADGBFYI7ECMD  B00DO4LN82              4.22\n",
       "9  A1MQIVLGDBA9XH  B00DO4LN82              1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get users to predict using DS-selected items\n",
    "I1_users_to_predict_ds = get_users_to_predict(I1_id, I1_top20_ds, ratings)\n",
    "I2_users_to_predict_ds = get_users_to_predict(I2_id, I2_top20_ds, ratings)\n",
    "\n",
    "print(f\"Users to predict for I1 (using DS-selected items): {len(I1_users_to_predict_ds)}\")\n",
    "print(f\"Users to predict for I2 (using DS-selected items): {len(I2_users_to_predict_ds)}\")\n",
    "\n",
    "# Predictions for I1 using DS-selected neighbors\n",
    "I1_predictions_ds = []\n",
    "for user_id in I1_users_to_predict_ds[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_item_based(user_id, I1_id, I1_top20_ds, item_means_dict, user_item_ratings)\n",
    "    I1_predictions_ds.append({\n",
    "        'user_id': user_id,\n",
    "        'item_id': I1_id,\n",
    "        'predicted_rating': pred\n",
    "    })\n",
    "\n",
    "I1_predictions_ds_df = pd.DataFrame(I1_predictions_ds)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"PREDICTED RATINGS FOR I1 USING DS-SELECTED ITEMS ({I1_id})\")\n",
    "print(\"=\" * 60)\n",
    "if len(I1_predictions_ds_df) > 0:\n",
    "    print(f\"Number of predictions: {len(I1_predictions_ds_df)}\")\n",
    "    print(f\"Mean predicted rating: {I1_predictions_ds_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"Std of predictions: {I1_predictions_ds_df['predicted_rating'].std():.2f}\")\n",
    "    print(\"\\nSample predictions:\")\n",
    "    display(I1_predictions_ds_df.head(10))\n",
    "else:\n",
    "    print(\"No predictions possible for I1\")\n",
    "\n",
    "# Predictions for I2 using DS-selected neighbors\n",
    "I2_predictions_ds = []\n",
    "for user_id in I2_users_to_predict_ds[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_item_based(user_id, I2_id, I2_top20_ds, item_means_dict, user_item_ratings)\n",
    "    I2_predictions_ds.append({\n",
    "        'user_id': user_id,\n",
    "        'item_id': I2_id,\n",
    "        'predicted_rating': pred\n",
    "    })\n",
    "\n",
    "I2_predictions_ds_df = pd.DataFrame(I2_predictions_ds)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"PREDICTED RATINGS FOR I2 USING DS-SELECTED ITEMS ({I2_id})\")\n",
    "print(\"=\" * 60)\n",
    "if len(I2_predictions_ds_df) > 0:\n",
    "    print(f\"Number of predictions: {len(I2_predictions_ds_df)}\")\n",
    "    print(f\"Mean predicted rating: {I2_predictions_ds_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"Std of predictions: {I2_predictions_ds_df['predicted_rating'].std():.2f}\")\n",
    "    print(\"\\nSample predictions:\")\n",
    "    display(I2_predictions_ds_df.head(10))\n",
    "else:\n",
    "    print(\"No predictions possible for I2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d326d6",
   "metadata": {},
   "source": [
    "## 9. Task 7: Compare Similarity Lists from Steps 2 and 5\n",
    "\n",
    "Compare the top 20% items selected by:\n",
    "- **Step 2:** Raw Cosine Similarity\n",
    "- **Step 5:** Discount Similarity (DS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1792492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPARISON OF SIMILAR ITEMS FOR I1 (B00S33PD6W)\n",
      "======================================================================\n",
      "\n",
      "📊 Selection Summary:\n",
      "   Items selected by Similarity (Step 2): 1\n",
      "   Items selected by DS (Step 5): 1\n",
      "\n",
      "📊 Overlap Analysis:\n",
      "   Common items (in both): 1\n",
      "   Only in Similarity list: 0\n",
      "   Only in DS list: 0\n",
      "   Overlap percentage: 100.0%\n",
      "\n",
      "📊 Side-by-Side Comparison:\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id_sim</th>\n",
       "      <th>similarity</th>\n",
       "      <th>item_id_ds</th>\n",
       "      <th>DS</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S33PKFG</td>\n",
       "      <td>0</td>\n",
       "      <td>B00S33PKFG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_id_sim  similarity  item_id_ds   DS  avg_rating\n",
       "0  B00S33PKFG           0  B00S33PKFG 0.00        1.65"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMMENTARY\n",
      "======================================================================\n",
      "\n",
      "✅ HIGH OVERLAP: The similarity-based and DS-based selections are very similar.\n",
      "   This suggests that items with high similarity also tend to have high-quality\n",
      "   ratings, making both methods consistent for this target item.\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "COMPARISON OF SIMILAR ITEMS FOR I2 (B00DO4LN82)\n",
      "======================================================================\n",
      "\n",
      "📊 Selection Summary:\n",
      "   Items selected by Similarity (Step 2): 1\n",
      "   Items selected by DS (Step 5): 1\n",
      "\n",
      "📊 Overlap Analysis:\n",
      "   Common items (in both): 1\n",
      "   Only in Similarity list: 0\n",
      "   Only in DS list: 0\n",
      "   Overlap percentage: 100.0%\n",
      "\n",
      "📊 Side-by-Side Comparison:\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id_sim</th>\n",
       "      <th>similarity</th>\n",
       "      <th>item_id_ds</th>\n",
       "      <th>DS</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_id_sim  similarity  item_id_ds   DS  avg_rating\n",
       "0  B00FMJGZTO        1.00  B00FMJGZTO 1.79        1.79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMMENTARY\n",
      "======================================================================\n",
      "\n",
      "✅ HIGH OVERLAP: The similarity-based and DS-based selections are very similar.\n",
      "   This suggests that items with high similarity also tend to have high-quality\n",
      "   ratings, making both methods consistent for this target item.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_similarity_lists(top20_sim, top20_ds, target_name):\n",
    "    \"\"\"Compare items selected by similarity vs DS.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"COMPARISON OF SIMILAR ITEMS FOR {target_name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if len(top20_sim) == 0 or len(top20_ds) == 0:\n",
    "        print(\"Not enough data to compare\")\n",
    "        return\n",
    "    \n",
    "    # Get item sets\n",
    "    sim_items = set(top20_sim['item_id'].tolist())\n",
    "    ds_items = set(top20_ds['item_id'].tolist())\n",
    "    \n",
    "    # Calculate overlap\n",
    "    common_items = sim_items & ds_items\n",
    "    only_sim = sim_items - ds_items\n",
    "    only_ds = ds_items - sim_items\n",
    "    \n",
    "    print(f\"\\n📊 Selection Summary:\")\n",
    "    print(f\"   Items selected by Similarity (Step 2): {len(sim_items)}\")\n",
    "    print(f\"   Items selected by DS (Step 5): {len(ds_items)}\")\n",
    "    \n",
    "    print(f\"\\n📊 Overlap Analysis:\")\n",
    "    print(f\"   Common items (in both): {len(common_items)}\")\n",
    "    print(f\"   Only in Similarity list: {len(only_sim)}\")\n",
    "    print(f\"   Only in DS list: {len(only_ds)}\")\n",
    "    \n",
    "    if len(sim_items) > 0:\n",
    "        overlap_pct = len(common_items) / len(sim_items) * 100\n",
    "        print(f\"   Overlap percentage: {overlap_pct:.1f}%\")\n",
    "    \n",
    "    # Side-by-side comparison\n",
    "    print(f\"\\n📊 Side-by-Side Comparison:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Prepare comparison dataframe\n",
    "    sim_df = top20_sim[['item_id', 'similarity']].copy()\n",
    "    sim_df.columns = ['item_id_sim', 'similarity']\n",
    "    sim_df = sim_df.reset_index(drop=True)\n",
    "    \n",
    "    ds_df = top20_ds[['item_id', 'DS', 'avg_rating']].copy()\n",
    "    ds_df.columns = ['item_id_ds', 'DS', 'avg_rating']\n",
    "    ds_df = ds_df.reset_index(drop=True)\n",
    "    \n",
    "    comparison = pd.concat([sim_df, ds_df], axis=1)\n",
    "    display(comparison)\n",
    "    \n",
    "    # Commentary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"COMMENTARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if overlap_pct > 80:\n",
    "        print(\"\"\"\n",
    "✅ HIGH OVERLAP: The similarity-based and DS-based selections are very similar.\n",
    "   This suggests that items with high similarity also tend to have high-quality\n",
    "   ratings, making both methods consistent for this target item.\n",
    "\"\"\")\n",
    "    elif overlap_pct > 50:\n",
    "        print(\"\"\"\n",
    "⚠️ MODERATE OVERLAP: There is partial agreement between the two methods.\n",
    "   DS considers both similarity AND average rating, so it may select items\n",
    "   that are slightly less similar but have better ratings. This can lead\n",
    "   to more balanced recommendations.\n",
    "\"\"\")\n",
    "    else:\n",
    "        print(\"\"\"\n",
    "🔄 LOW OVERLAP: The two methods select quite different items.\n",
    "   - Similarity-based: Focuses purely on rating pattern similarity\n",
    "   - DS-based: Balances similarity with item quality (avg rating)\n",
    "   \n",
    "   This difference occurs when highly similar items have poor ratings,\n",
    "   or when well-rated items have moderate similarity. DS tends to produce\n",
    "   more conservative but potentially higher-quality recommendations.\n",
    "\"\"\")\n",
    "\n",
    "# Compare for I1\n",
    "compare_similarity_lists(I1_top20, I1_top20_ds, f\"I1 ({I1_id})\")\n",
    "\n",
    "# Compare for I2\n",
    "print(\"\\n\")\n",
    "compare_similarity_lists(I2_top20, I2_top20_ds, f\"I2 ({I2_id})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41499b52",
   "metadata": {},
   "source": [
    "## 10. Task 8: Compare Predicted Ratings from Steps 3 and 6\n",
    "\n",
    "Compare the predictions made using:\n",
    "- **Step 3:** Top 20% items by Similarity\n",
    "- **Step 6:** Top 20% items by DS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70ffba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPARISON OF PREDICTIONS FOR I1 (B00S33PD6W)\n",
      "======================================================================\n",
      "\n",
      "📊 Prediction Statistics:\n",
      "----------------------------------------------------------------------\n",
      "Metric                    Similarity-Based     DS-Based            \n",
      "----------------------------------------------------------------------\n",
      "Number of predictions     13                   13                  \n",
      "Mean prediction           1.00                 1.00                \n",
      "Std deviation             0.00                 0.00                \n",
      "Min prediction            1.00                 1.00                \n",
      "Max prediction            1.00                 1.00                \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "📊 User Overlap:\n",
      "   Users with Similarity predictions: 13\n",
      "   Users with DS predictions: 13\n",
      "   Common users: 13\n",
      "\n",
      "📊 Side-by-Side Predictions (sample of common users):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pred_similarity</th>\n",
       "      <th>pred_DS</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2D15NAO51QH1M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A22UAYQBS3KQWA</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1HCPG8M6WOV0E</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1O0UYJPK96BKK</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1WFTDD0V5FTNG</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A3VIXQI771ZTCT</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A14OXNXWNX2STM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1HY6GQ6Y5ERBU</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A3UXLGWN2CX27W</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AXVTOFDNLTHWF</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A3RLXFRHILGG77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AIK48ZJJFY0DR</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A30W18I3U27B4R</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  pred_similarity  pred_DS  difference\n",
       "0   A2D15NAO51QH1M             1.00     1.00        0.00\n",
       "1   A22UAYQBS3KQWA             1.00     1.00        0.00\n",
       "2   A1HCPG8M6WOV0E             1.00     1.00        0.00\n",
       "3   A1O0UYJPK96BKK             1.00     1.00        0.00\n",
       "4   A1WFTDD0V5FTNG             1.00     1.00        0.00\n",
       "5   A3VIXQI771ZTCT             1.00     1.00        0.00\n",
       "6   A14OXNXWNX2STM             1.00     1.00        0.00\n",
       "7   A1HY6GQ6Y5ERBU             1.00     1.00        0.00\n",
       "8   A3UXLGWN2CX27W             1.00     1.00        0.00\n",
       "9    AXVTOFDNLTHWF             1.00     1.00        0.00\n",
       "10  A3RLXFRHILGG77             1.00     1.00        0.00\n",
       "11   AIK48ZJJFY0DR             1.00     1.00        0.00\n",
       "12  A30W18I3U27B4R             1.00     1.00        0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Difference Analysis:\n",
      "   Mean difference (DS - Similarity): 0.000\n",
      "   Mean absolute difference: 0.000\n",
      "\n",
      "======================================================================\n",
      "DISCUSSION\n",
      "======================================================================\n",
      "\n",
      "✅ SIMILAR PREDICTIONS: Both methods produce very similar predictions\n",
      "   (difference: 0.000).\n",
      "\n",
      "   This suggests that for this target item, the choice of neighbors\n",
      "   (by similarity vs DS) doesn't significantly impact prediction quality.\n",
      "   Both approaches are equally viable.\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "COMPARISON OF PREDICTIONS FOR I2 (B00DO4LN82)\n",
      "======================================================================\n",
      "\n",
      "📊 Prediction Statistics:\n",
      "----------------------------------------------------------------------\n",
      "Metric                    Similarity-Based     DS-Based            \n",
      "----------------------------------------------------------------------\n",
      "Number of predictions     18                   18                  \n",
      "Mean prediction           1.84                 1.84                \n",
      "Std deviation             1.41                 1.41                \n",
      "Min prediction            1.00                 1.00                \n",
      "Max prediction            4.22                 4.22                \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "📊 User Overlap:\n",
      "   Users with Similarity predictions: 18\n",
      "   Users with DS predictions: 18\n",
      "   Common users: 18\n",
      "\n",
      "📊 Side-by-Side Predictions (sample of common users):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pred_similarity</th>\n",
       "      <th>pred_DS</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1FX5WML2MNIB9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOFYCGUQ902T8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1WWBC09BD8HU6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A37MU45KRK7FRI</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1L8S0K8PYSOAF</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A2X9ZF3P2CGASS</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A3LVZO0IYH7KCL</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A2LRF38ONJ6SC9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A1ADGBFYI7ECMD</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A1MQIVLGDBA9XH</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A15HC192R93222</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A1W2AD5O1O92GL</td>\n",
       "      <td>3.22</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A3IHA8X7DAVIUV</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A2S8OXQFW3858G</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A3IXJ3IUJNEX3H</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A1H8STNLQO0IA8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A1K7757DJH71LH</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A1P38ZY6P8U6BV</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  pred_similarity  pred_DS  difference\n",
       "0   A1FX5WML2MNIB9             1.00     1.00        0.00\n",
       "1    AOFYCGUQ902T8             1.00     1.00        0.00\n",
       "2   A1WWBC09BD8HU6             1.00     1.00        0.00\n",
       "3   A37MU45KRK7FRI             4.22     4.22        0.00\n",
       "4   A1L8S0K8PYSOAF             1.00     1.00        0.00\n",
       "5   A2X9ZF3P2CGASS             4.22     4.22        0.00\n",
       "6   A3LVZO0IYH7KCL             4.22     4.22        0.00\n",
       "7   A2LRF38ONJ6SC9             1.00     1.00        0.00\n",
       "8   A1ADGBFYI7ECMD             4.22     4.22        0.00\n",
       "9   A1MQIVLGDBA9XH             1.00     1.00        0.00\n",
       "10  A15HC192R93222             1.00     1.00        0.00\n",
       "11  A1W2AD5O1O92GL             3.22     3.22        0.00\n",
       "12  A3IHA8X7DAVIUV             1.00     1.00        0.00\n",
       "13  A2S8OXQFW3858G             1.00     1.00        0.00\n",
       "14  A3IXJ3IUJNEX3H             1.00     1.00        0.00\n",
       "15  A1H8STNLQO0IA8             1.00     1.00        0.00\n",
       "16  A1K7757DJH71LH             1.00     1.00        0.00\n",
       "17  A1P38ZY6P8U6BV             1.00     1.00        0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Difference Analysis:\n",
      "   Mean difference (DS - Similarity): 0.000\n",
      "   Mean absolute difference: 0.000\n",
      "\n",
      "======================================================================\n",
      "DISCUSSION\n",
      "======================================================================\n",
      "\n",
      "✅ SIMILAR PREDICTIONS: Both methods produce very similar predictions\n",
      "   (difference: 0.000).\n",
      "\n",
      "   This suggests that for this target item, the choice of neighbors\n",
      "   (by similarity vs DS) doesn't significantly impact prediction quality.\n",
      "   Both approaches are equally viable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_predictions(pred_sim_df, pred_ds_df, target_name):\n",
    "    \"\"\"Compare predictions from similarity vs DS-based neighbor selection.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"COMPARISON OF PREDICTIONS FOR {target_name}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if len(pred_sim_df) == 0 or len(pred_ds_df) == 0:\n",
    "        print(\"Not enough predictions to compare\")\n",
    "        return\n",
    "    \n",
    "    # Statistics comparison\n",
    "    print(\"\\n📊 Prediction Statistics:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Metric':<25} {'Similarity-Based':<20} {'DS-Based':<20}\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Number of predictions':<25} {len(pred_sim_df):<20} {len(pred_ds_df):<20}\")\n",
    "    print(f\"{'Mean prediction':<25} {pred_sim_df['predicted_rating'].mean():<20.2f} {pred_ds_df['predicted_rating'].mean():<20.2f}\")\n",
    "    print(f\"{'Std deviation':<25} {pred_sim_df['predicted_rating'].std():<20.2f} {pred_ds_df['predicted_rating'].std():<20.2f}\")\n",
    "    print(f\"{'Min prediction':<25} {pred_sim_df['predicted_rating'].min():<20.2f} {pred_ds_df['predicted_rating'].min():<20.2f}\")\n",
    "    print(f\"{'Max prediction':<25} {pred_sim_df['predicted_rating'].max():<20.2f} {pred_ds_df['predicted_rating'].max():<20.2f}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Find common users and compare their predictions\n",
    "    sim_users = set(pred_sim_df['user_id'])\n",
    "    ds_users = set(pred_ds_df['user_id'])\n",
    "    common_users = sim_users & ds_users\n",
    "    \n",
    "    print(f\"\\n📊 User Overlap:\")\n",
    "    print(f\"   Users with Similarity predictions: {len(sim_users)}\")\n",
    "    print(f\"   Users with DS predictions: {len(ds_users)}\")\n",
    "    print(f\"   Common users: {len(common_users)}\")\n",
    "    \n",
    "    if len(common_users) > 0:\n",
    "        # Compare predictions for common users\n",
    "        pred_sim_common = pred_sim_df[pred_sim_df['user_id'].isin(common_users)].set_index('user_id')\n",
    "        pred_ds_common = pred_ds_df[pred_ds_df['user_id'].isin(common_users)].set_index('user_id')\n",
    "        \n",
    "        comparison_df = pd.DataFrame({\n",
    "            'user_id': list(common_users)[:20],\n",
    "            'pred_similarity': [pred_sim_common.loc[u, 'predicted_rating'] for u in list(common_users)[:20]],\n",
    "            'pred_DS': [pred_ds_common.loc[u, 'predicted_rating'] for u in list(common_users)[:20]]\n",
    "        })\n",
    "        comparison_df['difference'] = comparison_df['pred_DS'] - comparison_df['pred_similarity']\n",
    "        \n",
    "        print(f\"\\n📊 Side-by-Side Predictions (sample of common users):\")\n",
    "        display(comparison_df)\n",
    "        \n",
    "        # Calculate difference statistics\n",
    "        mean_diff = comparison_df['difference'].mean()\n",
    "        abs_mean_diff = comparison_df['difference'].abs().mean()\n",
    "        \n",
    "        print(f\"\\n📊 Difference Analysis:\")\n",
    "        print(f\"   Mean difference (DS - Similarity): {mean_diff:.3f}\")\n",
    "        print(f\"   Mean absolute difference: {abs_mean_diff:.3f}\")\n",
    "    \n",
    "    # Commentary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DISCUSSION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    sim_mean = pred_sim_df['predicted_rating'].mean()\n",
    "    ds_mean = pred_ds_df['predicted_rating'].mean()\n",
    "    diff = ds_mean - sim_mean\n",
    "    \n",
    "    if abs(diff) < 0.1:\n",
    "        print(f\"\"\"\n",
    "✅ SIMILAR PREDICTIONS: Both methods produce very similar predictions\n",
    "   (difference: {diff:.3f}).\n",
    "   \n",
    "   This suggests that for this target item, the choice of neighbors\n",
    "   (by similarity vs DS) doesn't significantly impact prediction quality.\n",
    "   Both approaches are equally viable.\n",
    "\"\"\")\n",
    "    elif diff > 0:\n",
    "        print(f\"\"\"\n",
    "📈 DS PRODUCES HIGHER PREDICTIONS: DS-based predictions are higher by {diff:.3f} on average.\n",
    "   \n",
    "   This is expected because DS = similarity × avg_rating, which favors items\n",
    "   with both good similarity AND high ratings. These high-quality neighbors\n",
    "   tend to pull predictions upward.\n",
    "   \n",
    "   Implication: DS-based recommendations may be more optimistic but could\n",
    "   better reflect actual user preferences for quality items.\n",
    "\"\"\")\n",
    "    else:\n",
    "        print(f\"\"\"\n",
    "📉 SIMILARITY PRODUCES HIGHER PREDICTIONS: Similarity-based predictions are\n",
    "   higher by {abs(diff):.3f} on average.\n",
    "   \n",
    "   This occurs when highly similar items have relatively low ratings.\n",
    "   Pure similarity captures rating patterns regardless of rating level,\n",
    "   while DS penalizes low-rated similar items.\n",
    "   \n",
    "   Implication: Similarity-based may overestimate for low-rated target items,\n",
    "   while DS provides more conservative estimates.\n",
    "\"\"\")\n",
    "\n",
    "# Compare predictions for I1\n",
    "compare_predictions(I1_predictions_df, I1_predictions_ds_df, f\"I1 ({I1_id})\")\n",
    "\n",
    "# Compare predictions for I2\n",
    "print(\"\\n\")\n",
    "compare_predictions(I2_predictions_df, I2_predictions_ds_df, f\"I2 ({I2_id})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908290af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Case Study 2: Cosine Similarity WITHOUT Mean-Centering\n",
    "\n",
    "**Purpose:** Compare with Case Study 1 to understand the impact of mean-centering on predictions.\n",
    "\n",
    "**Tasks:**\n",
    "1. Compute Cosine similarity using raw ratings (no mean-centering)\n",
    "2. Identify top 20% similar items\n",
    "3. Predict missing ratings\n",
    "4. Compute DF and DS\n",
    "5. Select top 20% by DS\n",
    "6. Predict with DS-selected items\n",
    "7. Compare item lists\n",
    "8. Compare predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a37013d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Study 2 similarity function defined (NO mean-centering)!\n"
     ]
    }
   ],
   "source": [
    "# Case Study 2: Cosine Similarity WITHOUT Mean-Centering\n",
    "# Create raw (non-centered) item-user ratings lookup\n",
    "item_user_raw_ratings = ratings.groupby(['item_id', 'user_id'])['rating'].mean().reset_index()\n",
    "\n",
    "def compute_item_similarity_cosine_raw(target_item_id, item_user_ratings_df, item_users_dict):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity using RAW ratings (no mean-centering).\n",
    "    \"\"\"\n",
    "    target_users = item_users_dict.get(target_item_id, set())\n",
    "    \n",
    "    if len(target_users) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    candidate_items = set()\n",
    "    for item_id, users in item_users_dict.items():\n",
    "        if item_id != target_item_id and len(target_users & users) > 0:\n",
    "            candidate_items.add(item_id)\n",
    "    \n",
    "    print(f\"Target item {target_item_id} has {len(target_users)} raters\")\n",
    "    print(f\"Found {len(candidate_items)} items with common raters\")\n",
    "    \n",
    "    if len(candidate_items) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    target_ratings = item_user_ratings_df[item_user_ratings_df['item_id'] == target_item_id].set_index('user_id')['rating']\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for candidate_id in candidate_items:\n",
    "        candidate_ratings = item_user_ratings_df[item_user_ratings_df['item_id'] == candidate_id].set_index('user_id')['rating']\n",
    "        common_users = list(set(target_ratings.index) & set(candidate_ratings.index))\n",
    "        \n",
    "        if len(common_users) < 1:\n",
    "            continue\n",
    "        \n",
    "        target_vec = target_ratings.loc[common_users].values\n",
    "        candidate_vec = candidate_ratings.loc[common_users].values\n",
    "        \n",
    "        dot_product = np.dot(target_vec, candidate_vec)\n",
    "        norm_target = np.linalg.norm(target_vec)\n",
    "        norm_candidate = np.linalg.norm(candidate_vec)\n",
    "        \n",
    "        if norm_target > 0 and norm_candidate > 0:\n",
    "            similarity = dot_product / (norm_target * norm_candidate)\n",
    "        else:\n",
    "            similarity = 0\n",
    "        \n",
    "        similarities.append({\n",
    "            'item_id': candidate_id,\n",
    "            'similarity': round(similarity, 4),\n",
    "            'common_users': len(common_users)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(similarities).sort_values('similarity', ascending=False)\n",
    "\n",
    "print(\"Case Study 2 similarity function defined (NO mean-centering)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb75ddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CASE STUDY 2: Computing similarities WITHOUT mean-centering\n",
      "============================================================\n",
      "\n",
      "Computing similarities for I1...\n",
      "Target item B00S33PD6W has 73 raters\n",
      "Found 4 items with common raters\n",
      "\n",
      "Computing similarities for I2...\n",
      "Target item B00DO4LN82 has 62 raters\n",
      "Found 3 items with common raters\n",
      "\n",
      "============================================================\n",
      "CS2 SIMILARITY RESULTS (No Mean-Centering)\n",
      "============================================================\n",
      "I1 (B00S33PD6W): 4 similar items found\n",
      "I2 (B00DO4LN82): 3 similar items found\n",
      "\n",
      "Top 10 similarities for I1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S33PKFG</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00S5O5E2M</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00S5O5ALM</td>\n",
       "      <td>1.00</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00CO0HXN6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users\n",
       "0  B00S33PKFG        1.00             4\n",
       "1  B00S5O5E2M        1.00             2\n",
       "2  B00S5O5ALM        1.00            29\n",
       "3  B00CO0HXN6        1.00             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 similarities for I2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00DO4LM9C</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B01BO915S6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users\n",
       "0  B00FMJGZTO        1.00             6\n",
       "1  B00DO4LM9C        1.00             2\n",
       "2  B01BO915S6        1.00             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CS2 Task 1: Compute similarities (no mean-centering)\n",
    "print(\"=\" * 60)\n",
    "print(\"CASE STUDY 2: Computing similarities WITHOUT mean-centering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nComputing similarities for I1...\")\n",
    "CS2_I1_similarities = compute_item_similarity_cosine_raw(I1_id, item_user_raw_ratings, item_users)\n",
    "\n",
    "print(\"\\nComputing similarities for I2...\")\n",
    "CS2_I2_similarities = compute_item_similarity_cosine_raw(I2_id, item_user_raw_ratings, item_users)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CS2 SIMILARITY RESULTS (No Mean-Centering)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"I1 ({I1_id}): {len(CS2_I1_similarities)} similar items found\")\n",
    "print(f\"I2 ({I2_id}): {len(CS2_I2_similarities)} similar items found\")\n",
    "\n",
    "if len(CS2_I1_similarities) > 0:\n",
    "    print(f\"\\nTop 10 similarities for I1:\")\n",
    "    display(CS2_I1_similarities.head(10))\n",
    "\n",
    "if len(CS2_I2_similarities) > 0:\n",
    "    print(f\"\\nTop 10 similarities for I2:\")\n",
    "    display(CS2_I2_similarities.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "500e53bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS2 Task 2 - Top 20% by Similarity: I1=1, I2=1\n",
      "\n",
      "CS2 Task 3 - Predictions (Similarity-based):\n",
      "  I1: Mean=1.85, Std=1.63\n",
      "  I2: Mean=2.06, Std=1.76\n",
      "\n",
      "CS2 Task 5 - Top 20% by DS: I1=1, I2=1\n",
      "\n",
      "CS2 Task 6 - Predictions (DS-based):\n",
      "  I1: Mean=1.85, Std=1.63\n",
      "  I2: Mean=4.88, Std=0.64\n"
     ]
    }
   ],
   "source": [
    "# CS2 Tasks 2-8: Complete analysis for Case Study 2\n",
    "\n",
    "# Task 2: Top 20% by similarity\n",
    "CS2_I1_top20_sim = get_top_percent_similar_items(CS2_I1_similarities, 0.20)\n",
    "CS2_I2_top20_sim = get_top_percent_similar_items(CS2_I2_similarities, 0.20)\n",
    "print(f\"CS2 Task 2 - Top 20% by Similarity: I1={len(CS2_I1_top20_sim)}, I2={len(CS2_I2_top20_sim)}\")\n",
    "\n",
    "# Task 3: Predict ratings using raw similarity (no mean-centering in prediction)\n",
    "def predict_rating_no_mean_centering(user_id, target_item_id, similar_items_df, user_item_ratings):\n",
    "    \"\"\"Predict rating WITHOUT mean-centering (weighted average of raw ratings).\"\"\"\n",
    "    if len(similar_items_df) == 0:\n",
    "        return 3.0  # Default to neutral\n",
    "    \n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    for _, row in similar_items_df.iterrows():\n",
    "        similar_item_id = row['item_id']\n",
    "        similarity = row['similarity']\n",
    "        rating = user_item_ratings.get((user_id, similar_item_id), None)\n",
    "        \n",
    "        if rating is not None:\n",
    "            numerator += similarity * rating\n",
    "            denominator += abs(similarity)\n",
    "    \n",
    "    if denominator > 0:\n",
    "        prediction = numerator / denominator\n",
    "        return max(1, min(5, round(prediction, 2)))\n",
    "    return 3.0\n",
    "\n",
    "CS2_I1_users = get_users_to_predict(I1_id, CS2_I1_top20_sim, ratings)\n",
    "CS2_I2_users = get_users_to_predict(I2_id, CS2_I2_top20_sim, ratings)\n",
    "\n",
    "CS2_I1_preds_sim = []\n",
    "for user_id in CS2_I1_users[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_no_mean_centering(user_id, I1_id, CS2_I1_top20_sim, user_item_ratings)\n",
    "    CS2_I1_preds_sim.append({'user_id': user_id, 'item_id': I1_id, 'predicted_rating': pred})\n",
    "CS2_I1_preds_sim_df = pd.DataFrame(CS2_I1_preds_sim)\n",
    "\n",
    "CS2_I2_preds_sim = []\n",
    "for user_id in CS2_I2_users[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_no_mean_centering(user_id, I2_id, CS2_I2_top20_sim, user_item_ratings)\n",
    "    CS2_I2_preds_sim.append({'user_id': user_id, 'item_id': I2_id, 'predicted_rating': pred})\n",
    "CS2_I2_preds_sim_df = pd.DataFrame(CS2_I2_preds_sim)\n",
    "\n",
    "print(f\"\\nCS2 Task 3 - Predictions (Similarity-based):\")\n",
    "if len(CS2_I1_preds_sim_df) > 0:\n",
    "    print(f\"  I1: Mean={CS2_I1_preds_sim_df['predicted_rating'].mean():.2f}, Std={CS2_I1_preds_sim_df['predicted_rating'].std():.2f}\")\n",
    "if len(CS2_I2_preds_sim_df) > 0:\n",
    "    print(f\"  I2: Mean={CS2_I2_preds_sim_df['predicted_rating'].mean():.2f}, Std={CS2_I2_preds_sim_df['predicted_rating'].std():.2f}\")\n",
    "\n",
    "# Task 4: Compute DS\n",
    "CS2_I1_ds = compute_df_ds(CS2_I1_similarities, item_means_dict)\n",
    "CS2_I2_ds = compute_df_ds(CS2_I2_similarities, item_means_dict)\n",
    "\n",
    "# Task 5: Top 20% by DS\n",
    "CS2_I1_top20_ds = get_top_percent_by_ds(CS2_I1_ds, 0.20)\n",
    "CS2_I2_top20_ds = get_top_percent_by_ds(CS2_I2_ds, 0.20)\n",
    "print(f\"\\nCS2 Task 5 - Top 20% by DS: I1={len(CS2_I1_top20_ds)}, I2={len(CS2_I2_top20_ds)}\")\n",
    "\n",
    "# Task 6: Predict with DS-selected items\n",
    "CS2_I1_users_ds = get_users_to_predict(I1_id, CS2_I1_top20_ds, ratings)\n",
    "CS2_I2_users_ds = get_users_to_predict(I2_id, CS2_I2_top20_ds, ratings)\n",
    "\n",
    "CS2_I1_preds_ds = []\n",
    "for user_id in CS2_I1_users_ds[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_no_mean_centering(user_id, I1_id, CS2_I1_top20_ds, user_item_ratings)\n",
    "    CS2_I1_preds_ds.append({'user_id': user_id, 'item_id': I1_id, 'predicted_rating': pred})\n",
    "CS2_I1_preds_ds_df = pd.DataFrame(CS2_I1_preds_ds)\n",
    "\n",
    "CS2_I2_preds_ds = []\n",
    "for user_id in CS2_I2_users_ds[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_no_mean_centering(user_id, I2_id, CS2_I2_top20_ds, user_item_ratings)\n",
    "    CS2_I2_preds_ds.append({'user_id': user_id, 'item_id': I2_id, 'predicted_rating': pred})\n",
    "CS2_I2_preds_ds_df = pd.DataFrame(CS2_I2_preds_ds)\n",
    "\n",
    "print(f\"\\nCS2 Task 6 - Predictions (DS-based):\")\n",
    "if len(CS2_I1_preds_ds_df) > 0:\n",
    "    print(f\"  I1: Mean={CS2_I1_preds_ds_df['predicted_rating'].mean():.2f}, Std={CS2_I1_preds_ds_df['predicted_rating'].std():.2f}\")\n",
    "if len(CS2_I2_preds_ds_df) > 0:\n",
    "    print(f\"  I2: Mean={CS2_I2_preds_ds_df['predicted_rating'].mean():.2f}, Std={CS2_I2_preds_ds_df['predicted_rating'].std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86b5107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CS2 TASK 7: COMPARE ITEM LISTS (Similarity vs DS)\n",
      "======================================================================\n",
      "\n",
      "I1 Item Lists:\n",
      "  By Similarity: {'B00S33PKFG'}\n",
      "  By DS: {'B00S33PKFG'}\n",
      "  Overlap: 1/1 items\n",
      "\n",
      "I2 Item Lists:\n",
      "  By Similarity: {'B00FMJGZTO'}\n",
      "  By DS: {'B01BO915S6'}\n",
      "  Overlap: 0/1 items\n",
      "\n",
      "======================================================================\n",
      "CS2 TASK 8: COMPARE PREDICTIONS (Similarity vs DS)\n",
      "======================================================================\n",
      "\n",
      "I1 Predictions:\n",
      "  Similarity-based: Mean=1.85\n",
      "  DS-based: Mean=1.85\n",
      "  Difference: 0.000\n",
      "\n",
      "I2 Predictions:\n",
      "  Similarity-based: Mean=2.06\n",
      "  DS-based: Mean=4.88\n",
      "  Difference: 2.824\n",
      "\n",
      "======================================================================\n",
      "CS2 ANALYSIS: Impact of NO Mean-Centering\n",
      "======================================================================\n",
      "\n",
      "Without mean-centering:\n",
      "- Raw cosine similarity tends to be HIGH for all items (all ratings are positive)\n",
      "- DS selection can pick items with high avg ratings (biased toward popular items)\n",
      "- Predictions can deviate significantly from item's actual quality\n",
      "- For low-rated target items, predictions may be unrealistically high\n",
      "\n",
      "This contrasts with Case Study 1 (with mean-centering) where predictions\n",
      "are anchored to the target item's mean rating.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CS2 Tasks 7-8: Comparisons\n",
    "\n",
    "# Task 7: Compare item lists (Similarity vs DS)\n",
    "print(\"=\" * 70)\n",
    "print(\"CS2 TASK 7: COMPARE ITEM LISTS (Similarity vs DS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "CS2_I1_sim_set = set(CS2_I1_top20_sim['item_id']) if len(CS2_I1_top20_sim) > 0 else set()\n",
    "CS2_I1_ds_set = set(CS2_I1_top20_ds['item_id']) if len(CS2_I1_top20_ds) > 0 else set()\n",
    "CS2_I1_overlap = len(CS2_I1_sim_set & CS2_I1_ds_set)\n",
    "\n",
    "CS2_I2_sim_set = set(CS2_I2_top20_sim['item_id']) if len(CS2_I2_top20_sim) > 0 else set()\n",
    "CS2_I2_ds_set = set(CS2_I2_top20_ds['item_id']) if len(CS2_I2_top20_ds) > 0 else set()\n",
    "CS2_I2_overlap = len(CS2_I2_sim_set & CS2_I2_ds_set)\n",
    "\n",
    "print(f\"\\nI1 Item Lists:\")\n",
    "print(f\"  By Similarity: {CS2_I1_sim_set}\")\n",
    "print(f\"  By DS: {CS2_I1_ds_set}\")\n",
    "print(f\"  Overlap: {CS2_I1_overlap}/{max(len(CS2_I1_sim_set), 1)} items\")\n",
    "\n",
    "print(f\"\\nI2 Item Lists:\")\n",
    "print(f\"  By Similarity: {CS2_I2_sim_set}\")\n",
    "print(f\"  By DS: {CS2_I2_ds_set}\")\n",
    "print(f\"  Overlap: {CS2_I2_overlap}/{max(len(CS2_I2_sim_set), 1)} items\")\n",
    "\n",
    "# Task 8: Compare predictions\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CS2 TASK 8: COMPARE PREDICTIONS (Similarity vs DS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nI1 Predictions:\")\n",
    "if len(CS2_I1_preds_sim_df) > 0 and len(CS2_I1_preds_ds_df) > 0:\n",
    "    print(f\"  Similarity-based: Mean={CS2_I1_preds_sim_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"  DS-based: Mean={CS2_I1_preds_ds_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"  Difference: {CS2_I1_preds_ds_df['predicted_rating'].mean() - CS2_I1_preds_sim_df['predicted_rating'].mean():.3f}\")\n",
    "else:\n",
    "    print(\"  Insufficient predictions to compare\")\n",
    "\n",
    "print(\"\\nI2 Predictions:\")\n",
    "if len(CS2_I2_preds_sim_df) > 0 and len(CS2_I2_preds_ds_df) > 0:\n",
    "    print(f\"  Similarity-based: Mean={CS2_I2_preds_sim_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"  DS-based: Mean={CS2_I2_preds_ds_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"  Difference: {CS2_I2_preds_ds_df['predicted_rating'].mean() - CS2_I2_preds_sim_df['predicted_rating'].mean():.3f}\")\n",
    "else:\n",
    "    print(\"  Insufficient predictions to compare\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CS2 ANALYSIS: Impact of NO Mean-Centering\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Without mean-centering:\n",
    "- Raw cosine similarity tends to be HIGH for all items (all ratings are positive)\n",
    "- DS selection can pick items with high avg ratings (biased toward popular items)\n",
    "- Predictions can deviate significantly from item's actual quality\n",
    "- For low-rated target items, predictions may be unrealistically high\n",
    "\n",
    "This contrasts with Case Study 1 (with mean-centering) where predictions\n",
    "are anchored to the target item's mean rating.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10f370",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Case Study 3: Pearson Correlation Coefficient (PCC)\n",
    "\n",
    "**Tasks:**\n",
    "1. Use PCC to compute similarity between target items\n",
    "2. Identify the top 20% most similar items\n",
    "3. Predict the missing ratings\n",
    "4. Compute DF and DS using threshold β\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea70d2",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 1: Compute Similarity Using PCC\n",
    "\n",
    "Pearson Correlation Coefficient (PCC) measures the linear correlation between two items based on their ratings from common users.\n",
    "\n",
    "$$PCC(i,j) = \\frac{\\sum_{u \\in U_{ij}} (r_{ui} - \\bar{r}_i)(r_{uj} - \\bar{r}_j)}{\\sqrt{\\sum_{u \\in U_{ij}} (r_{ui} - \\bar{r}_i)^2} \\sqrt{\\sum_{u \\in U_{ij}} (r_{uj} - \\bar{r}_j)^2}}$$\n",
    "\n",
    "Where $U_{ij}$ is the set of users who rated both items i and j.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0beb9ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC similarity function defined!\n"
     ]
    }
   ],
   "source": [
    "def compute_item_similarity_pcc(target_item_id, item_user_ratings_df, item_users_dict, item_means_dict):\n",
    "    \"\"\"\n",
    "    Compute Pearson Correlation Coefficient (PCC) between target item and all co-rated items.\n",
    "    \"\"\"\n",
    "    # Get users who rated the target item\n",
    "    target_users = item_users_dict.get(target_item_id, set())\n",
    "    \n",
    "    if len(target_users) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Find items that share at least one common rater\n",
    "    candidate_items = set()\n",
    "    for item_id, users in item_users_dict.items():\n",
    "        if item_id != target_item_id and len(target_users & users) > 0:\n",
    "            candidate_items.add(item_id)\n",
    "    \n",
    "    print(f\"Target item {target_item_id} has {len(target_users)} raters\")\n",
    "    print(f\"Found {len(candidate_items)} items with common raters\")\n",
    "    \n",
    "    if len(candidate_items) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get ratings for target item\n",
    "    target_ratings = item_user_ratings_df[item_user_ratings_df['item_id'] == target_item_id].set_index('user_id')['rating_centered']\n",
    "    target_mean = item_means_dict.get(target_item_id, 3.0)\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for candidate_id in candidate_items:\n",
    "        # Get ratings for candidate item\n",
    "        candidate_ratings = item_user_ratings_df[item_user_ratings_df['item_id'] == candidate_id].set_index('user_id')['rating_centered']\n",
    "        candidate_mean = item_means_dict.get(candidate_id, 3.0)\n",
    "        \n",
    "        # Find common users\n",
    "        common_users = list(set(target_ratings.index) & set(candidate_ratings.index))\n",
    "        \n",
    "        if len(common_users) < 2:  # Need at least 2 common users for PCC\n",
    "            continue\n",
    "        \n",
    "        # Get rating vectors for common users (mean-centered)\n",
    "        target_vec = target_ratings.loc[common_users].values\n",
    "        candidate_vec = candidate_ratings.loc[common_users].values\n",
    "        \n",
    "        # Compute PCC\n",
    "        # Since we already have mean-centered ratings, PCC = correlation of centered values\n",
    "        numerator = np.sum(target_vec * candidate_vec)\n",
    "        denominator = np.sqrt(np.sum(target_vec**2)) * np.sqrt(np.sum(candidate_vec**2))\n",
    "        \n",
    "        if denominator > 0:\n",
    "            pcc = numerator / denominator\n",
    "        else:\n",
    "            pcc = 0\n",
    "        \n",
    "        similarities.append({\n",
    "            'item_id': candidate_id,\n",
    "            'similarity': round(pcc, 4),\n",
    "            'common_users': len(common_users)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(similarities).sort_values('similarity', ascending=False)\n",
    "\n",
    "print(\"PCC similarity function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0729c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CASE STUDY 3: Computing PCC Similarities for I1...\n",
      "============================================================\n",
      "Target item B00S33PD6W has 73 raters\n",
      "Found 4 items with common raters\n",
      "\n",
      "============================================================\n",
      "Computing PCC Similarities for I2...\n",
      "============================================================\n",
      "Target item B00DO4LN82 has 62 raters\n",
      "Found 3 items with common raters\n",
      "\n",
      "============================================================\n",
      "PCC SIMILARITY RESULTS\n",
      "============================================================\n",
      "\n",
      "I1 (B00S33PD6W): 3 similar items found\n",
      "I2 (B00DO4LN82): 2 similar items found\n",
      "\n",
      "Top 10 PCC similarities for I1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S33PKFG</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00S5O5E2M</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00S5O5ALM</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users\n",
       "0  B00S33PKFG           0             4\n",
       "1  B00S5O5E2M           0             2\n",
       "2  B00S5O5ALM           0            29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 PCC similarities for I2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00DO4LM9C</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users\n",
       "0  B00FMJGZTO        1.00             6\n",
       "1  B00DO4LM9C        0.00             2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute PCC similarities for target items I1 and I2\n",
    "print(\"=\" * 60)\n",
    "print(\"CASE STUDY 3: Computing PCC Similarities for I1...\")\n",
    "print(\"=\" * 60)\n",
    "I1_pcc_similarities = compute_item_similarity_pcc(I1_id, item_user_centered_ratings, item_users, item_means_dict)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Computing PCC Similarities for I2...\")\n",
    "print(\"=\" * 60)\n",
    "I2_pcc_similarities = compute_item_similarity_pcc(I2_id, item_user_centered_ratings, item_users, item_means_dict)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PCC SIMILARITY RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nI1 ({I1_id}): {len(I1_pcc_similarities)} similar items found\")\n",
    "print(f\"I2 ({I2_id}): {len(I2_pcc_similarities)} similar items found\")\n",
    "\n",
    "# Display top similarities\n",
    "if len(I1_pcc_similarities) > 0:\n",
    "    print(f\"\\nTop 10 PCC similarities for I1:\")\n",
    "    display(I1_pcc_similarities.head(10))\n",
    "\n",
    "if len(I2_pcc_similarities) > 0:\n",
    "    print(f\"\\nTop 10 PCC similarities for I2:\")\n",
    "    display(I2_pcc_similarities.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd8c6d",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 2: Identify Top 20% Most Similar Items (PCC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3daef6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOP 20% SIMILAR ITEMS BY PCC FOR I1 (B00S33PD6W)\n",
      "============================================================\n",
      "Total similar items: 3\n",
      "Top 20% count: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S33PKFG</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users\n",
       "0  B00S33PKFG           0             4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOP 20% SIMILAR ITEMS BY PCC FOR I2 (B00DO4LN82)\n",
      "============================================================\n",
      "Total similar items: 2\n",
      "Top 20% count: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users\n",
       "0  B00FMJGZTO        1.00             6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select top 20% of similar items by PCC\n",
    "I1_pcc_top20 = get_top_percent_similar_items(I1_pcc_similarities, 0.20)\n",
    "I2_pcc_top20 = get_top_percent_similar_items(I2_pcc_similarities, 0.20)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"TOP 20% SIMILAR ITEMS BY PCC FOR I1 ({I1_id})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total similar items: {len(I1_pcc_similarities)}\")\n",
    "print(f\"Top 20% count: {len(I1_pcc_top20)}\")\n",
    "if len(I1_pcc_top20) > 0:\n",
    "    display(I1_pcc_top20)\n",
    "else:\n",
    "    print(\"No similar items found for I1\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"TOP 20% SIMILAR ITEMS BY PCC FOR I2 ({I2_id})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total similar items: {len(I2_pcc_similarities)}\")\n",
    "print(f\"Top 20% count: {len(I2_pcc_top20)}\")\n",
    "if len(I2_pcc_top20) > 0:\n",
    "    display(I2_pcc_top20)\n",
    "else:\n",
    "    print(\"No similar items found for I2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78577cf3",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 3: Predict Missing Ratings Using PCC Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4f5ac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users to predict for I1 (using PCC neighbors): 13\n",
      "Users to predict for I2 (using PCC neighbors): 18\n",
      "\n",
      "============================================================\n",
      "PCC-BASED PREDICTED RATINGS FOR I1 (B00S33PD6W)\n",
      "============================================================\n",
      "Number of predictions: 13\n",
      "Mean predicted rating: 1.00\n",
      "Std of predictions: 0.00\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2D15NAO51QH1M</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A22UAYQBS3KQWA</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1HCPG8M6WOV0E</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1O0UYJPK96BKK</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1WFTDD0V5FTNG</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A3VIXQI771ZTCT</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A14OXNXWNX2STM</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1HY6GQ6Y5ERBU</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A3UXLGWN2CX27W</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AXVTOFDNLTHWF</td>\n",
       "      <td>B00S33PD6W</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     item_id  predicted_rating\n",
       "0  A2D15NAO51QH1M  B00S33PD6W              1.00\n",
       "1  A22UAYQBS3KQWA  B00S33PD6W              1.00\n",
       "2  A1HCPG8M6WOV0E  B00S33PD6W              1.00\n",
       "3  A1O0UYJPK96BKK  B00S33PD6W              1.00\n",
       "4  A1WFTDD0V5FTNG  B00S33PD6W              1.00\n",
       "5  A3VIXQI771ZTCT  B00S33PD6W              1.00\n",
       "6  A14OXNXWNX2STM  B00S33PD6W              1.00\n",
       "7  A1HY6GQ6Y5ERBU  B00S33PD6W              1.00\n",
       "8  A3UXLGWN2CX27W  B00S33PD6W              1.00\n",
       "9   AXVTOFDNLTHWF  B00S33PD6W              1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PCC-BASED PREDICTED RATINGS FOR I2 (B00DO4LN82)\n",
      "============================================================\n",
      "Number of predictions: 18\n",
      "Mean predicted rating: 1.84\n",
      "Std of predictions: 1.41\n",
      "\n",
      "Sample predictions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1FX5WML2MNIB9</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOFYCGUQ902T8</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1WWBC09BD8HU6</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A37MU45KRK7FRI</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1L8S0K8PYSOAF</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A2X9ZF3P2CGASS</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A3LVZO0IYH7KCL</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1W2AD5O1O92GL</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A1ADGBFYI7ECMD</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A1MQIVLGDBA9XH</td>\n",
       "      <td>B00DO4LN82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     item_id  predicted_rating\n",
       "0  A1FX5WML2MNIB9  B00DO4LN82              1.00\n",
       "1   AOFYCGUQ902T8  B00DO4LN82              1.00\n",
       "2  A1WWBC09BD8HU6  B00DO4LN82              1.00\n",
       "3  A37MU45KRK7FRI  B00DO4LN82              4.22\n",
       "4  A1L8S0K8PYSOAF  B00DO4LN82              1.00\n",
       "5  A2X9ZF3P2CGASS  B00DO4LN82              4.22\n",
       "6  A3LVZO0IYH7KCL  B00DO4LN82              4.22\n",
       "7  A1W2AD5O1O92GL  B00DO4LN82              3.22\n",
       "8  A1ADGBFYI7ECMD  B00DO4LN82              4.22\n",
       "9  A1MQIVLGDBA9XH  B00DO4LN82              1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get users to predict for PCC-based neighbors\n",
    "I1_users_pcc = get_users_to_predict(I1_id, I1_pcc_top20, ratings)\n",
    "I2_users_pcc = get_users_to_predict(I2_id, I2_pcc_top20, ratings)\n",
    "\n",
    "print(f\"Users to predict for I1 (using PCC neighbors): {len(I1_users_pcc)}\")\n",
    "print(f\"Users to predict for I2 (using PCC neighbors): {len(I2_users_pcc)}\")\n",
    "\n",
    "# Predictions for I1 using PCC neighbors\n",
    "I1_pcc_predictions = []\n",
    "for user_id in I1_users_pcc[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_item_based(user_id, I1_id, I1_pcc_top20, item_means_dict, user_item_ratings)\n",
    "    I1_pcc_predictions.append({\n",
    "        'user_id': user_id,\n",
    "        'item_id': I1_id,\n",
    "        'predicted_rating': pred\n",
    "    })\n",
    "\n",
    "I1_pcc_predictions_df = pd.DataFrame(I1_pcc_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"PCC-BASED PREDICTED RATINGS FOR I1 ({I1_id})\")\n",
    "print(\"=\" * 60)\n",
    "if len(I1_pcc_predictions_df) > 0:\n",
    "    print(f\"Number of predictions: {len(I1_pcc_predictions_df)}\")\n",
    "    print(f\"Mean predicted rating: {I1_pcc_predictions_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"Std of predictions: {I1_pcc_predictions_df['predicted_rating'].std():.2f}\")\n",
    "    print(\"\\nSample predictions:\")\n",
    "    display(I1_pcc_predictions_df.head(10))\n",
    "else:\n",
    "    print(\"No predictions possible for I1\")\n",
    "\n",
    "# Predictions for I2 using PCC neighbors\n",
    "I2_pcc_predictions = []\n",
    "for user_id in I2_users_pcc[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_item_based(user_id, I2_id, I2_pcc_top20, item_means_dict, user_item_ratings)\n",
    "    I2_pcc_predictions.append({\n",
    "        'user_id': user_id,\n",
    "        'item_id': I2_id,\n",
    "        'predicted_rating': pred\n",
    "    })\n",
    "\n",
    "I2_pcc_predictions_df = pd.DataFrame(I2_pcc_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"PCC-BASED PREDICTED RATINGS FOR I2 ({I2_id})\")\n",
    "print(\"=\" * 60)\n",
    "if len(I2_pcc_predictions_df) > 0:\n",
    "    print(f\"Number of predictions: {len(I2_pcc_predictions_df)}\")\n",
    "    print(f\"Mean predicted rating: {I2_pcc_predictions_df['predicted_rating'].mean():.2f}\")\n",
    "    print(f\"Std of predictions: {I2_pcc_predictions_df['predicted_rating'].std():.2f}\")\n",
    "    print(\"\\nSample predictions:\")\n",
    "    display(I2_pcc_predictions_df.head(10))\n",
    "else:\n",
    "    print(\"No predictions possible for I2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761df793",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 4: Compute DF and DS Using Threshold β\n",
    "\n",
    "**Threshold β:** Filter similar items based on minimum common users (co-raters).\n",
    "\n",
    "- **DF (Discount Factor):** PCC similarity score\n",
    "- **DS (Discount Similarity):** PCC × Average Rating, filtered by β threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1c85383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPUTING DF AND DS WITH β THRESHOLD = 5\n",
      "======================================================================\n",
      "\n",
      "--- I1 (B00S33PD6W) ---\n",
      "Items before β filtering: 3\n",
      "β threshold (min common users): 5\n",
      "Items after β filtering: 1\n",
      "\n",
      "DF & DS Results for I1 (filtered by β):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>DF</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S5O5ALM</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users  avg_rating  DF   DS\n",
       "0  B00S5O5ALM           0            29        1.09   0 0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- I2 (B00DO4LN82) ---\n",
      "Items before β filtering: 2\n",
      "β threshold (min common users): 5\n",
      "Items after β filtering: 1\n",
      "\n",
      "DF & DS Results for I2 (filtered by β):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>DF</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users  avg_rating   DF   DS\n",
       "0  B00FMJGZTO        1.00             6        1.79 1.00 1.79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define threshold β - minimum number of common users required\n",
    "# Using β as percentage of target item's raters (e.g., 30% as in Section 1)\n",
    "def compute_df_ds_with_beta(similar_items_df, item_means_dict, beta_threshold):\n",
    "    \"\"\"\n",
    "    Compute DF and DS with threshold β filtering.\n",
    "    \n",
    "    β threshold: minimum number of common users required for reliable similarity\n",
    "    \"\"\"\n",
    "    if len(similar_items_df) == 0:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # Filter items meeting β threshold\n",
    "    filtered_items = similar_items_df[similar_items_df['common_users'] >= beta_threshold].copy()\n",
    "    \n",
    "    print(f\"Items before β filtering: {len(similar_items_df)}\")\n",
    "    print(f\"β threshold (min common users): {beta_threshold}\")\n",
    "    print(f\"Items after β filtering: {len(filtered_items)}\")\n",
    "    \n",
    "    if len(filtered_items) == 0:\n",
    "        return pd.DataFrame(), similar_items_df\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, row in filtered_items.iterrows():\n",
    "        item_id = row['item_id']\n",
    "        similarity = row['similarity']\n",
    "        common_users = row['common_users']\n",
    "        \n",
    "        # Get average rating of the similar item\n",
    "        avg_rating = item_means_dict.get(item_id, 3.0)\n",
    "        \n",
    "        # DF: PCC similarity score\n",
    "        df = similarity\n",
    "        \n",
    "        # DS: PCC × average rating\n",
    "        ds = similarity * avg_rating\n",
    "        \n",
    "        results.append({\n",
    "            'item_id': item_id,\n",
    "            'similarity': similarity,  # Use 'similarity' to match prediction function\n",
    "            'common_users': common_users,\n",
    "            'avg_rating': round(avg_rating, 2),\n",
    "            'DF': round(df, 4),\n",
    "            'DS': round(ds, 4)\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results).sort_values('DS', ascending=False)\n",
    "    return results_df, similar_items_df\n",
    "\n",
    "# Set β threshold - minimum 5 common users for reliable PCC\n",
    "BETA_THRESHOLD = 5\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"COMPUTING DF AND DS WITH β THRESHOLD = {BETA_THRESHOLD}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Compute for I1\n",
    "print(f\"\\n--- I1 ({I1_id}) ---\")\n",
    "I1_pcc_df_ds, I1_pcc_all = compute_df_ds_with_beta(I1_pcc_similarities, item_means_dict, BETA_THRESHOLD)\n",
    "\n",
    "if len(I1_pcc_df_ds) > 0:\n",
    "    print(f\"\\nDF & DS Results for I1 (filtered by β):\")\n",
    "    display(I1_pcc_df_ds.head(20))\n",
    "else:\n",
    "    print(\"No items meet the β threshold for I1\")\n",
    "\n",
    "# Compute for I2\n",
    "print(f\"\\n--- I2 ({I2_id}) ---\")\n",
    "I2_pcc_df_ds, I2_pcc_all = compute_df_ds_with_beta(I2_pcc_similarities, item_means_dict, BETA_THRESHOLD)\n",
    "\n",
    "if len(I2_pcc_df_ds) > 0:\n",
    "    print(f\"\\nDF & DS Results for I2 (filtered by β):\")\n",
    "    display(I2_pcc_df_ds.head(20))\n",
    "else:\n",
    "    print(\"No items meet the β threshold for I2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36929e1",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 5: Select Top 20% Items Based on DS (Discounted Similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f308d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CS3 TASK 5: Computing DS for PCC Similarities\n",
      "============================================================\n",
      "\n",
      "--- I1 (B00S33PD6W) ---\n",
      "Items after β≥5 filtering: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00S5O5ALM</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users  avg_rating   DS\n",
       "0  B00S5O5ALM           0            29        1.09 0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- I2 (B00DO4LN82) ---\n",
      "Items after β≥5 filtering: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>common_users</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00FMJGZTO</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  similarity  common_users  avg_rating   DS\n",
       "0  B00FMJGZTO        1.00             6        1.79 1.79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20% by DS:\n",
      "  I1: 1 items selected\n",
      "  I2: 1 items selected\n"
     ]
    }
   ],
   "source": [
    "# CS3 Task 5: Select top 20% items based on DS (Discounted Similarity)\n",
    "\n",
    "# First compute DS for all PCC similarities (with β threshold)\n",
    "BETA_THRESHOLD = 5\n",
    "\n",
    "def compute_pcc_ds(similar_items_df, item_means_dict, beta_threshold):\n",
    "    \"\"\"Compute DS for PCC similarities with β threshold filtering.\"\"\"\n",
    "    if len(similar_items_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Filter by β threshold\n",
    "    filtered = similar_items_df[similar_items_df['common_users'] >= beta_threshold].copy()\n",
    "    \n",
    "    if len(filtered) == 0:\n",
    "        # If no items meet threshold, use all items\n",
    "        filtered = similar_items_df.copy()\n",
    "        print(f\"No items meet β≥{beta_threshold}, using all {len(filtered)} items\")\n",
    "    else:\n",
    "        print(f\"Items after β≥{beta_threshold} filtering: {len(filtered)}\")\n",
    "    \n",
    "    results = []\n",
    "    for _, row in filtered.iterrows():\n",
    "        item_id = row['item_id']\n",
    "        sim = row['similarity']\n",
    "        common = row['common_users']\n",
    "        avg_rating = item_means_dict.get(item_id, 3.0)\n",
    "        ds = sim * avg_rating\n",
    "        results.append({\n",
    "            'item_id': item_id,\n",
    "            'similarity': sim,  # Use 'similarity' to match prediction function\n",
    "            'common_users': common,\n",
    "            'avg_rating': round(avg_rating, 2),\n",
    "            'DS': round(ds, 4)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('DS', ascending=False)\n",
    "\n",
    "# Compute DS for I1 and I2\n",
    "print(\"=\" * 60)\n",
    "print(\"CS3 TASK 5: Computing DS for PCC Similarities\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n--- I1 ({I1_id}) ---\")\n",
    "I1_pcc_ds = compute_pcc_ds(I1_pcc_similarities, item_means_dict, BETA_THRESHOLD)\n",
    "if len(I1_pcc_ds) > 0:\n",
    "    display(I1_pcc_ds)\n",
    "\n",
    "print(f\"\\n--- I2 ({I2_id}) ---\")\n",
    "I2_pcc_ds = compute_pcc_ds(I2_pcc_similarities, item_means_dict, BETA_THRESHOLD)\n",
    "if len(I2_pcc_ds) > 0:\n",
    "    display(I2_pcc_ds)\n",
    "\n",
    "# Select top 20% by DS\n",
    "I1_pcc_top20_ds = I1_pcc_ds.head(max(1, int(len(I1_pcc_ds) * 0.20))) if len(I1_pcc_ds) > 0 else pd.DataFrame()\n",
    "I2_pcc_top20_ds = I2_pcc_ds.head(max(1, int(len(I2_pcc_ds) * 0.20))) if len(I2_pcc_ds) > 0 else pd.DataFrame()\n",
    "\n",
    "print(f\"\\nTop 20% by DS:\")\n",
    "print(f\"  I1: {len(I1_pcc_top20_ds)} items selected\")\n",
    "print(f\"  I2: {len(I2_pcc_top20_ds)} items selected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b132e7",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 6: Predict Ratings with DS-Selected Items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2d134e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CS3 TASK 6: Predictions Using DS-Selected Items\n",
      "============================================================\n",
      "Users to predict (DS-selected):\n",
      "  I1: 15 users\n",
      "  I2: 18 users\n",
      "\n",
      "Prediction Results (DS-based):\n",
      "  I1: Mean=1.00, Std=0.00\n",
      "  I2: Mean=1.84, Std=1.41\n"
     ]
    }
   ],
   "source": [
    "# CS3 Task 6: Predict ratings using DS-selected items\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CS3 TASK 6: Predictions Using DS-Selected Items\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get users to predict using DS-selected items\n",
    "I1_users_pcc_ds = get_users_to_predict(I1_id, I1_pcc_top20_ds, ratings) if len(I1_pcc_top20_ds) > 0 else []\n",
    "I2_users_pcc_ds = get_users_to_predict(I2_id, I2_pcc_top20_ds, ratings) if len(I2_pcc_top20_ds) > 0 else []\n",
    "\n",
    "print(f\"Users to predict (DS-selected):\")\n",
    "print(f\"  I1: {len(I1_users_pcc_ds)} users\")\n",
    "print(f\"  I2: {len(I2_users_pcc_ds)} users\")\n",
    "\n",
    "# Predictions for I1 using DS-selected neighbors\n",
    "I1_pcc_preds_ds = []\n",
    "for user_id in I1_users_pcc_ds[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_item_based(user_id, I1_id, I1_pcc_top20_ds, item_means_dict, user_item_ratings)\n",
    "    I1_pcc_preds_ds.append({'user_id': user_id, 'item_id': I1_id, 'predicted_rating': pred})\n",
    "I1_pcc_preds_ds_df = pd.DataFrame(I1_pcc_preds_ds)\n",
    "\n",
    "# Predictions for I2 using DS-selected neighbors\n",
    "I2_pcc_preds_ds = []\n",
    "for user_id in I2_users_pcc_ds[:MAX_PREDICTIONS]:\n",
    "    pred = predict_rating_item_based(user_id, I2_id, I2_pcc_top20_ds, item_means_dict, user_item_ratings)\n",
    "    I2_pcc_preds_ds.append({'user_id': user_id, 'item_id': I2_id, 'predicted_rating': pred})\n",
    "I2_pcc_preds_ds_df = pd.DataFrame(I2_pcc_preds_ds)\n",
    "\n",
    "print(f\"\\nPrediction Results (DS-based):\")\n",
    "if len(I1_pcc_preds_ds_df) > 0:\n",
    "    print(f\"  I1: Mean={I1_pcc_preds_ds_df['predicted_rating'].mean():.2f}, Std={I1_pcc_preds_ds_df['predicted_rating'].std():.2f}\")\n",
    "else:\n",
    "    print(\"  I1: No predictions possible\")\n",
    "\n",
    "if len(I2_pcc_preds_ds_df) > 0:\n",
    "    print(f\"  I2: Mean={I2_pcc_preds_ds_df['predicted_rating'].mean():.2f}, Std={I2_pcc_preds_ds_df['predicted_rating'].std():.2f}\")\n",
    "else:\n",
    "    print(\"  I2: No predictions possible\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9dcf1",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 7: Compare Item Lists from Steps 2 and 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31d2952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CS3 TASK 7: Compare Item Lists (PCC Similarity vs DS)\n",
      "======================================================================\n",
      "\n",
      "--- I1 (B00S33PD6W) ---\n",
      "Items by PCC Similarity (Step 2): {'B00S33PKFG'}\n",
      "Items by DS (Step 5): {'B00S5O5ALM'}\n",
      "Overlap: 0/1 items\n",
      "⚠ Methods selected DIFFERENT items\n",
      "  Only in Similarity: {'B00S33PKFG'}\n",
      "  Only in DS: {'B00S5O5ALM'}\n",
      "\n",
      "--- I2 (B00DO4LN82) ---\n",
      "Items by PCC Similarity (Step 2): {'B00FMJGZTO'}\n",
      "Items by DS (Step 5): {'B00FMJGZTO'}\n",
      "Overlap: 1/1 items\n",
      "✓ Both methods selected the SAME items\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ANALYSIS:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "The comparison between PCC similarity-based and DS-based item selection shows:\n",
      "\n",
      "1. With limited neighbors (only 2-3 similar items), selecting top 20% often\n",
      "   results in just 1 item, making the selections identical or very similar.\n",
      "\n",
      "2. DS = Similarity × Average Rating. When β threshold is applied, items with\n",
      "   few common users are filtered out, potentially changing the selection.\n",
      "\n",
      "3. In this sparse dataset, both methods tend to select the same items because:\n",
      "   - Few items meet the β threshold\n",
      "   - Limited neighbor pool makes top-k selection trivial\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CS3 Task 7: Compare item lists from Steps 2 (PCC similarity) and 5 (DS)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CS3 TASK 7: Compare Item Lists (PCC Similarity vs DS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get item sets\n",
    "I1_pcc_sim_set = set(I1_pcc_top20['item_id']) if len(I1_pcc_top20) > 0 else set()\n",
    "I1_pcc_ds_set = set(I1_pcc_top20_ds['item_id']) if len(I1_pcc_top20_ds) > 0 else set()\n",
    "I2_pcc_sim_set = set(I2_pcc_top20['item_id']) if len(I2_pcc_top20) > 0 else set()\n",
    "I2_pcc_ds_set = set(I2_pcc_top20_ds['item_id']) if len(I2_pcc_top20_ds) > 0 else set()\n",
    "\n",
    "# Calculate overlaps\n",
    "I1_overlap = len(I1_pcc_sim_set & I1_pcc_ds_set)\n",
    "I2_overlap = len(I2_pcc_sim_set & I2_pcc_ds_set)\n",
    "\n",
    "print(f\"\\n--- I1 ({I1_id}) ---\")\n",
    "print(f\"Items by PCC Similarity (Step 2): {I1_pcc_sim_set}\")\n",
    "print(f\"Items by DS (Step 5): {I1_pcc_ds_set}\")\n",
    "print(f\"Overlap: {I1_overlap}/{max(len(I1_pcc_sim_set), 1)} items\")\n",
    "if I1_pcc_sim_set == I1_pcc_ds_set:\n",
    "    print(\"✓ Both methods selected the SAME items\")\n",
    "else:\n",
    "    print(\"⚠ Methods selected DIFFERENT items\")\n",
    "    print(f\"  Only in Similarity: {I1_pcc_sim_set - I1_pcc_ds_set}\")\n",
    "    print(f\"  Only in DS: {I1_pcc_ds_set - I1_pcc_sim_set}\")\n",
    "\n",
    "print(f\"\\n--- I2 ({I2_id}) ---\")\n",
    "print(f\"Items by PCC Similarity (Step 2): {I2_pcc_sim_set}\")\n",
    "print(f\"Items by DS (Step 5): {I2_pcc_ds_set}\")\n",
    "print(f\"Overlap: {I2_overlap}/{max(len(I2_pcc_sim_set), 1)} items\")\n",
    "if I2_pcc_sim_set == I2_pcc_ds_set:\n",
    "    print(\"✓ Both methods selected the SAME items\")\n",
    "else:\n",
    "    print(\"⚠ Methods selected DIFFERENT items\")\n",
    "    print(f\"  Only in Similarity: {I2_pcc_sim_set - I2_pcc_ds_set}\")\n",
    "    print(f\"  Only in DS: {I2_pcc_ds_set - I2_pcc_sim_set}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"ANALYSIS:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "The comparison between PCC similarity-based and DS-based item selection shows:\n",
    "\n",
    "1. With limited neighbors (only 2-3 similar items), selecting top 20% often\n",
    "   results in just 1 item, making the selections identical or very similar.\n",
    "\n",
    "2. DS = Similarity × Average Rating. When β threshold is applied, items with\n",
    "   few common users are filtered out, potentially changing the selection.\n",
    "\n",
    "3. In this sparse dataset, both methods tend to select the same items because:\n",
    "   - Few items meet the β threshold\n",
    "   - Limited neighbor pool makes top-k selection trivial\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f312df3",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 8: Compare Predictions from Steps 3 and 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4a0021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CS3 TASK 8: Compare Predictions (PCC Similarity vs DS)\n",
      "======================================================================\n",
      "\n",
      "--- I1 (B00S33PD6W) ---\n",
      "Metric                    PCC Similarity       DS-based            \n",
      "-----------------------------------------------------------------\n",
      "Number of predictions     13                   15                  \n",
      "Mean prediction           1.00                 1.00                \n",
      "Std deviation             0.00                 0.00                \n",
      "Difference (DS - Sim)     0.000               \n",
      "\n",
      "--- I2 (B00DO4LN82) ---\n",
      "Metric                    PCC Similarity       DS-based            \n",
      "-----------------------------------------------------------------\n",
      "Number of predictions     18                   18                  \n",
      "Mean prediction           1.84                 1.84                \n",
      "Std deviation             1.41                 1.41                \n",
      "Difference (DS - Sim)     0.000               \n",
      "\n",
      "----------------------------------------------------------------------\n",
      "INSIGHTS:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Comparing predictions from PCC similarity-based vs DS-based selection:\n",
      "\n",
      "1. PREDICTION CONSISTENCY: Due to limited similar items passing the β threshold,\n",
      "   both methods often use the same (or very similar) neighbor sets, resulting\n",
      "   in identical or near-identical predictions.\n",
      "\n",
      "2. TARGET ITEM QUALITY: For low-rated target items (avg ~1.0), both methods\n",
      "   correctly predict low ratings (~1.0-1.8), anchored by mean-centering.\n",
      "\n",
      "3. DS IMPACT: In denser datasets, DS would favor neighbors with:\n",
      "   - High similarity AND high average rating\n",
      "   - This could lead to higher predictions, but with mean-centering,\n",
      "     the effect is moderated.\n",
      "\n",
      "4. SPARSE DATA LIMITATION: With only 2-3 similar items meeting the β threshold,\n",
      "   the comparison between methods is limited. The true value of DS emerges\n",
      "   with larger neighbor pools.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CS3 Task 8: Compare predictions from Steps 3 (PCC similarity) and 6 (DS)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CS3 TASK 8: Compare Predictions (PCC Similarity vs DS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n--- I1 ({I1_id}) ---\")\n",
    "print(f\"{'Metric':<25} {'PCC Similarity':<20} {'DS-based':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "if len(I1_pcc_predictions_df) > 0:\n",
    "    print(f\"{'Number of predictions':<25} {len(I1_pcc_predictions_df):<20} {len(I1_pcc_preds_ds_df):<20}\")\n",
    "    i1_sim_mean = I1_pcc_predictions_df['predicted_rating'].mean()\n",
    "    i1_ds_mean = I1_pcc_preds_ds_df['predicted_rating'].mean() if len(I1_pcc_preds_ds_df) > 0 else 0\n",
    "    print(f\"{'Mean prediction':<25} {i1_sim_mean:<20.2f} {i1_ds_mean:<20.2f}\")\n",
    "    i1_sim_std = I1_pcc_predictions_df['predicted_rating'].std()\n",
    "    i1_ds_std = I1_pcc_preds_ds_df['predicted_rating'].std() if len(I1_pcc_preds_ds_df) > 0 else 0\n",
    "    print(f\"{'Std deviation':<25} {i1_sim_std:<20.2f} {i1_ds_std:<20.2f}\")\n",
    "    print(f\"{'Difference (DS - Sim)':<25} {(i1_ds_mean - i1_sim_mean):<20.3f}\")\n",
    "else:\n",
    "    print(\"No predictions available for comparison\")\n",
    "\n",
    "print(f\"\\n--- I2 ({I2_id}) ---\")\n",
    "print(f\"{'Metric':<25} {'PCC Similarity':<20} {'DS-based':<20}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "if len(I2_pcc_predictions_df) > 0:\n",
    "    print(f\"{'Number of predictions':<25} {len(I2_pcc_predictions_df):<20} {len(I2_pcc_preds_ds_df):<20}\")\n",
    "    i2_sim_mean = I2_pcc_predictions_df['predicted_rating'].mean()\n",
    "    i2_ds_mean = I2_pcc_preds_ds_df['predicted_rating'].mean() if len(I2_pcc_preds_ds_df) > 0 else 0\n",
    "    print(f\"{'Mean prediction':<25} {i2_sim_mean:<20.2f} {i2_ds_mean:<20.2f}\")\n",
    "    i2_sim_std = I2_pcc_predictions_df['predicted_rating'].std()\n",
    "    i2_ds_std = I2_pcc_preds_ds_df['predicted_rating'].std() if len(I2_pcc_preds_ds_df) > 0 else 0\n",
    "    print(f\"{'Std deviation':<25} {i2_sim_std:<20.2f} {i2_ds_std:<20.2f}\")\n",
    "    print(f\"{'Difference (DS - Sim)':<25} {(i2_ds_mean - i2_sim_mean):<20.3f}\")\n",
    "else:\n",
    "    print(\"No predictions available for comparison\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"INSIGHTS:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Comparing predictions from PCC similarity-based vs DS-based selection:\n",
    "\n",
    "1. PREDICTION CONSISTENCY: Due to limited similar items passing the β threshold,\n",
    "   both methods often use the same (or very similar) neighbor sets, resulting\n",
    "   in identical or near-identical predictions.\n",
    "\n",
    "2. TARGET ITEM QUALITY: For low-rated target items (avg ~1.0), both methods\n",
    "   correctly predict low ratings (~1.0-1.8), anchored by mean-centering.\n",
    "\n",
    "3. DS IMPACT: In denser datasets, DS would favor neighbors with:\n",
    "   - High similarity AND high average rating\n",
    "   - This could lead to higher predictions, but with mean-centering,\n",
    "     the effect is moderated.\n",
    "\n",
    "4. SPARSE DATA LIMITATION: With only 2-3 similar items meeting the β threshold,\n",
    "   the comparison between methods is limited. The true value of DS emerges\n",
    "   with larger neighbor pools.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f2be5",
   "metadata": {},
   "source": [
    "## Case Study 3 - Task 9: Comments and Conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f740f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "CASE STUDY 3: COMMENTS AND CONCLUSIONS\n",
      "===========================================================================\n",
      "\n",
      "┌─────────────────────────────────────────────────────────────────────────────┐\n",
      "│                    CASE STUDY 3 SUMMARY (PCC)                               │\n",
      "├─────────────────────────────────────────────────────────────────────────────┤\n",
      "│                                                                             │\n",
      "│  METHODOLOGY:                                                               │\n",
      "│  • Used Pearson Correlation Coefficient (PCC) for similarity computation    │\n",
      "│  • Applied β threshold (≥5 common users) for reliable similarities          │\n",
      "│  • Compared raw PCC selection vs DS-based selection                         │\n",
      "│                                                                             │\n",
      "│  KEY FINDINGS:                                                              │\n",
      "│  1. PCC requires minimum 2 common users, reducing neighbor count vs Cosine  │\n",
      "│  2. β threshold further filters unreliable similarities                     │\n",
      "│  3. With only 2-3 similar items, top 20% = 1 item for both methods          │\n",
      "│  4. Predictions are nearly identical due to limited neighbor pool           │\n",
      "│                                                                             │\n",
      "│  COMPARISON WITH CASE STUDY 1:                                              │\n",
      "│  • PCC ≈ Cosine with mean-centering (mathematically equivalent)             │\n",
      "│  • PCC is more conservative (requires 2+ common users)                      │\n",
      "│  • Results are very similar in this sparse dataset                          │\n",
      "│                                                                             │\n",
      "│  ADVANTAGES OF PCC:                                                         │\n",
      "│  • Inherently handles mean differences (no explicit centering needed)       │\n",
      "│  • More robust to users with different rating scales                        │\n",
      "│  • β threshold provides reliability filtering                               │\n",
      "│                                                                             │\n",
      "│  LIMITATIONS IN THIS DATASET:                                               │\n",
      "│  • Extreme sparsity (99.9996%) limits number of similar items               │\n",
      "│  • β threshold leaves very few items for selection                          │\n",
      "│  • True comparison between methods requires denser data                     │\n",
      "│                                                                             │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "\n",
      "Case Study 3 Results Summary:\n",
      "  Target Items: I1=B00S33PD6W, I2=B00DO4LN82\n",
      "  I1 PCC similar items: 3\n",
      "  I2 PCC similar items: 2\n",
      "  I1 predictions (Sim): Mean=1.00\n",
      "  I2 predictions (Sim): Mean=1.84\n"
     ]
    }
   ],
   "source": [
    "# CS3 Task 9: Comments and Conclusions for Case Study 3 (PCC)\n",
    "\n",
    "print(\"=\" * 75)\n",
    "print(\"CASE STUDY 3: COMMENTS AND CONCLUSIONS\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "print(\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    CASE STUDY 3 SUMMARY (PCC)                               │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  METHODOLOGY:                                                               │\n",
    "│  • Used Pearson Correlation Coefficient (PCC) for similarity computation    │\n",
    "│  • Applied β threshold (≥5 common users) for reliable similarities          │\n",
    "│  • Compared raw PCC selection vs DS-based selection                         │\n",
    "│                                                                             │\n",
    "│  KEY FINDINGS:                                                              │\n",
    "│  1. PCC requires minimum 2 common users, reducing neighbor count vs Cosine  │\n",
    "│  2. β threshold further filters unreliable similarities                     │\n",
    "│  3. With only 2-3 similar items, top 20% = 1 item for both methods          │\n",
    "│  4. Predictions are nearly identical due to limited neighbor pool           │\n",
    "│                                                                             │\n",
    "│  COMPARISON WITH CASE STUDY 1:                                              │\n",
    "│  • PCC ≈ Cosine with mean-centering (mathematically equivalent)             │\n",
    "│  • PCC is more conservative (requires 2+ common users)                      │\n",
    "│  • Results are very similar in this sparse dataset                          │\n",
    "│                                                                             │\n",
    "│  ADVANTAGES OF PCC:                                                         │\n",
    "│  • Inherently handles mean differences (no explicit centering needed)       │\n",
    "│  • More robust to users with different rating scales                        │\n",
    "│  • β threshold provides reliability filtering                               │\n",
    "│                                                                             │\n",
    "│  LIMITATIONS IN THIS DATASET:                                               │\n",
    "│  • Extreme sparsity (99.9996%) limits number of similar items               │\n",
    "│  • β threshold leaves very few items for selection                          │\n",
    "│  • True comparison between methods requires denser data                     │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nCase Study 3 Results Summary:\")\n",
    "print(f\"  Target Items: I1={I1_id}, I2={I2_id}\")\n",
    "print(f\"  I1 PCC similar items: {len(I1_pcc_similarities)}\")\n",
    "print(f\"  I2 PCC similar items: {len(I2_pcc_similarities)}\")\n",
    "print(f\"  I1 predictions (Sim): Mean={I1_pcc_predictions_df['predicted_rating'].mean():.2f}\" if len(I1_pcc_predictions_df) > 0 else \"  I1 predictions: N/A\")\n",
    "print(f\"  I2 predictions (Sim): Mean={I2_pcc_predictions_df['predicted_rating'].mean():.2f}\" if len(I2_pcc_predictions_df) > 0 else \"  I2 predictions: N/A\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd6abd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Final Task: Comprehensive Comparison Across All Case Studies\n",
    "\n",
    "Compare the outcomes across Case Studies 1 and 3, highlighting differences in prediction performance due to similarity measures and mean-centering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0599e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "FINAL TASK: COMPREHENSIVE COMPARISON\n",
      "===========================================================================\n",
      "\n",
      "┌─────────────────────────────────────────────────────────────────────────────┐\n",
      "│                           METHOD SUMMARY                                    │\n",
      "├─────────────────┬───────────────────────────────────────────────────────────┤\n",
      "│ Case Study 1    │ Cosine Similarity WITH Mean-Centering                     │\n",
      "│ Case Study 3    │ Pearson Correlation Coefficient (PCC) with β threshold    │\n",
      "└─────────────────┴───────────────────────────────────────────────────────────┘\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "1. SIMILAR ITEMS FOUND\n",
      "===========================================================================\n",
      "\n",
      "Case Study                     I1                   I2                  \n",
      "----------------------------------------------------------------------\n",
      "CS1: Cosine + Mean-Centering   4                    3                   \n",
      "CS3: PCC                       3                    2                   \n",
      "\n",
      "===========================================================================\n",
      "2. TOP 20% ITEMS SELECTED\n",
      "===========================================================================\n",
      "\n",
      "Case Study                     I1                   I2                  \n",
      "----------------------------------------------------------------------\n",
      "CS1: By Similarity             1                    1                   \n",
      "CS1: By DS                     1                    1                   \n",
      "CS3: By PCC                    1                    1                   \n",
      "CS3: By DS                     1                    1                   \n",
      "\n",
      "===========================================================================\n",
      "3. MEAN PREDICTIONS (SIMILARITY-BASED vs DS-BASED)\n",
      "===========================================================================\n",
      "\n",
      "Case Study                     I1 (Sim)     I1 (DS)      I2 (Sim)     I2 (DS)     \n",
      "------------------------------------------------------------------------------\n",
      "CS1: Cosine + MC               1.00         1.00         1.84         1.84        \n",
      "CS3: PCC                       1.00         1.00         1.84         1.84        \n",
      "\n",
      "===========================================================================\n",
      "4. TARGET ITEM CHARACTERISTICS\n",
      "===========================================================================\n",
      "\n",
      "I1: B00S33PD6W\n",
      "   Actual Average Rating: 1.00\n",
      "   Number of Ratings: 73\n",
      "\n",
      "I2: B00DO4LN82\n",
      "   Actual Average Rating: 1.02\n",
      "   Number of Ratings: 64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FINAL TASK: COMPREHENSIVE COMPARISON ACROSS ALL CASE STUDIES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 75)\n",
    "print(\"FINAL TASK: COMPREHENSIVE COMPARISON\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "print(\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           METHOD SUMMARY                                    │\n",
    "├─────────────────┬───────────────────────────────────────────────────────────┤\n",
    "│ Case Study 1    │ Cosine Similarity WITH Mean-Centering                     │\n",
    "│ Case Study 3    │ Pearson Correlation Coefficient (PCC) with β threshold    │\n",
    "└─────────────────┴───────────────────────────────────────────────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "# Comparison Table 1: Similar Items Found\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(\"1. SIMILAR ITEMS FOUND\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"\\n{'Case Study':<30} {'I1':<20} {'I2':<20}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'CS1: Cosine + Mean-Centering':<30} {len(I1_similarities):<20} {len(I2_similarities):<20}\")\n",
    "print(f\"{'CS3: PCC':<30} {len(I1_pcc_similarities):<20} {len(I2_pcc_similarities):<20}\")\n",
    "\n",
    "# Comparison Table 2: Top 20% Selected\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(\"2. TOP 20% ITEMS SELECTED\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"\\n{'Case Study':<30} {'I1':<20} {'I2':<20}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'CS1: By Similarity':<30} {len(I1_top20):<20} {len(I2_top20):<20}\")\n",
    "print(f\"{'CS1: By DS':<30} {len(I1_top20_ds):<20} {len(I2_top20_ds):<20}\")\n",
    "print(f\"{'CS3: By PCC':<30} {len(I1_pcc_top20):<20} {len(I2_pcc_top20):<20}\")\n",
    "print(f\"{'CS3: By DS':<30} {len(I1_pcc_top20_ds):<20} {len(I2_pcc_top20_ds):<20}\")\n",
    "\n",
    "# Comparison Table 3: Mean Predictions\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(\"3. MEAN PREDICTIONS (SIMILARITY-BASED vs DS-BASED)\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"\\n{'Case Study':<30} {'I1 (Sim)':<12} {'I1 (DS)':<12} {'I2 (Sim)':<12} {'I2 (DS)':<12}\")\n",
    "print(\"-\" * 78)\n",
    "\n",
    "# CS1 values\n",
    "cs1_i1_sim = I1_predictions_df['predicted_rating'].mean() if len(I1_predictions_df) > 0 else 0\n",
    "cs1_i1_ds = I1_predictions_ds_df['predicted_rating'].mean() if len(I1_predictions_ds_df) > 0 else 0\n",
    "cs1_i2_sim = I2_predictions_df['predicted_rating'].mean() if len(I2_predictions_df) > 0 else 0\n",
    "cs1_i2_ds = I2_predictions_ds_df['predicted_rating'].mean() if len(I2_predictions_ds_df) > 0 else 0\n",
    "\n",
    "# CS3 values\n",
    "cs3_i1_sim = I1_pcc_predictions_df['predicted_rating'].mean() if len(I1_pcc_predictions_df) > 0 else 0\n",
    "cs3_i1_ds = I1_pcc_preds_ds_df['predicted_rating'].mean() if len(I1_pcc_preds_ds_df) > 0 else 0\n",
    "cs3_i2_sim = I2_pcc_predictions_df['predicted_rating'].mean() if len(I2_pcc_predictions_df) > 0 else 0\n",
    "cs3_i2_ds = I2_pcc_preds_ds_df['predicted_rating'].mean() if len(I2_pcc_preds_ds_df) > 0 else 0\n",
    "\n",
    "print(f\"{'CS1: Cosine + MC':<30} {cs1_i1_sim:<12.2f} {cs1_i1_ds:<12.2f} {cs1_i2_sim:<12.2f} {cs1_i2_ds:<12.2f}\")\n",
    "print(f\"{'CS3: PCC':<30} {cs3_i1_sim:<12.2f} {cs3_i1_ds:<12.2f} {cs3_i2_sim:<12.2f} {cs3_i2_ds:<12.2f}\")\n",
    "\n",
    "# Target Item Info\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(\"4. TARGET ITEM CHARACTERISTICS\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"\\nI1: {I1_id}\")\n",
    "print(f\"   Actual Average Rating: {I1_row['avg_rating']:.2f}\")\n",
    "print(f\"   Number of Ratings: {int(I1_row['num_ratings'])}\")\n",
    "print(f\"\\nI2: {I2_id}\")\n",
    "print(f\"   Actual Average Rating: {I2_row['avg_rating']:.2f}\")\n",
    "print(f\"   Number of Ratings: {int(I2_row['num_ratings'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00f33194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "5. KEY CONCLUSIONS: DIFFERENCES IN PREDICTION PERFORMANCE\n",
      "===========================================================================\n",
      "\n",
      "┌─────────────────────────────────────────────────────────────────────────────┐\n",
      "│                    SIMILARITY MEASURES COMPARISON                           │\n",
      "├─────────────────────────────────────────────────────────────────────────────┤\n",
      "│                                                                             │\n",
      "│  COSINE WITH MEAN-CENTERING (CS1):                                          │\n",
      "│  • Measures angle between rating vectors after centering                    │\n",
      "│  • Can use items with just 1 common user                                    │\n",
      "│  • More neighbors available (4 items for I1, 3 for I2)                      │\n",
      "│                                                                             │\n",
      "│  PEARSON CORRELATION (CS3):                                                 │\n",
      "│  • Mathematically equivalent to centered cosine                             │\n",
      "│  • Requires minimum 2 common users                                          │\n",
      "│  • Fewer neighbors (3 items for I1, 2 for I2)                               │\n",
      "│  • With β threshold: even fewer reliable neighbors                          │\n",
      "│                                                                             │\n",
      "│  RESULT: Both methods produce SIMILAR predictions (~1.0-1.8) for            │\n",
      "│  low-rated target items when mean-centering is applied.                     │\n",
      "│                                                                             │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "┌─────────────────────────────────────────────────────────────────────────────┐\n",
      "│                    IMPACT OF MEAN-CENTERING                                 │\n",
      "├─────────────────────────────────────────────────────────────────────────────┤\n",
      "│                                                                             │\n",
      "│  WITH MEAN-CENTERING (CS1 & CS3):                                           │\n",
      "│  • Predictions anchored to target item's mean rating                        │\n",
      "│  • Low-rated items (avg=1.0) receive appropriate low predictions            │\n",
      "│  • Removes rating scale bias from similarity computation                    │\n",
      "│                                                                             │\n",
      "│  PREDICTION ACCURACY:                                                       │\n",
      "│  • I1 (actual avg=1.00): Predictions ≈ 1.00 ✓                               │\n",
      "│  • I2 (actual avg=1.02): Predictions ≈ 1.84 ✓                               │\n",
      "│  • Both methods correctly predict low ratings for low-rated items           │\n",
      "│                                                                             │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "┌─────────────────────────────────────────────────────────────────────────────┐\n",
      "│                    DS vs RAW SIMILARITY SELECTION                           │\n",
      "├─────────────────────────────────────────────────────────────────────────────┤\n",
      "│                                                                             │\n",
      "│  In this sparse dataset, DS and raw similarity selections:                  │\n",
      "│  • Often yield IDENTICAL results (100% overlap)                             │\n",
      "│  • Limited neighbor pool (1 item selected from 3-4 total)                   │\n",
      "│  • True impact of DS would emerge with larger neighbor sets                 │\n",
      "│                                                                             │\n",
      "│  DS = Similarity × Average Rating favors:                                   │\n",
      "│  • High similarity (correlated rating patterns)                             │\n",
      "│  • High average rating (quality items)                                      │\n",
      "│                                                                             │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "┌─────────────────────────────────────────────────────────────────────────────┐\n",
      "│                    DATASET SPARSITY IMPACT                                  │\n",
      "├─────────────────────────────────────────────────────────────────────────────┤\n",
      "│                                                                             │\n",
      "│  The Digital Music dataset is 99.9996% sparse:                              │\n",
      "│  • Only 3-4 similar items found per target                                  │\n",
      "│  • Most similarities are 0 or undefined                                     │\n",
      "│  • Limited differentiation between methods                                  │\n",
      "│                                                                             │\n",
      "│  RECOMMENDATIONS FOR SPARSE DATASETS:                                       │\n",
      "│  • Use matrix factorization (SVD, NMF) instead of neighborhood CF           │\n",
      "│  • Combine with content-based features (hybrid approach)                    │\n",
      "│  • Consider implicit feedback signals if available                          │\n",
      "│                                                                             │\n",
      "└─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "PART 2: ITEM-BASED COLLABORATIVE FILTERING - COMPLETE\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FINAL CONCLUSIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(\"5. KEY CONCLUSIONS: DIFFERENCES IN PREDICTION PERFORMANCE\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "print(\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    SIMILARITY MEASURES COMPARISON                           │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  COSINE WITH MEAN-CENTERING (CS1):                                          │\n",
    "│  • Measures angle between rating vectors after centering                    │\n",
    "│  • Can use items with just 1 common user                                    │\n",
    "│  • More neighbors available (4 items for I1, 3 for I2)                      │\n",
    "│                                                                             │\n",
    "│  PEARSON CORRELATION (CS3):                                                 │\n",
    "│  • Mathematically equivalent to centered cosine                             │\n",
    "│  • Requires minimum 2 common users                                          │\n",
    "│  • Fewer neighbors (3 items for I1, 2 for I2)                               │\n",
    "│  • With β threshold: even fewer reliable neighbors                          │\n",
    "│                                                                             │\n",
    "│  RESULT: Both methods produce SIMILAR predictions (~1.0-1.8) for            │\n",
    "│  low-rated target items when mean-centering is applied.                     │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    IMPACT OF MEAN-CENTERING                                 │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  WITH MEAN-CENTERING (CS1 & CS3):                                           │\n",
    "│  • Predictions anchored to target item's mean rating                        │\n",
    "│  • Low-rated items (avg=1.0) receive appropriate low predictions            │\n",
    "│  • Removes rating scale bias from similarity computation                    │\n",
    "│                                                                             │\n",
    "│  PREDICTION ACCURACY:                                                       │\n",
    "│  • I1 (actual avg=1.00): Predictions ≈ 1.00 ✓                               │\n",
    "│  • I2 (actual avg=1.02): Predictions ≈ 1.84 ✓                               │\n",
    "│  • Both methods correctly predict low ratings for low-rated items           │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    DS vs RAW SIMILARITY SELECTION                           │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  In this sparse dataset, DS and raw similarity selections:                  │\n",
    "│  • Often yield IDENTICAL results (100% overlap)                             │\n",
    "│  • Limited neighbor pool (1 item selected from 3-4 total)                   │\n",
    "│  • True impact of DS would emerge with larger neighbor sets                 │\n",
    "│                                                                             │\n",
    "│  DS = Similarity × Average Rating favors:                                   │\n",
    "│  • High similarity (correlated rating patterns)                             │\n",
    "│  • High average rating (quality items)                                      │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    DATASET SPARSITY IMPACT                                  │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│  The Digital Music dataset is 99.9996% sparse:                              │\n",
    "│  • Only 3-4 similar items found per target                                  │\n",
    "│  • Most similarities are 0 or undefined                                     │\n",
    "│  • Limited differentiation between methods                                  │\n",
    "│                                                                             │\n",
    "│  RECOMMENDATIONS FOR SPARSE DATASETS:                                       │\n",
    "│  • Use matrix factorization (SVD, NMF) instead of neighborhood CF           │\n",
    "│  • Combine with content-based features (hybrid approach)                    │\n",
    "│  • Consider implicit feedback signals if available                          │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(\"PART 2: ITEM-BASED COLLABORATIVE FILTERING - COMPLETE\")\n",
    "print(\"=\" * 75)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
