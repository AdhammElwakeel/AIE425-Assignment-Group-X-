{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13994587,"sourceType":"datasetVersion","datasetId":8918672}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Section 2 Part 1\n","metadata":{}},{"cell_type":"markdown","source":"# User-User CF","metadata":{}},{"cell_type":"markdown","source":"**Zeyad Mohamed Mahmoud Fayed 222 102 242**","metadata":{}},{"cell_type":"markdown","source":"# Case Study 1","metadata":{}},{"cell_type":"code","source":"import pandas as \nimport numpy as np\n\nMIN_USER_RATINGS = 5\nMIN_ITEM_RATINGS = 10\n\nprint(\"Original Dataset Shape:\", ratings.shape)\n\n\ndf_clean = ratings.copy()\ndone = False\niteration = 0\n\nwhile not done:\n    iteration += 1\n    start_shape = df_clean.shape\n    \n\n    user_counts = df_clean['user_id'].value_counts()\n    active_users = user_counts[user_counts >= MIN_USER_RATINGS].index\n    df_clean = df_clean[df_clean['user_id'].isin(active_users)]\n    \n\n    item_counts = df_clean['item_id'].value_counts()\n    popular_items = item_counts[item_counts >= MIN_ITEM_RATINGS].index\n    df_clean = df_clean[df_clean['item_id'].isin(popular_items)]\n    \n    end_shape = df_clean.shape\n    \n    print(f\"Iteration {iteration}: {start_shape} -> {end_shape}\")\n    \n\n    if start_shape == end_shape:\n        done = True\n\nprint(\"\\nFinal Filtered Dataset Shape:\", df_clean.shape)\n\nn_users = df_clean['user_id'].nunique()\nn_items = df_clean['item_id'].nunique()\nn_ratings = len(df_clean)\nsparsity = (1 - (n_ratings / (n_users * n_items))) * 100\n\nprint(f\"New Users: {n_users}\")\nprint(f\"New Items: {n_items}\")\nprint(f\"New Sparsity: {sparsity:.4f}% (Improved density)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T13:50:19.949394Z","iopub.execute_input":"2025-12-06T13:50:19.950092Z","iopub.status.idle":"2025-12-06T13:50:21.801769Z","shell.execute_reply.started":"2025-12-06T13:50:19.950066Z","shell.execute_reply":"2025-12-06T13:50:21.800991Z"}},"outputs":[{"name":"stdout","text":"Original Dataset Shape: (1584082, 4)\nIteration 1: (1584082, 4) -> (190470, 4)\nIteration 2: (190470, 4) -> (115637, 4)\nIteration 3: (115637, 4) -> (102336, 4)\nIteration 4: (102336, 4) -> (98662, 4)\nIteration 5: (98662, 4) -> (97477, 4)\nIteration 6: (97477, 4) -> (97161, 4)\nIteration 7: (97161, 4) -> (97087, 4)\nIteration 8: (97087, 4) -> (97071, 4)\nIteration 9: (97071, 4) -> (97071, 4)\n\nFinal Filtered Dataset Shape: (97071, 4)\nNew Users: 9893\nNew Items: 4029\nNew Sparsity: 99.7565% (Improved density)\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"from scipy.sparse import csr_matrix\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport random\nimport os\n\nWORK_DIR = '/kaggle/working/User_CF_Results'\nos.makedirs(WORK_DIR, exist_ok=True)\n\nprint(\"1. Preparing Optimized Matrix...\")\n\n\nunique_users = df_clean['user_id'].unique()\nunique_items = df_clean['item_id'].unique()\n\nuser_to_idx = {user: i for i, user in enumerate(unique_users)}\nidx_to_user = {i: user for user, i in user_to_idx.items()}\n\nitem_to_idx = {item: i for i, item in enumerate(unique_items)}\nidx_to_item = {i: item for item, i in item_to_idx.items()}\n\n\nuser_indices = df_clean['user_id'].map(user_to_idx)\nitem_indices = df_clean['item_id'].map(item_to_idx)\n\n\nsparse_matrix = csr_matrix(\n    (df_clean['rating'], (user_indices, item_indices)),\n    shape=(len(unique_users), len(unique_items))\n)\n\nprint(f\"Sparse Matrix Shape: {sparse_matrix.shape}\")\n\n\nprint(\"2. Training SVD Model...\")\n\nsvd = TruncatedSVD(n_components=50, random_state=42)\nmatrix_svd = svd.fit_transform(sparse_matrix)\n\nprint(f\"SVD Reduced Matrix: {matrix_svd.shape} (Ready for Similarity)\")\n\n\ndef get_recommendations(target_user_id, k_neighbors=50, top_n=10):\n    # 1. الحصول على متجه المستخدم\n    target_idx = user_to_idx[target_user_id]\n    target_vector = matrix_svd[target_idx].reshape(1, -1)\n    \n    \n    sim_scores = cosine_similarity(target_vector, matrix_svd).flatten()\n    \n    \n    similar_indices = sim_scores.argsort()[::-1]\n    similar_indices = similar_indices[similar_indices != target_idx]\n    top_k_indices = similar_indices[:k_neighbors]\n    \n    \n    print(f\"\\nTop 5 Neighbors for {target_user_id}:\")\n    for i in range(5):\n        idx = top_k_indices[i]\n        print(f\"  User: {idx_to_user[idx]} | Similarity: {sim_scores[idx]:.4f}\")\n\n    \n    neighbor_sims = sim_scores[top_k_indices]\n    neighbor_ratings = sparse_matrix[top_k_indices] # (K, Items)\n    \n   \n    weighted_sum = neighbor_ratings.T.dot(neighbor_sims)\n    sum_of_sims = np.sum(np.abs(neighbor_sims))\n    \n    if sum_of_sims == 0: return None\n    \n    predicted_scores = weighted_sum / sum_of_sims\n    \n    \n    user_history = sparse_matrix[target_idx].toarray().flatten()\n    predicted_scores[user_history > 0] = -1 \n    \n    top_item_indices = predicted_scores.argsort()[::-1][:top_n]\n    \n    recs = []\n    for idx in top_item_indices:\n        if predicted_scores[idx] > 0:\n            recs.append({\n                'Item_ID': idx_to_item[idx],\n                'Predicted_Rating': round(predicted_scores[idx], 4)\n            })\n            \n    return pd.DataFrame(recs)\n\n\nrandom_user = random.choice(unique_users)\n\nprint(f\"\\n--- Generating Recommendations for User: {random_user} ---\")\nrecs_df = get_recommendations(random_user)\n\nif recs_df is not None and not recs_df.empty:\n    print(\"\\nTop 10 Recommended Items:\")\n    display(recs_df)\n    \n   \n    recs_df.to_csv(f'{WORK_DIR}/SVD_Recs_{random_user}.csv', index=False)\n    print(\"Results saved.\")\nelse:\n    print(\"No recommendations found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T13:51:57.276999Z","iopub.execute_input":"2025-12-06T13:51:57.277771Z","iopub.status.idle":"2025-12-06T13:51:57.600485Z","shell.execute_reply.started":"2025-12-06T13:51:57.277742Z","shell.execute_reply":"2025-12-06T13:51:57.599860Z"}},"outputs":[{"name":"stdout","text":"1. Preparing Optimized Matrix...\nSparse Matrix Shape: (9893, 4029)\n2. Training SVD Model...\nSVD Reduced Matrix: (9893, 50) (Ready for Similarity)\n\n--- Generating Recommendations for User: AYXA1QO0KIXWV ---\n\nTop 5 Neighbors for AYXA1QO0KIXWV:\n  User: A3DO1Z69FZKSIX | Similarity: 0.9911\n  User: A3CPVP2M3JI6AN | Similarity: 0.9882\n  User: A3AMABALFJBHDU | Similarity: 0.9858\n  User: A2X46TS9VTP3BK | Similarity: 0.9855\n  User: A24D0DSUY34824 | Similarity: 0.9809\n\nTop 10 Recommended Items:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Item_ID  Predicted_Rating\n0  B00137VCQK              1.96\n1  B00137MOS0              1.13\n2  B00137Z0EK              0.77\n3  B00MR8YM4I              0.68\n4  B007QNRBRY              0.50\n5  B004UE3784              0.50\n6  B002X9RH2K              0.48\n7  B000S51XMQ              0.41\n8  B006H1ME5A              0.41\n9  B00137UV44              0.40","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item_ID</th>\n      <th>Predicted_Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B00137VCQK</td>\n      <td>1.96</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B00137MOS0</td>\n      <td>1.13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B00137Z0EK</td>\n      <td>0.77</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B00MR8YM4I</td>\n      <td>0.68</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>B007QNRBRY</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>B004UE3784</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>B002X9RH2K</td>\n      <td>0.48</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>B000S51XMQ</td>\n      <td>0.41</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>B006H1ME5A</td>\n      <td>0.41</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>B00137UV44</td>\n      <td>0.40</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Results saved.\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport os\n\n\nWORK_DIR = '/kaggle/working/User_CF_Results'\nos.makedirs(WORK_DIR, exist_ok=True)\nprint(f\"Results will be saved to: {WORK_DIR}\")\n\n\n\nif 'df_clean' in globals():\n    unique_users = df_clean['user_id'].unique()\n    \n    new_targets = df_clean['user_id'].value_counts().head(3).index.tolist()\n    \n    target_users_df = pd.DataFrame({\n        'target': ['U1_New', 'U2_New', 'U3_New'],\n        'user_id': new_targets\n    })\n    print(f\"\\nSelected New Target Users (from filtered data):\\n{target_users_df}\")\nelse:\n    raise ValueError(\"df_clean not found! Please run the Iterative Filtering step first.\")\n\n\nprint(\"\\nCreating Matrices & Applying SVD...\")\n\n\nuser_to_idx = {user: i for i, user in enumerate(df_clean['user_id'].unique())}\nidx_to_user = {i: user for user, i in user_to_idx.items()}\n\nitem_to_idx = {item: i for i, item in enumerate(df_clean['item_id'].unique())}\nidx_to_item = {i: item for item, i in item_to_idx.items()}\n\n\nuser_indices = df_clean['user_id'].map(user_to_idx)\nitem_indices = df_clean['item_id'].map(item_to_idx)\n\n\nsparse_matrix = csr_matrix(\n    (df_clean['rating'], (user_indices, item_indices)),\n    shape=(len(user_to_idx), len(item_to_idx))\n)\n\n\nsvd = TruncatedSVD(n_components=50, random_state=42)\nmatrix_svd = svd.fit_transform(sparse_matrix)\n\nprint(f\"Sparse Matrix Shape: {sparse_matrix.shape}\")\nprint(f\"SVD Matrix Shape: {matrix_svd.shape}\")\n\n\ndef run_user_based_cf(target_u_id, k_neighbors=50, n_recommendations=10):\n    \n    \n    if target_u_id not in user_to_idx:\n        print(f\"User {target_u_id} not found in matrix.\")\n        return None, None\n\n    target_idx = user_to_idx[target_u_id]\n    \n    \n    target_vector_svd = matrix_svd[target_idx].reshape(1, -1)\n    sim_scores = cosine_similarity(target_vector_svd, matrix_svd).flatten()\n    \n    \n    similar_indices = sim_scores.argsort()[::-1]\n    similar_indices = similar_indices[similar_indices != target_idx] # استبعاد النفس\n    top_k_indices = similar_indices[:k_neighbors]\n    \n   \n    neighbors_data = []\n    for idx in top_k_indices:\n        neighbors_data.append({\n            'Target_User': target_u_id,\n            'Neighbor_User_ID': idx_to_user[idx],\n            'Similarity_Score': round(sim_scores[idx], 4)\n        })\n    neighbors_df = pd.DataFrame(neighbors_data)\n\n    \n    neighbor_sims = sim_scores[top_k_indices].reshape(-1, 1) \n    neighbor_ratings = sparse_matrix[top_k_indices]          \n    \n   \n    \n    weighted_sum = neighbor_ratings.T.dot(neighbor_sims)\n    weighted_sum = np.asarray(weighted_sum).ravel() \n    \n    \n    sum_of_sims = np.sum(np.abs(neighbor_sims))\n    \n    if sum_of_sims == 0:\n        predicted_ratings = np.zeros(sparse_matrix.shape[1])\n    else:\n        predicted_ratings = weighted_sum / sum_of_sims\n\n   \n    items_rated_by_target = sparse_matrix[target_idx].nonzero()[1]\n    predicted_ratings[items_rated_by_target] = -1\n    \n   \n    top_n_indices = predicted_ratings.argsort()[::-1][:n_recommendations]\n    \n    recs_data = []\n    for idx in top_n_indices:\n        score = predicted_ratings[idx]\n        if score > 0:\n            recs_data.append({\n                'Target_User': target_u_id,\n                'Item_ID': idx_to_item[idx],\n                'Predicted_Rating': round(score, 4)\n            })\n            \n    recs_df = pd.DataFrame(recs_data)\n    \n    return neighbors_df, recs_df\n\n\nprint(\"\\nProcessing Target Users...\")\n\nfor i, row in target_users_df.iterrows():\n    label = row['target']\n    user_id = row['user_id']\n    \n    print(f\"\\nRunning User CF (SVD-Enhanced) for {label}: {user_id}\")\n    \n    neighbors_df, recs_df = run_user_based_cf(user_id, k_neighbors=50)\n    \n    \n    if neighbors_df is not None and not neighbors_df.empty:\n        n_filename = f\"{label}_Neighbors.csv\"\n        neighbors_df.to_csv(os.path.join(WORK_DIR, n_filename), index=False)\n        print(f\"  -> Saved neighbors to {n_filename}\")\n        display(neighbors_df.head(3))\n        \n    \n    if recs_df is not None and not recs_df.empty:\n        r_filename = f\"{label}_Recommendations.csv\"\n        recs_df.to_csv(os.path.join(WORK_DIR, r_filename), index=False)\n        print(f\"  -> Saved recommendations to {r_filename}\")\n        display(recs_df.head(3))\n    else:\n        print(\"  -> No recommendations found.\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(f\"All files saved in: {WORK_DIR}\")\nprint(\"=\"*50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T13:54:54.544494Z","iopub.execute_input":"2025-12-06T13:54:54.544912Z","iopub.status.idle":"2025-12-06T13:54:54.852576Z","shell.execute_reply.started":"2025-12-06T13:54:54.544888Z","shell.execute_reply":"2025-12-06T13:54:54.851998Z"}},"outputs":[{"name":"stdout","text":"Results will be saved to: /kaggle/working/User_CF_Results\n\nSelected New Target Users (from filtered data):\n   target         user_id\n0  U1_New  A3W4D8XOGLWUN5\n1  U2_New  A2H3JURQZOHVMB\n2  U3_New  A36EDWL4F3AASU\n\nCreating Matrices & Applying SVD...\nSparse Matrix Shape: (9893, 4029)\nSVD Matrix Shape: (9893, 50)\n\nProcessing Target Users...\n\nRunning User CF (SVD-Enhanced) for U1_New: A3W4D8XOGLWUN5\n  -> Saved neighbors to U1_New_Neighbors.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Target_User Neighbor_User_ID  Similarity_Score\n0  A3W4D8XOGLWUN5    AK0H0GRSKKOBO              0.89\n1  A3W4D8XOGLWUN5   A3IY9HIAMJQ7HL              0.87\n2  A3W4D8XOGLWUN5   A1IPYBGXRLS6MX              0.87","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Neighbor_User_ID</th>\n      <th>Similarity_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>AK0H0GRSKKOBO</td>\n      <td>0.89</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>A3IY9HIAMJQ7HL</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>A1IPYBGXRLS6MX</td>\n      <td>0.87</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"  -> Saved recommendations to U1_New_Recommendations.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Target_User     Item_ID  Predicted_Rating\n0  A3W4D8XOGLWUN5  B000W08K0U              0.35\n1  A3W4D8XOGLWUN5  B001229BCS              0.23\n2  A3W4D8XOGLWUN5  B000WLH8OI              0.22","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Item_ID</th>\n      <th>Predicted_Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B000W08K0U</td>\n      <td>0.35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B001229BCS</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B000WLH8OI</td>\n      <td>0.22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nRunning User CF (SVD-Enhanced) for U2_New: A2H3JURQZOHVMB\n  -> Saved neighbors to U2_New_Neighbors.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Target_User Neighbor_User_ID  Similarity_Score\n0  A2H3JURQZOHVMB    A8FKME502E5B0              0.92\n1  A2H3JURQZOHVMB   A2901ODCE3J5HC              0.91\n2  A2H3JURQZOHVMB   A1PHLZYNXAAV31              0.90","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Neighbor_User_ID</th>\n      <th>Similarity_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A2H3JURQZOHVMB</td>\n      <td>A8FKME502E5B0</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A2H3JURQZOHVMB</td>\n      <td>A2901ODCE3J5HC</td>\n      <td>0.91</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A2H3JURQZOHVMB</td>\n      <td>A1PHLZYNXAAV31</td>\n      <td>0.90</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"  -> Saved recommendations to U2_New_Recommendations.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Target_User     Item_ID  Predicted_Rating\n0  A2H3JURQZOHVMB  B000W216ZY              0.39\n1  A2H3JURQZOHVMB  B00ODGXGNU              0.23\n2  A2H3JURQZOHVMB  B00136LIBK              0.21","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Item_ID</th>\n      <th>Predicted_Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A2H3JURQZOHVMB</td>\n      <td>B000W216ZY</td>\n      <td>0.39</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A2H3JURQZOHVMB</td>\n      <td>B00ODGXGNU</td>\n      <td>0.23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A2H3JURQZOHVMB</td>\n      <td>B00136LIBK</td>\n      <td>0.21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nRunning User CF (SVD-Enhanced) for U3_New: A36EDWL4F3AASU\n  -> Saved neighbors to U3_New_Neighbors.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Target_User Neighbor_User_ID  Similarity_Score\n0  A36EDWL4F3AASU   A1KYHC3ZXAJICU              0.82\n1  A36EDWL4F3AASU    AXG5I4CK8OQ2F              0.70\n2  A36EDWL4F3AASU    ATIDIWJFL41W7              0.69","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Neighbor_User_ID</th>\n      <th>Similarity_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A36EDWL4F3AASU</td>\n      <td>A1KYHC3ZXAJICU</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A36EDWL4F3AASU</td>\n      <td>AXG5I4CK8OQ2F</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A36EDWL4F3AASU</td>\n      <td>ATIDIWJFL41W7</td>\n      <td>0.69</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"  -> Saved recommendations to U3_New_Recommendations.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Target_User     Item_ID  Predicted_Rating\n0  A36EDWL4F3AASU  B00961ZGQC              0.76\n1  A36EDWL4F3AASU  B00LWC6P1S              0.51\n2  A36EDWL4F3AASU  B00A3SGY4K              0.51","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Item_ID</th>\n      <th>Predicted_Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A36EDWL4F3AASU</td>\n      <td>B00961ZGQC</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A36EDWL4F3AASU</td>\n      <td>B00LWC6P1S</td>\n      <td>0.51</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A36EDWL4F3AASU</td>\n      <td>B00A3SGY4K</td>\n      <td>0.51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n==================================================\nAll files saved in: /kaggle/working/User_CF_Results\n==================================================\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport os\nimport math\n\n# 1. إعداد المسارات والمستخدم المستهدف (النشط)\nWORK_DIR = '/kaggle/working/User_CF_Results'\nos.makedirs(WORK_DIR, exist_ok=True)\n\n# نستخدم المستخدم النشط الذي أعطى نتائج جيدة في التجارب السابقة\nTARGET_USER_ID = 'AAE2DUEMTR30I'\n\nprint(\"1. Performing Iterative Filtering (To fix Sparsity)...\")\n\n\nMIN_USER_RATINGS = 5\nMIN_ITEM_RATINGS = 10\n\ndf_clean = ratings.copy()\ndone = False\niteration = 0\n\nwhile not done:\n    iteration += 1\n    start_shape = df_clean.shape\n    \n    # أ) فلترة المستخدمين\n    user_counts = df_clean['user_id'].value_counts()\n    active_users = user_counts[user_counts >= MIN_USER_RATINGS].index\n    df_clean = df_clean[df_clean['user_id'].isin(active_users)]\n    \n    # ب) فلترة المنتجات\n    item_counts = df_clean['item_id'].value_counts()\n    popular_items = item_counts[item_counts >= MIN_ITEM_RATINGS].index\n    df_clean = df_clean[df_clean['item_id'].isin(popular_items)]\n    \n    end_shape = df_clean.shape\n    print(f\"   Iteration {iteration}: {start_shape} -> {end_shape}\")\n    \n    if start_shape == end_shape:\n        done = True\n\nprint(f\"\\nFinal Dataset Shape: {df_clean.shape}\")\n\n# التأكد أن المستخدم المستهدف لا يزال موجوداً\nif TARGET_USER_ID not in df_clean['user_id'].values:\n    print(f\"Warning: Target user {TARGET_USER_ID} was filtered out! Selecting a new top user...\")\n    TARGET_USER_ID = df_clean['user_id'].value_counts().index[0]\n    print(f\"New Target User: {TARGET_USER_ID}\")\n\n# ---------------------------------------------------------\n# بناء المصفوفة و SVD\n# ---------------------------------------------------------\nprint(\"\\n2. Creating Matrix & Applying SVD...\")\n\n# Maps\nuser_ids = df_clean['user_id'].unique()\nitem_ids = df_clean['item_id'].unique()\n\nuser_to_idx = {user: i for i, user in enumerate(user_ids)}\nitem_to_idx = {item: i for i, item in enumerate(item_ids)}\n\nuser_indices = df_clean['user_id'].map(user_to_idx)\nitem_indices = df_clean['item_id'].map(item_to_idx)\n\nsparse_matrix = csr_matrix(\n    (df_clean['rating'], (user_indices, item_indices)),\n    shape=(len(user_ids), len(item_ids))\n)\n\nsvd = TruncatedSVD(n_components=50, random_state=42)\nmatrix_svd = svd.fit_transform(sparse_matrix)\n\nprint(f\"Sparse Shape: {sparse_matrix.shape}\")\nprint(f\"SVD Shape: {matrix_svd.shape}\")\n\nprint(f\"\\n3. Calculating SVD-Based Similarity for {TARGET_USER_ID}...\")\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\ntarget_vector = matrix_svd[target_idx].reshape(1, -1)\n\nsimilarity_scores = cosine_similarity(target_vector, matrix_svd).flatten()\n\nresults_df = pd.DataFrame({\n    'User_ID': user_ids,\n    'Similarity_Score': similarity_scores\n})\n\nresults_df = results_df[results_df['User_ID'] != TARGET_USER_ID]\n\nresults_df = results_df[results_df['Similarity_Score'] > 0]\n\nresults_df = results_df.sort_values(by='Similarity_Score', ascending=False)\n\ntop_k_count = math.ceil(len(results_df) * 0.20)\ntop_20_df = results_df.head(top_k_count)\n\noutput_file = os.path.join(WORK_DIR, f'Similarity_SVD_{TARGET_USER_ID}.csv')\ntop_20_df.to_csv(output_file, index=False)\n\nprint(f\"Done! Top {len(top_20_df)} users saved to: {output_file}\")\n\nprint(\"\\nTop 10 Similar Users (SVD Results):\")\ndisplay(top_20_df.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T13:56:50.602680Z","iopub.execute_input":"2025-12-06T13:56:50.603293Z","iopub.status.idle":"2025-12-06T13:56:52.608343Z","shell.execute_reply.started":"2025-12-06T13:56:50.603270Z","shell.execute_reply":"2025-12-06T13:56:52.607733Z"}},"outputs":[{"name":"stdout","text":"1. Performing Iterative Filtering (To fix Sparsity)...\n   Iteration 1: (1584082, 4) -> (190470, 4)\n   Iteration 2: (190470, 4) -> (115637, 4)\n   Iteration 3: (115637, 4) -> (102336, 4)\n   Iteration 4: (102336, 4) -> (98662, 4)\n   Iteration 5: (98662, 4) -> (97477, 4)\n   Iteration 6: (97477, 4) -> (97161, 4)\n   Iteration 7: (97161, 4) -> (97087, 4)\n   Iteration 8: (97087, 4) -> (97071, 4)\n   Iteration 9: (97071, 4) -> (97071, 4)\n\nFinal Dataset Shape: (97071, 4)\nWarning: Target user AAE2DUEMTR30I was filtered out! Selecting a new top user...\nNew Target User: A3W4D8XOGLWUN5\n\n2. Creating Matrix & Applying SVD...\nSparse Shape: (9893, 4029)\nSVD Shape: (9893, 50)\n\n3. Calculating SVD-Based Similarity for A3W4D8XOGLWUN5...\nDone! Top 1420 users saved to: /kaggle/working/User_CF_Results/Similarity_SVD_A3W4D8XOGLWUN5.csv\n\nTop 10 Similar Users (SVD Results):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Similarity_Score\n7618   AK0H0GRSKKOBO              0.89\n6177  A3IY9HIAMJQ7HL              0.87\n6176  A1IPYBGXRLS6MX              0.87\n1954  A3QOQY24XUTR28              0.87\n3778   AD5R0C4EO8M9E              0.84\n7812  A36XJ5PAWMXHCV              0.82\n5786  A1NQFV0KQPM366              0.82\n3563   A1Z0KQUE6A5F9              0.81\n2031   AIYB8FUXTF365              0.81\n530   A368R6C5ZEO71R              0.81","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Similarity_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7618</th>\n      <td>AK0H0GRSKKOBO</td>\n      <td>0.89</td>\n    </tr>\n    <tr>\n      <th>6177</th>\n      <td>A3IY9HIAMJQ7HL</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>6176</th>\n      <td>A1IPYBGXRLS6MX</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>1954</th>\n      <td>A3QOQY24XUTR28</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>3778</th>\n      <td>AD5R0C4EO8M9E</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>7812</th>\n      <td>A36XJ5PAWMXHCV</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>5786</th>\n      <td>A1NQFV0KQPM366</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>3563</th>\n      <td>A1Z0KQUE6A5F9</td>\n      <td>0.81</td>\n    </tr>\n    <tr>\n      <th>2031</th>\n      <td>AIYB8FUXTF365</td>\n      <td>0.81</td>\n    </tr>\n    <tr>\n      <th>530</th>\n      <td>A368R6C5ZEO71R</td>\n      <td>0.81</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"import pandas as pd\nimport math\nimport os\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\nWORK_DIR = '/kaggle/working/User_CF_Results'\n\n\nif 'user_to_idx' not in globals():\n    raise ValueError(\"User mappings not found. Please run the SVD/Matrix step first.\")\n\n\nREQUESTED_USER_ID = 'AAE2DUEMTR30I'\n\nif REQUESTED_USER_ID in user_to_idx:\n    TARGET_USER_ID = REQUESTED_USER_ID\n    print(f\"User {TARGET_USER_ID} found in filtered data.\")\nelse:\n    print(f\"⚠️ User {REQUESTED_USER_ID} was dropped during data filtering.\")\n    \n\n    if 'df_clean' in globals():\n        TARGET_USER_ID = df_clean['user_id'].value_counts().idxmax()\n    else:\n        TARGET_USER_ID = list(user_to_idx.keys())[0]\n        \n    print(f\"-> Switched to NEW Valid Target User: {TARGET_USER_ID}\")\n\nprint(f\"\\nIdentifying Top 20% neighbors (SVD-Based) for: {TARGET_USER_ID}\")\n\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\n\n#\ntarget_vector_svd = matrix_svd[target_idx].reshape(1, -1)\n\n\nsim_scores = cosine_similarity(target_vector_svd, matrix_svd).flatten()\n\n\nvalid_user_ids = list(user_to_idx.keys())\n\ndf_scores = pd.DataFrame({\n    'User_ID': valid_user_ids,\n    'Similarity_Score': sim_scores\n})\n\n\ndf_scores = df_scores[df_scores['User_ID'] != TARGET_USER_ID]\n\n\ndf_scores = df_scores[df_scores['Similarity_Score'] > 0]\n\ndf_scores = df_scores.sort_values(by='Similarity_Score', ascending=False)\n\ntotal_neighbors = len(df_scores)\ntop_20_count = math.ceil(total_neighbors * 0.20)\n\nprint(f\"Total valid neighbors (Sim > 0): {total_neighbors}\")\nprint(f\"Top 20% count: {top_20_count}\")\n\n# هـ) استخراج القائمة\ntop_20_percent_df = df_scores.head(top_20_count)\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_SVD_Top20_Neighbors.csv')\ntop_20_percent_df.to_csv(output_file, index=False)\n\nprint(f\"\\nSaved SVD Top 20% to: {output_file}\")\nprint(\"\\nHere are the Top 20% Users (SVD):\")\ndisplay(top_20_percent_df.head(10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:00:12.404306Z","iopub.execute_input":"2025-12-06T14:00:12.404848Z","iopub.status.idle":"2025-12-06T14:00:12.445899Z","shell.execute_reply.started":"2025-12-06T14:00:12.404823Z","shell.execute_reply":"2025-12-06T14:00:12.445171Z"}},"outputs":[{"name":"stdout","text":"⚠️ User AAE2DUEMTR30I was dropped during data filtering.\n-> Switched to NEW Valid Target User: A3W4D8XOGLWUN5\n\nIdentifying Top 20% neighbors (SVD-Based) for: A3W4D8XOGLWUN5\nTotal valid neighbors (Sim > 0): 7098\nTop 20% count: 1420\n\nSaved SVD Top 20% to: /kaggle/working/User_CF_Results/A3W4D8XOGLWUN5_SVD_Top20_Neighbors.csv\n\nHere are the Top 20% Users (SVD):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Similarity_Score\n7618   AK0H0GRSKKOBO              0.89\n6177  A3IY9HIAMJQ7HL              0.87\n6176  A1IPYBGXRLS6MX              0.87\n1954  A3QOQY24XUTR28              0.87\n3778   AD5R0C4EO8M9E              0.84\n7812  A36XJ5PAWMXHCV              0.82\n5786  A1NQFV0KQPM366              0.82\n3563   A1Z0KQUE6A5F9              0.81\n2031   AIYB8FUXTF365              0.81\n530   A368R6C5ZEO71R              0.81","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Similarity_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7618</th>\n      <td>AK0H0GRSKKOBO</td>\n      <td>0.89</td>\n    </tr>\n    <tr>\n      <th>6177</th>\n      <td>A3IY9HIAMJQ7HL</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>6176</th>\n      <td>A1IPYBGXRLS6MX</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>1954</th>\n      <td>A3QOQY24XUTR28</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>3778</th>\n      <td>AD5R0C4EO8M9E</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>7812</th>\n      <td>A36XJ5PAWMXHCV</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>5786</th>\n      <td>A1NQFV0KQPM366</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>3563</th>\n      <td>A1Z0KQUE6A5F9</td>\n      <td>0.81</td>\n    </tr>\n    <tr>\n      <th>2031</th>\n      <td>AIYB8FUXTF365</td>\n      <td>0.81</td>\n    </tr>\n    <tr>\n      <th>530</th>\n      <td>A368R6C5ZEO71R</td>\n      <td>0.81</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\n# التأكد من المتغيرات\nif 'top_20_percent_df' not in globals() or top_20_percent_df.empty:\n    raise ValueError(\"Error: Top 20% neighbors dataframe missing. Run the previous step first.\")\n\nif 'sparse_matrix' not in globals():\n    raise ValueError(\"Error: Sparse Matrix missing. Run the Matrix Creation step first.\")\n\n\nif 'TARGET_USER_ID' not in globals():\n    print(\"Warning: TARGET_USER_ID variable lost. Using latest valid user.\")\n    TARGET_USER_ID = list(user_to_idx.keys())[0] \n\nprint(f\"Predicting ratings for: {TARGET_USER_ID}\")\nprint(f\"Based on {len(top_20_percent_df)} neighbors (SVD-selected)...\")\nneighbor_ids = top_20_percent_df['User_ID'].values\nneighbor_sims = top_20_percent_df['Similarity_Score'].values\n\nneighbor_indices = [user_to_idx[uid] for uid in neighbor_ids]\n\nneighbor_ratings_matrix = sparse_matrix[neighbor_indices]\n\nnumerator = neighbor_ratings_matrix.T.dot(neighbor_sims)\n\nbinary_ratings = neighbor_ratings_matrix.copy()\nbinary_ratings.data = np.ones_like(binary_ratings.data) # 1 if rated, 0 if not\ndenominator = binary_ratings.T.dot(neighbor_sims)\n\npredicted_ratings = np.zeros(sparse_matrix.shape[1])\nmask = denominator > 0\npredicted_ratings[mask] = numerator[mask] / denominator[mask]\n\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\nitems_rated_by_target = sparse_matrix[target_idx].indices\n\npredicted_ratings[items_rated_by_target] = 0\n\nrecommended_item_indices = predicted_ratings.argsort()[::-1]\n\nrecommendations_list = []\ncount = 0\n\nfor idx in recommended_item_indices:\n    score = predicted_ratings[idx]\n    \n    if score <= 0: break\n    if count >= 50: brea\n    \n    recommendations_list.append({\n        'Target_User': TARGET_USER_ID,\n        'Item_ID': idx_to_item[idx], # تحويل Index إلى ID\n        'Predicted_Rating': round(score, 4)\n    })\n    count += 1\n\nrecs_df = pd.DataFrame(recommendations_list)\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_SVD_Predicted_Preferences.csv')\nrecs_df.to_csv(output_file, index=False)\n\nprint(f\"\\nPrediction Complete!\")\nprint(f\"Number of unrated items predicted: {len(recs_df)}\")\nprint(f\"Results saved to: {output_file}\")\n\nif not recs_df.empty:\n    print(\"\\nTop 10 Recommended Items for User (SVD-Based):\")\n    display(recs_df.head(10))\nel\n    print(\"No recommendations generated.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:01:35.290040Z","iopub.execute_input":"2025-12-06T14:01:35.290675Z","iopub.status.idle":"2025-12-06T14:01:35.310864Z","shell.execute_reply.started":"2025-12-06T14:01:35.290651Z","shell.execute_reply":"2025-12-06T14:01:35.310206Z"}},"outputs":[{"name":"stdout","text":"Predicting ratings for: A3W4D8XOGLWUN5\nBased on 1420 neighbors (SVD-selected)...\n\nPrediction Complete!\nNumber of unrated items predicted: 50\nResults saved to: /kaggle/working/User_CF_Results/A3W4D8XOGLWUN5_SVD_Predicted_Preferences.csv\n\nTop 10 Recommended Items for User (SVD-Based):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Target_User     Item_ID  Predicted_Rating\n0  A3W4D8XOGLWUN5  B00I83XD14             20.00\n1  A3W4D8XOGLWUN5  B00123LX7I             15.60\n2  A3W4D8XOGLWUN5  B00136NKHU             13.53\n3  A3W4D8XOGLWUN5  B001416OXG             12.26\n4  A3W4D8XOGLWUN5  B000W1MCQW             10.00\n5  A3W4D8XOGLWUN5  B00123M8ZY             10.00\n6  A3W4D8XOGLWUN5  B0013873K8             10.00\n7  A3W4D8XOGLWUN5  B00123BCKQ             10.00\n8  A3W4D8XOGLWUN5  B00137VDBY             10.00\n9  A3W4D8XOGLWUN5  B00137VE9A             10.00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Item_ID</th>\n      <th>Predicted_Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B00I83XD14</td>\n      <td>20.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B00123LX7I</td>\n      <td>15.60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B00136NKHU</td>\n      <td>13.53</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B001416OXG</td>\n      <td>12.26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B000W1MCQW</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B00123M8ZY</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B0013873K8</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B00123BCKQ</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B00137VDBY</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A3W4D8XOGLWUN5</td>\n      <td>B00137VE9A</td>\n      <td>10.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport os\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nWORK_DIR = '/kaggle/working/User_CF_Result\nif 'sparse_matrix' not in globals() or 'matrix_svd' not in globals():\n    raise ValueError(\"Error: Filtered Matrices (sparse_matrix, matrix_svd) not found. Run the SVD step first.\")\n\nPREFERRED_ID = 'AAE2DUEMTR30I'\n\nif PREFERRED_ID in user_to_idx:\n    TARGET_USER_ID = PREFERRED_ID\nelse:\n    TARGET_USER_ID = list(user_to_idx.keys())[0]\n    print(f\"Warning: {PREFERRED_ID} not in filtered data. Switched to {TARGET_USER_ID}\")\n\nprint(f\"Calculating Discounted Similarity (DS) for: {TARGET_USER_ID}\"\ntarget_idx = user_to_idx[TARGET_USER_ID]\n\ntarget_vector_svd = matrix_svd[target_idx].reshape(1, -1)\n\nsvd_sim_scores = cosine_similarity(target_vector_svd, matrix_svd).flatten()\ntarget_vector_sparse = sparse_matrix[target_idx]\nnum_target_ratings = target_vector_sparse.getnnz()\n\nbeta = math.ceil(0.30 * num_target_ratings)\nbeta = max(1, beta)\n\n\nprint(f\"Target User Rated Items (Actual): {num_target_ratings}\")\nprint(f\"Threshold (Beta) @ 30%: {beta}\")\n\nprint(\"Calculating actual overlap count...\")\nbinary_matrix = sparse_matrix.copy()\nbinary_matrix.data[:] = 1\nbinary_target = binary_matrix[target_idx]\n\ncommon_counts = binary_target.dot(binary_matrix.T).toarray().flatten()\n\nuser_ids_list = list(user_to_idx.keys())\n\nds_df = pd.DataFrame({\n    'User_ID': user_ids_list,\n    'Similarity_Score': svd_sim_scores, \n    \n    'Num_Common_Items': common_counts  \n    \n})\n\nds_df['Discount_Factor'] = ds_df['Num_Common_Items'].apply(lambda x: min(x / beta, 1.0))\n\nds_df['Discounted_Similarity'] = ds_df['Similarity_Score'] * ds_df['Discount_Factor']\n\n\nds_df = ds_df[ds_df['User_ID'] != TARGET_USER_ID]\n\nds_valid = ds_df[ds_df['Discounted_Similarity'] > 0].sort_values(\n    by='Discounted_Similarity', ascending=False\n)\n\n# حساب الـ 20%\ntotal_valid = len(ds_valid)\ntop_k_count = math.ceil(total_valid * 0.20)\n\nprint(f\"Total valid neighbors (DS > 0): {total_valid}\")\nprint(f\"Top 20% count: {top_k_count}\")\n\n\ntop_20_svd_ds = ds_valid.head(top_k_count)\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_SVD_DS_Top20.csv')\ntop_20_svd_ds.to_csv(output_file, index=False)\n\nprint(f\"\\nSaved SVD-DS Top 20% list to: {output_file}\")\n\nprint(\"\\nTop 10 Similar Users (SVD + Discounting):\")\n# عرض الأعمدة المهمة\ncols = ['User_ID', 'Num_Common_Items', 'Discount_Factor', 'Similarity_Score', 'Discounted_Similarity']\ndisplay(top_20_svd_ds[cols].head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:02:54.173055Z","iopub.execute_input":"2025-12-06T14:02:54.173355Z","iopub.status.idle":"2025-12-06T14:02:54.211336Z","shell.execute_reply.started":"2025-12-06T14:02:54.173334Z","shell.execute_reply":"2025-12-06T14:02:54.210767Z"}},"outputs":[{"name":"stdout","text":"Warning: AAE2DUEMTR30I not in filtered data. Switched to A9Q28YTLYREO7\nCalculating Discounted Similarity (DS) for: A9Q28YTLYREO7\nTarget User Rated Items (Actual): 70\nThreshold (Beta) @ 30%: 21\nCalculating actual overlap count...\nTotal valid neighbors (DS > 0): 977\nTop 20% count: 196\n\nSaved SVD-DS Top 20% list to: /kaggle/working/User_CF_Results/A9Q28YTLYREO7_SVD_DS_Top20.csv\n\nTop 10 Similar Users (SVD + Discounting):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Num_Common_Items  Discount_Factor  Similarity_Score  \\\n44    A1QEWOSV05RYEO             17.00             0.81              0.75   \n2183  A3HU0B9XUEVHIM             14.00             0.67              0.83   \n7159  A1HCCW38EQQBTY             12.00             0.57              0.81   \n4206  A24N1BAS3CU27H             12.00             0.57              0.80   \n3385   AE31M52VLKOG6             11.00             0.52              0.83   \n7157  A1P41TBZBOLTY1             10.00             0.48              0.70   \n14     AD3C29MKDX7V2              8.00             0.38              0.87   \n9179   AJNQTSR3IMW8Z              8.00             0.38              0.82   \n3254  A3PCTD8QM1BIXI              7.00             0.33              0.87   \n1219   AMP7TQRWAIE84             11.00             0.52              0.53   \n\n      Discounted_Similarity  \n44                     0.60  \n2183                   0.56  \n7159                   0.46  \n4206                   0.45  \n3385                   0.43  \n7157                   0.33  \n14                     0.33  \n9179                   0.31  \n3254                   0.29  \n1219                   0.28  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Num_Common_Items</th>\n      <th>Discount_Factor</th>\n      <th>Similarity_Score</th>\n      <th>Discounted_Similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44</th>\n      <td>A1QEWOSV05RYEO</td>\n      <td>17.00</td>\n      <td>0.81</td>\n      <td>0.75</td>\n      <td>0.60</td>\n    </tr>\n    <tr>\n      <th>2183</th>\n      <td>A3HU0B9XUEVHIM</td>\n      <td>14.00</td>\n      <td>0.67</td>\n      <td>0.83</td>\n      <td>0.56</td>\n    </tr>\n    <tr>\n      <th>7159</th>\n      <td>A1HCCW38EQQBTY</td>\n      <td>12.00</td>\n      <td>0.57</td>\n      <td>0.81</td>\n      <td>0.46</td>\n    </tr>\n    <tr>\n      <th>4206</th>\n      <td>A24N1BAS3CU27H</td>\n      <td>12.00</td>\n      <td>0.57</td>\n      <td>0.80</td>\n      <td>0.45</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>AE31M52VLKOG6</td>\n      <td>11.00</td>\n      <td>0.52</td>\n      <td>0.83</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>7157</th>\n      <td>A1P41TBZBOLTY1</td>\n      <td>10.00</td>\n      <td>0.48</td>\n      <td>0.70</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>AD3C29MKDX7V2</td>\n      <td>8.00</td>\n      <td>0.38</td>\n      <td>0.87</td>\n      <td>0.33</td>\n    </tr>\n    <tr>\n      <th>9179</th>\n      <td>AJNQTSR3IMW8Z</td>\n      <td>8.00</td>\n      <td>0.38</td>\n      <td>0.82</td>\n      <td>0.31</td>\n    </tr>\n    <tr>\n      <th>3254</th>\n      <td>A3PCTD8QM1BIXI</td>\n      <td>7.00</td>\n      <td>0.33</td>\n      <td>0.87</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>1219</th>\n      <td>AMP7TQRWAIE84</td>\n      <td>11.00</td>\n      <td>0.52</td>\n      <td>0.53</td>\n      <td>0.28</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nprint(\"1. Preparing Data from Filtered Dataset...\nif 'df_clean' not in globals():\n    raise ValueError(\"Error: 'df_clean' not found. Please run the Iterative Filtering step first.\"\nunique_users = df_clean['user_id'].unique()\nunique_items = df_clean['item_id'].unique()\n\nuser_to_idx = {user: i for i, user in enumerate(unique_users)}\n# نحتاج item mapping لبناء المصفوفة\nitem_to_idx = {item: i for i, item in enumerate(unique_items)}\nuser_indices = df_clean['user_id'].map(user_to_idx)\nitem_indices = df_clean['item_id'].map(item_to_idx)\n\nsparse_matrix = csr_matrix(\n    (df_clean['rating'], (user_indices, item_indices)),\n    shape=(len(unique_users), len(unique_items))\n)\n\nprint(f\"Sparse Matrix Shape: {sparse_matrix.shape}\")\n\nprint(\"2. Applying SVD for Dimensionality Reduction...\")\n\n# استخدام 50 ميزة (Latent Features)\nsvd = TruncatedSVD(n_components=50, random_state=42)\n\n# تحويل المصفوفة المتناثرة إلى مصفوفة SVD (كثيفة وذكية)\nmatrix_svd = svd.fit_transform(sparse_matrix)\n\nprint(f\"Reduced Matrix Shape (SVD): {matrix_svd.shape}\") \n\n\nPREFERRED_ID = 'AAE2DUEMTR30I'\n\nif PREFERRED_ID in user_to_idx:\n    TARGET_USER_ID = PREFERRED_ID\n    print(f\"Target User Found: {TARGET_USER_ID}\")\nelse:\n    # اختيار بديل تلقائي (أكثر مستخدم نشاطاً في البيانات الجديدة)\n    TARGET_USER_ID = df_clean['user_id'].value_counts().idxmax()\n    print(f\"Warning: {PREFERRED_ID} filtered out. Switched to Top User: {TARGET_USER_ID}\")\n\n# 6. حساب التشابه (SVD-Based Cosine Similarity)\n# ---------------------------------------------------------\nprint(f\"3. Calculating Similarity for {TARGET_USER_ID}...\")\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\ntarget_vector_reduced = matrix_svd[target_idx].reshape(1, -1)\n\n# حساب التشابه\nsim_scores_svd = cosine_similarity(target_vector_reduced, matrix_svd).flatten()\n\n# 7. عرض النتائج\n# ---------------------------------------------------------\nresults_svd = pd.DataFrame({\n    'User_ID': unique_users,\n    'Similarity_Score': sim_scores_svd\n})\n\n# استبعاد المستخدم نفسه\nresults_svd = results_svd[results_svd['User_ID'] != TARGET_USER_ID]\n\n# استبعاد القيم الصفرية (اختياري، للتركيز على التشابه الحقيقي)\nresults_svd = results_svd[results_svd['Similarity_Score'] > 0]\n\n# الترتيب تنازلياً\nresults_svd = results_svd.sort_values(by='Similarity_Score', ascending=False)\n\nprint(f\"\\nTop 10 Similar Users using SVD (Total found: {len(results_svd)}):\")\ndisplay(results_svd.head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:04:04.191095Z","iopub.execute_input":"2025-12-06T14:04:04.191651Z","iopub.status.idle":"2025-12-06T14:04:04.471575Z","shell.execute_reply.started":"2025-12-06T14:04:04.191628Z","shell.execute_reply":"2025-12-06T14:04:04.470942Z"}},"outputs":[{"name":"stdout","text":"1. Preparing Data from Filtered Dataset...\nSparse Matrix Shape: (9893, 4029)\n2. Applying SVD for Dimensionality Reduction...\nReduced Matrix Shape (SVD): (9893, 50)\nWarning: AAE2DUEMTR30I filtered out. Switched to Top User: A3W4D8XOGLWUN5\n3. Calculating Similarity for A3W4D8XOGLWUN5...\n\nTop 10 Similar Users using SVD (Total found: 7098):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Similarity_Score\n7618   AK0H0GRSKKOBO              0.89\n6177  A3IY9HIAMJQ7HL              0.87\n6176  A1IPYBGXRLS6MX              0.87\n1954  A3QOQY24XUTR28              0.87\n3778   AD5R0C4EO8M9E              0.84\n7812  A36XJ5PAWMXHCV              0.82\n5786  A1NQFV0KQPM366              0.82\n3563   A1Z0KQUE6A5F9              0.81\n2031   AIYB8FUXTF365              0.81\n530   A368R6C5ZEO71R              0.81","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Similarity_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7618</th>\n      <td>AK0H0GRSKKOBO</td>\n      <td>0.89</td>\n    </tr>\n    <tr>\n      <th>6177</th>\n      <td>A3IY9HIAMJQ7HL</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>6176</th>\n      <td>A1IPYBGXRLS6MX</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>1954</th>\n      <td>A3QOQY24XUTR28</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>3778</th>\n      <td>AD5R0C4EO8M9E</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>7812</th>\n      <td>A36XJ5PAWMXHCV</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>5786</th>\n      <td>A1NQFV0KQPM366</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>3563</th>\n      <td>A1Z0KQUE6A5F9</td>\n      <td>0.81</td>\n    </tr>\n    <tr>\n      <th>2031</th>\n      <td>AIYB8FUXTF365</td>\n      <td>0.81</td>\n    </tr>\n    <tr>\n      <th>530</th>\n      <td>A368R6C5ZEO71R</td>\n      <td>0.81</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport os\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# إعداد المسارات والمستخدم\nWORK_DIR = '/kaggle/working/User_CF_Results'\nTARGET_USER_ID = 'A3W4D8XOGLWUN5'  # المستخدم الذي ظهر في الخطأ لديك\n\nprint(f\"🚀 Fixing missing files and running comparison for: {TARGET_USER_ID}\")\n\n# التأكد من وجود المصفوفات الأساسية\nif 'sparse_matrix' not in globals() or 'matrix_svd' not in globals():\n    raise ValueError(\"Error: Matrices missing. Please run the 'Iterative Filtering & SVD' step first.\")\n\nif TARGET_USER_ID not in user_to_idx:\n    # في حالة عدم وجود المستخدم، نختار البديل الأول\n    TARGET_USER_ID = list(user_to_idx.keys())[0]\n    print(f\"Warning: Specific user not found. Switched to: {TARGET_USER_ID}\")\n\n# =========================================================\n# المرحلة 1: إنشاء ملف الجيران (DS Neighbors) - (لحل مشكلة الملف المفقود)\n# =========================================================\nprint(\"\\n[1/3] Generating Discounted Similarity (DS) Neighbors...\")\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\n\n# 1. حساب تشابه SVD\ntarget_vector_svd = matrix_svd[target_idx].reshape(1, -1)\nsvd_sim_scores = cosine_similarity(target_vector_svd, matrix_svd).flatten()\n\n# 2. حساب العناصر المشتركة (من المصفوفة الحقيقية)\nbinary_matrix = sparse_matrix.copy()\nbinary_matrix.data[:] = 1\ncommon_counts = binary_matrix[target_idx].dot(binary_matrix.T).toarray().flatten()\n\n# 3. حساب العتبة (Beta)\nnum_target_ratings = sparse_matrix[target_idx].getnnz()\nbeta = max(1, math.ceil(0.30 * num_target_ratings))\n\n# 4. بناء الجدول وحساب DS\nuser_ids_list = list(user_to_idx.keys())\nds_df = pd.DataFrame({\n    'User_ID': user_ids_list,\n    'Similarity_Score': svd_sim_scores,\n    'Num_Common_Items': common_counts\n})\n\nds_df['Discount_Factor'] = ds_df['Num_Common_Items'].apply(lambda x: min(x / beta, 1.0))\nds_df['Discounted_Similarity'] = ds_df['Similarity_Score'] * ds_df['Discount_Factor']\n\n# 5. حفظ أفضل 20%\nds_df = ds_df[ds_df['User_ID'] != TARGET_USER_ID] # حذف المستخدم نفسه\nds_df = ds_df[ds_df['Discounted_Similarity'] > 0].sort_values(by='Discounted_Similarity', ascending=False)\n\ntop_k = math.ceil(len(ds_df) * 0.20)\nds_neighbors_df = ds_df.head(top_k)\n\nds_file_path = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_SVD_DS_Top20.csv')\nds_neighbors_df.to_csv(ds_file_path, index=False)\nprint(f\"   -> Saved: {ds_file_path} ({len(ds_neighbors_df)} neighbors)\")\n\n\n# =========================================================\n# المرحلة 2: إنشاء ملف التوقعات القياسية (Standard SVD Predictions)\n# =========================================================\nprint(\"\\n[2/3] Generating Standard SVD Predictions...\")\n\n# نستخدم أعلى 50 جاراً بناءً على SVD فقط (بدون تخفيض)\nraw_neighbors = ds_df.sort_values(by='Similarity_Score', ascending=False).head(50)\nneighbor_indices = [user_to_idx[uid] for uid in raw_neighbors['User_ID']]\nneighbor_sims = raw_neighbors['Similarity_Score'].values.reshape(-1, 1)\nneighbor_ratings = sparse_matrix[neighbor_indices]\n\n# حساب التوقعات\nweighted_sum = neighbor_ratings.T.dot(neighbor_sims).ravel()\nsum_sims = np.sum(np.abs(neighbor_sims))\nstd_preds = weighted_sum / sum_sims if sum_sims > 0 else np.zeros(sparse_matrix.shape[1])\n\n# تصفير ما رآه المستخدم\nstd_preds[sparse_matrix[target_idx].indices] = 0\n\n# حفظ أعلى 50\ntop_idx = std_preds.argsort()[::-1][:50]\nstd_recs = [{'Item_ID': idx_to_item[i], 'Standard_SVD_Rating': round(std_preds[i], 4)} for i in top_idx if std_preds[i] > 0]\nstd_recs_df = pd.DataFrame(std_recs)\n\nstd_file_path = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_SVD_Predicted_Preferences.csv')\nstd_recs_df.to_csv(std_file_path, index=False)\nprint(f\"   -> Saved: {std_file_path}\")\n\n\n# =========================================================\n# المرحلة 3: المقارنة (Comparison)\n# =========================================================\nprint(\"\\n[3/3] Comparing Predictions (Standard vs DS)...\")\n\n# 1. حساب توقعات DS (باستخدام الجيران المخفضين)\nds_indices = [user_to_idx[uid] for uid in ds_neighbors_df['User_ID']]\nds_weights = ds_neighbors_df['Discounted_Similarity'].values.reshape(-1, 1)\nds_ratings_mat = sparse_matrix[ds_indices]\n\n# معادلة المتوسط المرجح لـ DS\nds_num = ds_ratings_mat.T.dot(ds_weights).ravel()\nds_denom = ds_ratings_mat.copy()\nds_denom.data[:] = 1\nds_div = ds_denom.T.dot(ds_weights).ravel()\n\nds_final_preds = np.zeros(sparse_matrix.shape[1])\nmask = ds_div > 0\nds_final_preds[mask] = ds_num[mask] / ds_div[mask]\nds_final_preds[sparse_matrix[target_idx].indices] = 0\n\n# تجهيز DataFrame للمقارنة\nds_top_idx = ds_final_preds.argsort()[::-1][:50]\nds_recs = [{'Item_ID': idx_to_item[i], 'DS_Rating': round(ds_final_preds[i], 4)} for i in ds_top_idx if ds_final_preds[i] > 0]\nds_recs_df = pd.DataFrame(ds_recs)\n\n# الدمج والمقارنة\nif not std_recs_df.empty and not ds_recs_df.empty:\n    comparison_df = pd.merge(std_recs_df, ds_recs_df, on='Item_ID', how='inner')\n    comparison_df['Diff'] = comparison_df['Standard_SVD_Rating'] - comparison_df['DS_Rating']\n    \n    print(f\"\\n=== Final Comparison ({len(comparison_df)} overlapping items) ===\")\n    if comparison_df.empty:\n        print(\"No overlap! The recommendations are completely different.\")\n        print(\"Top Standard:\", std_recs_df['Item_ID'].head(3).tolist())\n        print(\"Top DS:\", ds_recs_df['Item_ID'].head(3).tolist())\n    else:\n        display(comparison_df.head(10))\n        \n    comp_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_Prediction_Comparison.csv')\n    comparison_df.to_csv(comp_file, index=False)\n    print(f\"\\nComparison saved to: {comp_file}\")\nelse:\n    print(\"No recommendations generated to compare.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:07:04.902363Z","iopub.execute_input":"2025-12-06T14:07:04.903248Z","iopub.status.idle":"2025-12-06T14:07:04.959510Z","shell.execute_reply.started":"2025-12-06T14:07:04.903219Z","shell.execute_reply":"2025-12-06T14:07:04.958967Z"}},"outputs":[{"name":"stdout","text":"🚀 Fixing missing files and running comparison for: A3W4D8XOGLWUN5\n\n[1/3] Generating Discounted Similarity (DS) Neighbors...\n   -> Saved: /kaggle/working/User_CF_Results/A3W4D8XOGLWUN5_SVD_DS_Top20.csv (955 neighbors)\n\n[2/3] Generating Standard SVD Predictions...\n   -> Saved: /kaggle/working/User_CF_Results/A3W4D8XOGLWUN5_SVD_Predicted_Preferences.csv\n\n[3/3] Comparing Predictions (Standard vs DS)...\n\n=== Final Comparison (3 overlapping items) ===\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Item_ID  Standard_SVD_Rating  DS_Rating  Diff\n0  B000VZJPJ6                 0.21      10.00 -9.79\n1  B00122WK08                 0.19      10.00 -9.81\n2  B00122D76O                 0.19      10.00 -9.81","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item_ID</th>\n      <th>Standard_SVD_Rating</th>\n      <th>DS_Rating</th>\n      <th>Diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B000VZJPJ6</td>\n      <td>0.21</td>\n      <td>10.00</td>\n      <td>-9.79</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B00122WK08</td>\n      <td>0.19</td>\n      <td>10.00</td>\n      <td>-9.81</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B00122D76O</td>\n      <td>0.19</td>\n      <td>10.00</td>\n      <td>-9.81</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nComparison saved to: /kaggle/working/User_CF_Results/A3W4D8XOGLWUN5_Prediction_Comparison.csv\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Setup\nWORK_DIR = '/kaggle/working/User_CF_Results'\n# Use the Target User from previous steps (e.g., AAE2DUEMTR30I or the one auto-selected)\n# Assuming 'TARGET_USER_ID' and 'df_clean' exist from previous cells\n\nprint(f\"Analyzing Neighbor Types for: {TARGET_USER_ID}\")\n\n# 1. Get Target User's Items\ntarget_items = set(df_clean[df_clean['user_id'] == TARGET_USER_ID]['item_id'])\nprint(f\"Target User Rated: {len(target_items)} items\")\n\n# 2. Load the SVD-DS Neighbors list (from Step 7/8)\n# If variable exists in memory, use it. If not, load from CSV.\nif 'top_20_svd_ds' in globals():\n    neighbors_df = top_20_svd_ds.copy()\nelse:\n    # Fallback to loading file\n    file_path = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_SVD_DS_Top20.csv')\n    if os.path.exists(file_path):\n        neighbors_df = pd.read_csv(file_path)\n    else:\n        raise ValueError(\"Neighbors data not found. Run previous steps first.\")\n\n# 3. Calculate Total Ratings for each Neighbor\n# We need to go back to the dataset (df_clean) to count total ratings for these neighbors\nneighbor_ids = neighbors_df['User_ID'].tolist()\nneighbor_activity = df_clean[df_clean['user_id'].isin(neighbor_ids)].groupby('user_id')['item_id'].count()\n\n# 4. Add metrics to DataFrame\nneighbors_df['Total_Neighbor_Ratings'] = neighbors_df['User_ID'].map(neighbor_activity)\nneighbors_df['Num_Common_Items'] = neighbors_df['Num_Common_Items'].astype(int) # Ensure int\n\n# Calculate \"Overlap Ratio\" (How much of their profile is just the common items?)\n# Ratio = 1.0 means they are identical subsets. Ratio -> 0 means they are heavy users.\nneighbors_df['Overlap_Ratio'] = round(neighbors_df['Num_Common_Items'] / neighbors_df['Total_Neighbor_Ratings'], 2)\n\n# 5. Classify Users\ndef classify_trust(row):\n    if row['Overlap_Ratio'] >= 0.8:\n        return \"Twin (High Overlap %)\"\n    elif row['Overlap_Ratio'] <= 0.2:\n        return \"Explorer (Low Overlap %, Many other items)\"\n    else:\n        return \"Balanced\"\n\nneighbors_df['User_Type'] = neighbors_df.apply(classify_trust, axis=1)\n\n\nprint(\"\\n--- Group A: The 'Twins' (Rated mostly common items) ---\")\ndisplay(neighbors_df[neighbors_df['User_Type'].str.contains(\"Twin\")].head(5))\n\nprint(\"\\n--- Group B: The 'Explorers' (Rated common items + MANY others) ---\")\ndisplay(neighbors_df[neighbors_df['User_Type'].str.contains(\"Explorer\")].head(5))\n\n# Save for analysis\nneighbors_df.to_csv(os.path.join(WORK_DIR, f'{TARGET_USER_ID}_Trust_Analysis.csv'), index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:30:25.925207Z","iopub.execute_input":"2025-12-06T14:30:25.925756Z","iopub.status.idle":"2025-12-06T14:30:25.978157Z","shell.execute_reply.started":"2025-12-06T14:30:25.925724Z","shell.execute_reply":"2025-12-06T14:30:25.977606Z"}},"outputs":[{"name":"stdout","text":"Analyzing Neighbor Types for: AAE2DUEMTR30I\nTarget User Rated: 0 items\n\n--- Group A: The 'Twins' (Rated mostly common items) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Similarity_Score  Num_Common_Items  Discount_Factor  \\\n14     AD3C29MKDX7V2              0.87                 8             0.38   \n9179   AJNQTSR3IMW8Z              0.82                 8             0.38   \n5194  A23Y7ESOGEBSZT              0.87                 4             0.19   \n8008  A311XNVMNZHKM8              0.85                 4             0.19   \n8321   A66WBGGY7AYQ5              0.85                 4             0.19   \n\n      Discounted_Similarity  Total_Neighbor_Ratings  Overlap_Ratio  \\\n14                     0.33                       9           0.89   \n9179                   0.31                       8           1.00   \n5194                   0.17                       5           0.80   \n8008                   0.16                       5           0.80   \n8321                   0.16                       5           0.80   \n\n                  User_Type  \n14    Twin (High Overlap %)  \n9179  Twin (High Overlap %)  \n5194  Twin (High Overlap %)  \n8008  Twin (High Overlap %)  \n8321  Twin (High Overlap %)  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Similarity_Score</th>\n      <th>Num_Common_Items</th>\n      <th>Discount_Factor</th>\n      <th>Discounted_Similarity</th>\n      <th>Total_Neighbor_Ratings</th>\n      <th>Overlap_Ratio</th>\n      <th>User_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>AD3C29MKDX7V2</td>\n      <td>0.87</td>\n      <td>8</td>\n      <td>0.38</td>\n      <td>0.33</td>\n      <td>9</td>\n      <td>0.89</td>\n      <td>Twin (High Overlap %)</td>\n    </tr>\n    <tr>\n      <th>9179</th>\n      <td>AJNQTSR3IMW8Z</td>\n      <td>0.82</td>\n      <td>8</td>\n      <td>0.38</td>\n      <td>0.31</td>\n      <td>8</td>\n      <td>1.00</td>\n      <td>Twin (High Overlap %)</td>\n    </tr>\n    <tr>\n      <th>5194</th>\n      <td>A23Y7ESOGEBSZT</td>\n      <td>0.87</td>\n      <td>4</td>\n      <td>0.19</td>\n      <td>0.17</td>\n      <td>5</td>\n      <td>0.80</td>\n      <td>Twin (High Overlap %)</td>\n    </tr>\n    <tr>\n      <th>8008</th>\n      <td>A311XNVMNZHKM8</td>\n      <td>0.85</td>\n      <td>4</td>\n      <td>0.19</td>\n      <td>0.16</td>\n      <td>5</td>\n      <td>0.80</td>\n      <td>Twin (High Overlap %)</td>\n    </tr>\n    <tr>\n      <th>8321</th>\n      <td>A66WBGGY7AYQ5</td>\n      <td>0.85</td>\n      <td>4</td>\n      <td>0.19</td>\n      <td>0.16</td>\n      <td>5</td>\n      <td>0.80</td>\n      <td>Twin (High Overlap %)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n--- Group B: The 'Explorers' (Rated common items + MANY others) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Similarity_Score  Num_Common_Items  Discount_Factor  \\\n7157  A1P41TBZBOLTY1              0.70                10             0.48   \n1219   AMP7TQRWAIE84              0.53                11             0.52   \n4230  A3AL8GQ69QE7WN              0.71                 6             0.29   \n39    A14GK0E64J0WAS              0.79                 5             0.24   \n3578  A2IK776FY6MEMG              0.70                 4             0.19   \n\n      Discounted_Similarity  Total_Neighbor_Ratings  Overlap_Ratio  \\\n7157                   0.33                      49           0.20   \n1219                   0.28                     129           0.09   \n4230                   0.20                      39           0.15   \n39                     0.19                      34           0.15   \n3578                   0.13                      22           0.18   \n\n                                       User_Type  \n7157  Explorer (Low Overlap %, Many other items)  \n1219  Explorer (Low Overlap %, Many other items)  \n4230  Explorer (Low Overlap %, Many other items)  \n39    Explorer (Low Overlap %, Many other items)  \n3578  Explorer (Low Overlap %, Many other items)  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Similarity_Score</th>\n      <th>Num_Common_Items</th>\n      <th>Discount_Factor</th>\n      <th>Discounted_Similarity</th>\n      <th>Total_Neighbor_Ratings</th>\n      <th>Overlap_Ratio</th>\n      <th>User_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7157</th>\n      <td>A1P41TBZBOLTY1</td>\n      <td>0.70</td>\n      <td>10</td>\n      <td>0.48</td>\n      <td>0.33</td>\n      <td>49</td>\n      <td>0.20</td>\n      <td>Explorer (Low Overlap %, Many other items)</td>\n    </tr>\n    <tr>\n      <th>1219</th>\n      <td>AMP7TQRWAIE84</td>\n      <td>0.53</td>\n      <td>11</td>\n      <td>0.52</td>\n      <td>0.28</td>\n      <td>129</td>\n      <td>0.09</td>\n      <td>Explorer (Low Overlap %, Many other items)</td>\n    </tr>\n    <tr>\n      <th>4230</th>\n      <td>A3AL8GQ69QE7WN</td>\n      <td>0.71</td>\n      <td>6</td>\n      <td>0.29</td>\n      <td>0.20</td>\n      <td>39</td>\n      <td>0.15</td>\n      <td>Explorer (Low Overlap %, Many other items)</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>A14GK0E64J0WAS</td>\n      <td>0.79</td>\n      <td>5</td>\n      <td>0.24</td>\n      <td>0.19</td>\n      <td>34</td>\n      <td>0.15</td>\n      <td>Explorer (Low Overlap %, Many other items)</td>\n    </tr>\n    <tr>\n      <th>3578</th>\n      <td>A2IK776FY6MEMG</td>\n      <td>0.70</td>\n      <td>4</td>\n      <td>0.19</td>\n      <td>0.13</td>\n      <td>22</td>\n      <td>0.18</td>\n      <td>Explorer (Low Overlap %, Many other items)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Case Study 2","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport os\n\n\nWORK_DIR = '/kaggle/working/User_CF_Results_MeanCentered'\nos.makedirs(WORK_DIR, exist_ok=True)\n\n\nTARGET_USER_ID = 'AAE2DUEMTR30I' \n\nprint(f\"Case Study 2: Mean-Centered CF for {TARGET_USER_ID}\")\n\n\nif 'df_clean' not in globals() or 'sparse_matrix' not in globals():\n    raise ValueError(\"Filtered data not found. Please run Iterative Filtering step first.\")\n\n\nif TARGET_USER_ID not in user_to_idx:\n    TARGET_USER_ID = list(user_to_idx.keys())[0]\n    print(f\"Switched target to: {TARGET_USER_ID}\")\n\n\nprint(\"\\n[1/4] Calculating User Means and Centering Matrix...\")\n\n\nuser_sums = sparse_matrix.sum(axis=1).A1 \nuser_counts = sparse_matrix.getnnz(axis=1)\n\n\nuser_means = np.zeros(len(user_ids))\nvalid_mask = user_counts > 0\nuser_means[valid_mask] = user_sums[valid_mask] / user_counts[valid_mask]\n\n\nmatrix_centered = sparse_matrix.copy().astype(float)\n\n\nrows, cols = matrix_centered.nonzero()\n\n\nmatrix_centered.data -= np.take(user_means, rows)\n\nprint(f\"Target User Mean Rating: {user_means[user_to_idx[TARGET_USER_ID]]:.4f}\")\n\n\nprint(\"\\n[2/4] Calculating Mean-Centered Similarity...\")\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\ntarget_vec_centered = matrix_centered[target_idx]\n\n\nmc_sim_scores = cosine_similarity(target_vec_centered, matrix_centered).flatten()\n\n# حفظ الجيران\nmc_neighbors_df = pd.DataFrame({\n    'User_ID': user_ids,\n    'MC_Similarity': mc_sim_scores,\n    'User_Mean': user_means\n})\n\n\nmc_neighbors_df = mc_neighbors_df[mc_neighbors_df['User_ID'] != TARGET_USER_ID]\nmc_neighbors_df = mc_neighbors_df.sort_values(by='MC_Similarity', ascending=False)\n\n\ntop_50_mc = mc_neighbors_df.head(50)\ntop_50_mc.to_csv(os.path.join(WORK_DIR, f'{TARGET_USER_ID}_MC_Neighbors.csv'), index=False)\n\nprint(\"Top 5 Mean-Centered Neighbors:\")\ndisplay(top_50_mc.head(5))\n\n\nprint(\"\\n[3/4] Predicting Ratings...\")\n\n\n\nneighbor_indices = [user_to_idx[uid] for uid in top_50_mc['User_ID']]\nneighbor_weights = top_50_mc['MC_Similarity'].values\nneighbor_means = top_50_mc['User_Mean'].values\n\n\nneighbor_matrix_centered = matrix_centered[neighbor_indices]\n\n\nnumerator = neighbor_matrix_centered.T.dot(neighbor_weights)\n\n\nbinary_matrix = neighbor_matrix_centered.copy()\nbinary_matrix.data[:] = 1 \ndenominator = binary_matrix.T.dot(np.abs(neighbor_weights)) \n\npredicted_deviation = np.zeros(sparse_matrix.shape[1])\nmask = denominator > 0\npredicted_deviation[mask] = numerator[mask] / denominator[mask]\n\n\ntarget_mean = user_means[target_idx]\nfinal_predictions = predicted_deviation + target_mean\n\n\nrated_items_indices = sparse_matrix[target_idx].indices\nfinal_predictions[rated_items_indices] = 0\n\n# ترتيب\ntop_item_indices = final_predictions.argsort()[::-1][:50]\n\nrecs_list = []\nfor idx in top_item_indices:\n    score = final_predictions[idx]\n    \n    if score > 0: \n        recs_list.append({\n            'Item_ID': idx_to_item[idx],\n            'Predicted_Rating': round(score, 4),\n            'Deviation_from_Mean': round(predicted_deviation[idx], 4)\n        })\n\nrecs_df = pd.DataFrame(recs_list)\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_MC_Predictions.csv')\nrecs_df.to_csv(output_file, index=False)\n\nprint(f\"\\n[4/4] Done. Results saved to: {WORK_DIR}\")\ndisplay(recs_df.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:44:13.982216Z","iopub.execute_input":"2025-12-06T14:44:13.982993Z","iopub.status.idle":"2025-12-06T14:44:14.018678Z","shell.execute_reply.started":"2025-12-06T14:44:13.982963Z","shell.execute_reply":"2025-12-06T14:44:14.017959Z"}},"outputs":[{"name":"stdout","text":"Case Study 2: Mean-Centered CF for AAE2DUEMTR30I\nSwitched target to: A9Q28YTLYREO7\n\n[1/4] Calculating User Means and Centering Matrix...\nTarget User Mean Rating: 4.1000\n\n[2/4] Calculating Mean-Centered Similarity...\nTop 5 Mean-Centered Neighbors:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  MC_Similarity  User_Mean\n7159  A1HCCW38EQQBTY           0.26       4.96\n5722  A3GS5WAQVO4CFB           0.26       5.25\n138   A2A788AUOVBOL2           0.25       5.45\n5720  A17P4YJ8E81WNX           0.25       3.88\n1131  A22WY238ZYNOS1           0.25       5.50","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>MC_Similarity</th>\n      <th>User_Mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7159</th>\n      <td>A1HCCW38EQQBTY</td>\n      <td>0.26</td>\n      <td>4.96</td>\n    </tr>\n    <tr>\n      <th>5722</th>\n      <td>A3GS5WAQVO4CFB</td>\n      <td>0.26</td>\n      <td>5.25</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>A2A788AUOVBOL2</td>\n      <td>0.25</td>\n      <td>5.45</td>\n    </tr>\n    <tr>\n      <th>5720</th>\n      <td>A17P4YJ8E81WNX</td>\n      <td>0.25</td>\n      <td>3.88</td>\n    </tr>\n    <tr>\n      <th>1131</th>\n      <td>A22WY238ZYNOS1</td>\n      <td>0.25</td>\n      <td>5.50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n[3/4] Predicting Ratings...\n\n[4/4] Done. Results saved to: /kaggle/working/User_CF_Results_MeanCentered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      Item_ID  Predicted_Rating  Deviation_from_Mean\n0  B00123IAVK              9.18                 5.08\n1  B0011Z1D8Q              9.06                 4.96\n2  B000WKT6B2              8.95                 4.85\n3  B000VZYYWY              8.43                 4.33\n4  B00137T3ES              8.10                 4.00\n5  B000W176MM              7.96                 3.86\n6  B00136PSAM              7.60                 3.50\n7  B000YN32BM              7.48                 3.38\n8  B000W20FY2              7.40                 3.30\n9  B0013DA8R8              7.10                 3.00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item_ID</th>\n      <th>Predicted_Rating</th>\n      <th>Deviation_from_Mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>B00123IAVK</td>\n      <td>9.18</td>\n      <td>5.08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>B0011Z1D8Q</td>\n      <td>9.06</td>\n      <td>4.96</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B000WKT6B2</td>\n      <td>8.95</td>\n      <td>4.85</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B000VZYYWY</td>\n      <td>8.43</td>\n      <td>4.33</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>B00137T3ES</td>\n      <td>8.10</td>\n      <td>4.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>B000W176MM</td>\n      <td>7.96</td>\n      <td>3.86</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>B00136PSAM</td>\n      <td>7.60</td>\n      <td>3.50</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>B000YN32BM</td>\n      <td>7.48</td>\n      <td>3.38</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>B000W20FY2</td>\n      <td>7.40</td>\n      <td>3.30</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>B0013DA8R8</td>\n      <td>7.10</td>\n      <td>3.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"import pandas as pd\nimport math\nimport os\n\nWORK_DIR = '/kaggle/working/User_CF_Results_MeanCentered'\nTARGET_USER_ID = 'AAE2DUEMTR30I'\n\nprint(f\"Identifying Top 20% Neighbors (Mean-Centered) for: {TARGET_USER_ID}\")\n\nif 'mc_neighbors_df' not in globals():\n\n    try:\n        file_path = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_MC_Neighbors.csv')\n    \n        print(\"Variable 'mc_neighbors_df' not found. Using calculated scores from memory...\")\n    except:\n        raise ValueError(\"Error: Previous results missing. Please run Step 1 (Calculate Mean-Centered Sim) first.\")\n\nif 'mc_sim_scores' in globals() and 'user_ids' in globals():\n    df_scores = pd.DataFrame({\n        'User_ID': user_ids,\n        'Adjusted_Score': mc_sim_scores\n    })\nelse:\n    raise ValueError(\"Similarity scores missing from memory. Please re-run Step 1.\")\n\ndf_scores = df_scores[df_scores['User_ID'] != TARGET_USER_ID]\n\n\ndf_positive = df_scores[df_scores['Adjusted_Score'] > 0].copy()\n\n\ndf_positive = df_positive.sort_values(by='Adjusted_Score', ascending=False)\n\n\ntotal_positive_neighbors = len(df_positive)\n\n\ntop_k_count = math.ceil(total_positive_neighbors * 0.20)\n\nprint(f\"Total users with Positive Correlation (>0): {total_positive_neighbors}\")\nprint(f\"Top 20% Selection Count: {top_k_count}\")\n\ntop_20_mc_df = df_positive.head(top_k_count)\n\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_MC_Top20_Neighbors.csv')\ntop_20_mc_df.to_csv(output_file, index=False)\n\nprint(f\"\\nSaved Mean-Centered Top 20% to: {output_file}\")\n\nprint(\"\\nTop 10 Neighbors (Adjusted Similarity):\")\ndisplay(top_20_mc_df.head(10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:46:10.587115Z","iopub.execute_input":"2025-12-06T14:46:10.587640Z","iopub.status.idle":"2025-12-06T14:46:10.605015Z","shell.execute_reply.started":"2025-12-06T14:46:10.587615Z","shell.execute_reply":"2025-12-06T14:46:10.604229Z"}},"outputs":[{"name":"stdout","text":"Identifying Top 20% Neighbors (Mean-Centered) for: AAE2DUEMTR30I\nTotal users with Positive Correlation (>0): 649\nTop 20% Selection Count: 130\n\nSaved Mean-Centered Top 20% to: /kaggle/working/User_CF_Results_MeanCentered/AAE2DUEMTR30I_MC_Top20_Neighbors.csv\n\nTop 10 Neighbors (Adjusted Similarity):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Adjusted_Score\n0      A9Q28YTLYREO7            1.00\n7159  A1HCCW38EQQBTY            0.26\n5722  A3GS5WAQVO4CFB            0.26\n138   A2A788AUOVBOL2            0.25\n5720  A17P4YJ8E81WNX            0.25\n1131  A22WY238ZYNOS1            0.25\n6496  A3J8SZL4IN1D46            0.25\n6500  A1OKLAQJVFREOQ            0.25\n5204  A3BY2QW7T0401N            0.25\n3525  A32XSKO7TOI0BH            0.24","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Adjusted_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>7159</th>\n      <td>A1HCCW38EQQBTY</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>5722</th>\n      <td>A3GS5WAQVO4CFB</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>A2A788AUOVBOL2</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>5720</th>\n      <td>A17P4YJ8E81WNX</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>1131</th>\n      <td>A22WY238ZYNOS1</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>6496</th>\n      <td>A3J8SZL4IN1D46</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>6500</th>\n      <td>A1OKLAQJVFREOQ</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>5204</th>\n      <td>A3BY2QW7T0401N</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3525</th>\n      <td>A32XSKO7TOI0BH</td>\n      <td>0.24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\n# إعداد المسارات والمستخدم\nWORK_DIR = '/kaggle/working/User_CF_Results_MeanCentered'\nTARGET_USER_ID = 'AAE2DUEMTR30I' # (أو المستخدم الذي تم اختياره تلقائياً في الخطوة السابقة)\n\nprint(f\"Predicting Ratings (Mean-Centered Approach) for: {TARGET_USER_ID}\")\nif 'top_20_mc_df' not in globals() or 'matrix_centered' not in globals() or 'user_means' not in globals():\n    raise ValueError(\"Error: Missing data (Neighbors, Centered Matrix, or User Means). Please run previous steps.\")\n\nif TARGET_USER_ID not in user_to_idx:\n    TARGET_USER_ID = list(user_to_idx.keys())[0]\n    print(f\"Warning: Switched to {TARGET_USER_ID}\")\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\ntarget_mean = user_means[target_idx]\n\nprint(f\"Target User Average Rating: {target_mean:.4f}\")\nprint(f\"Using {len(top_20_mc_df)} neighbors for prediction...\")\n\n\nneighbor_ids = top_20_mc_df['User_ID'].values\nneighbor_weights = top_20_mc_df['Adjusted_Score'].values\nneighbor_indices = [user_to_idx[uid] for uid in neighbor_ids]\n\n\nneighbor_matrix_centered = matrix_centered[neighbor_indices]\n\n\n\nnumerator = neighbor_matrix_centered.T.dot(neighbor_weights)\n\n\nbinary_matrix = neighbor_matrix_centered.copy()\nbinary_matrix.data[:] = 1 \n\ndenominator = binary_matrix.T.dot(np.abs(neighbor_weights))\n\n\npred_deviation = np.zeros(matrix_centered.shape[1])\nmask = denominator > 0\npred_deviation[mask] = numerator[mask] / denominator[mask]\n\n\nfinal_predicted_ratings = pred_deviation + target_mean\n\n\nif 'sparse_matrix' in globals():\n    items_rated_indices = sparse_matrix[target_idx].indices\n    final_predicted_ratings[items_rated_indices] = 0 # تصفير ما رآه\nelse:\n    print(\"Warning: Original sparse_matrix not found, skipping 'already rated' filter.\")\n\n\ntop_indices = final_predicted_ratings.argsort()[::-1][:50]\n\nrecs_list = []\nfor idx in top_indices:\n    score = final_predicted_ratings[idx]\n    \n    if score > 0.001: \n        recs_list.append({\n            'Target_User': TARGET_USER_ID,\n            'Item_ID': idx_to_item[idx],\n            'Predicted_Rating': round(score, 4),\n            'Base_Mean': round(target_mean, 2),\n            'Predicted_Deviation': round(pred_deviation[idx], 4)\n        })\n\nrecs_df = pd.DataFrame(recs_list)\n\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_MC_Predictions.csv')\nrecs_df.to_csv(output_file, index=False)\n\nprint(f\"\\nPrediction Complete. Saved to: {output_file}\")\n\nif not recs_df.empty:\n    print(\"\\nTop 10 Recommendations (Mean-Centered):\")\n    display(recs_df.head(10))\nelse:\n    print(\"No recommendations generated (Check neighborhood","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:47:43.538381Z","iopub.execute_input":"2025-12-06T14:47:43.538992Z","iopub.status.idle":"2025-12-06T14:47:43.559788Z","shell.execute_reply.started":"2025-12-06T14:47:43.538965Z","shell.execute_reply":"2025-12-06T14:47:43.559066Z"}},"outputs":[{"name":"stdout","text":"Predicting Ratings (Mean-Centered Approach) for: AAE2DUEMTR30I\nWarning: Switched to A9Q28YTLYREO7\nTarget User Average Rating: 4.1000\nUsing 130 neighbors for prediction...\n\nPrediction Complete. Saved to: /kaggle/working/User_CF_Results_MeanCentered/A9Q28YTLYREO7_MC_Predictions.csv\n\nTop 10 Recommendations (Mean-Centered):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     Target_User     Item_ID  Predicted_Rating  Base_Mean  Predicted_Deviation\n0  A9Q28YTLYREO7  B0012CCO0E             13.50       4.10                 9.40\n1  A9Q28YTLYREO7  B0012FAUV6              9.93       4.10                 5.83\n2  A9Q28YTLYREO7  B000VWMTHE              9.93       4.10                 5.83\n3  A9Q28YTLYREO7  B00136LQC6              9.62       4.10                 5.52\n4  A9Q28YTLYREO7  B00123IAVK              9.18       4.10                 5.08\n5  A9Q28YTLYREO7  B0011Z1D8Q              9.06       4.10                 4.96\n6  A9Q28YTLYREO7  B00123KDR4              8.71       4.10                 4.61\n7  A9Q28YTLYREO7  B00137GCI8              8.71       4.10                 4.61\n8  A9Q28YTLYREO7  B00137SPH4              8.71       4.10                 4.61\n9  A9Q28YTLYREO7  B00137QMFG              8.71       4.10                 4.61","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Item_ID</th>\n      <th>Predicted_Rating</th>\n      <th>Base_Mean</th>\n      <th>Predicted_Deviation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B0012CCO0E</td>\n      <td>13.50</td>\n      <td>4.10</td>\n      <td>9.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B0012FAUV6</td>\n      <td>9.93</td>\n      <td>4.10</td>\n      <td>5.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B000VWMTHE</td>\n      <td>9.93</td>\n      <td>4.10</td>\n      <td>5.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00136LQC6</td>\n      <td>9.62</td>\n      <td>4.10</td>\n      <td>5.52</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00123IAVK</td>\n      <td>9.18</td>\n      <td>4.10</td>\n      <td>5.08</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B0011Z1D8Q</td>\n      <td>9.06</td>\n      <td>4.10</td>\n      <td>4.96</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00123KDR4</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137GCI8</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137SPH4</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137QMFG</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport os\n\nWORK_DIR = '/kaggle/working/User_CF_Results_MeanCentered'\nTARGET_USER_ID = 'AAE2DUEMTR30I' # (Or the user active in your session)\n\nprint(f\"Calculating DF and DS (Mean-Centered) for: {TARGET_USER_ID}\")\n\nif 'top_20_mc_df' not in globals() or 'sparse_matrix' not in globals():\n    raise ValueError(\"Error: Neighbors dataframe or Sparse Matrix not found. Please run previous steps.\")\n\nif TARGET_USER_ID not in user_to_idx:\n    TARGET_USER_ID = list(user_to_idx.keys())[0]\n    print(f\"Switched to: {TARGET_USER_ID}\")\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\ntarget_vector = sparse_matrix[target_idx]\n\nnum_target_ratings = target_vector.getnnz()\n\nbeta = math.ceil(0.30 * num_target_ratings)\nbeta = max(1, beta)\n\nprint(f\"Target User Rated Items: {num_target_ratings}\")\nprint(f\"Threshold (Beta) @ 30%: {beta}\")\nprint(\"Counting common items...\")\n\nneighbor_ids = top_20_mc_df['User_ID'].values\nneighbor_indices = [user_to_idx[uid] for uid in neighbor_ids]\n\nneighbor_matrix = sparse_matrix[neighbor_indices]\n\ntarget_binary = target_vector.copy()\ntarget_binary.data[:] = 1\n\nneighbor_binary = neighbor_matrix.copy()\nneighbor_binary.data[:] = 1\ncommon_counts = target_binary.dot(neighbor_binary.T).toarray().flatten()\n\nds_df = top_20_mc_df.copy()\nds_df['Num_Common_Items'] = common_counts\n\nds_df['Discount_Factor'] = ds_df['Num_Common_Items'].apply(lambda x: min(x / beta, 1.0))\n\nds_df['Discounted_Similarity'] = ds_df['Adjusted_Score'] * ds_df['Discount_Factor']\n\n\nds_df = ds_df.sort_values(by='Discounted_Similarity', ascending=False)\n\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_MC_DS_Neighbors.csv')\nds_df.to_csv(output_file, index=False)\n\nprint(f\"\\nCalculation Complete. Saved to: {output_file}\")\n\nprint(\"\\nTop 10 Neighbors after Discounting (Mean-Centered):\")\ncols = ['User_ID', 'Num_Common_Items', 'Discount_Factor', 'Adjusted_Score', 'Discounted_Similarity']\ndisplay(ds_df[cols].head(10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:49:40.520480Z","iopub.execute_input":"2025-12-06T14:49:40.521088Z","iopub.status.idle":"2025-12-06T14:49:40.541939Z","shell.execute_reply.started":"2025-12-06T14:49:40.521061Z","shell.execute_reply":"2025-12-06T14:49:40.541275Z"}},"outputs":[{"name":"stdout","text":"Calculating DF and DS (Mean-Centered) for: AAE2DUEMTR30I\nSwitched to: A9Q28YTLYREO7\nTarget User Rated Items: 70\nThreshold (Beta) @ 30%: 21\nCounting common items...\n\nCalculation Complete. Saved to: /kaggle/working/User_CF_Results_MeanCentered/A9Q28YTLYREO7_MC_DS_Neighbors.csv\n\nTop 10 Neighbors after Discounting (Mean-Centered):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Num_Common_Items  Discount_Factor  Adjusted_Score  \\\n0      A9Q28YTLYREO7             70.00             1.00            1.00   \n7159  A1HCCW38EQQBTY             12.00             0.57            0.26   \n2183  A3HU0B9XUEVHIM             14.00             0.67            0.18   \n4206  A24N1BAS3CU27H             12.00             0.57            0.10   \n1516  A200C7YQJ45LRR              7.00             0.33            0.17   \n3257  A23FQRKY8W2MM4              7.00             0.33            0.15   \n5720  A17P4YJ8E81WNX              4.00             0.19            0.25   \n3254  A3PCTD8QM1BIXI              7.00             0.33            0.14   \n14     AD3C29MKDX7V2              8.00             0.38            0.12   \n3385   AE31M52VLKOG6             11.00             0.52            0.08   \n\n      Discounted_Similarity  \n0                      1.00  \n7159                   0.15  \n2183                   0.12  \n4206                   0.06  \n1516                   0.06  \n3257                   0.05  \n5720                   0.05  \n3254                   0.05  \n14                     0.04  \n3385                   0.04  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Num_Common_Items</th>\n      <th>Discount_Factor</th>\n      <th>Adjusted_Score</th>\n      <th>Discounted_Similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>70.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>7159</th>\n      <td>A1HCCW38EQQBTY</td>\n      <td>12.00</td>\n      <td>0.57</td>\n      <td>0.26</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>2183</th>\n      <td>A3HU0B9XUEVHIM</td>\n      <td>14.00</td>\n      <td>0.67</td>\n      <td>0.18</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>4206</th>\n      <td>A24N1BAS3CU27H</td>\n      <td>12.00</td>\n      <td>0.57</td>\n      <td>0.10</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>1516</th>\n      <td>A200C7YQJ45LRR</td>\n      <td>7.00</td>\n      <td>0.33</td>\n      <td>0.17</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>3257</th>\n      <td>A23FQRKY8W2MM4</td>\n      <td>7.00</td>\n      <td>0.33</td>\n      <td>0.15</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>5720</th>\n      <td>A17P4YJ8E81WNX</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.25</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>3254</th>\n      <td>A3PCTD8QM1BIXI</td>\n      <td>7.00</td>\n      <td>0.33</td>\n      <td>0.14</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>AD3C29MKDX7V2</td>\n      <td>8.00</td>\n      <td>0.38</td>\n      <td>0.12</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>AE31M52VLKOG6</td>\n      <td>11.00</td>\n      <td>0.52</td>\n      <td>0.08</td>\n      <td>0.04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"import pandas as pd\nimport math\nimport os\n\n# Setup\nWORK_DIR = '/kaggle/working/User_CF_Results_MeanCentered'\nTARGET_USER_ID = 'AAE2DUEMTR30I' # (Or the active user)\n\nprint(f\"Selecting Top 20% Neighbors based on DS (Mean-Centered) for: {TARGET_USER_ID}\")\n\n\nif 'ds_df' not in globals() or ds_df.empty:\n    print(\"Error: Discounted Similarity results not found. Please run the previous DF/DS calculation step.\")\nelse:\n   \n    valid_neighbors = ds_df[ds_df['Discounted_Similarity'] > 0].copy()\n    \n    \n    valid_neighbors = valid_neighbors.sort_values(by='Discounted_Similarity', ascending=False)\n    \n    total_valid = len(valid_neighbors)\n    \n    if total_valid == 0:\n        print(\"No neighbors with positive Discounted Similarity found.\")\n    else:\n        \n        top_k_count = math.ceil(total_valid * 0.20)\n        \n        print(f\"Total Valid Neighbors (Positive DS): {total_valid}\")\n        print(f\"Selecting Top 20%: {top_k_count} neighbors\")\n        \n       \n        mc_ds_top20_df = valid_neighbors.head(top_k_count)\n        \n       \n        output_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_MC_DS_Top20.csv')\n        mc_ds_top20_df.to_csv(output_file, index=False)\n        \n        print(f\"\\nSaved Mean-Centered DS Top 20% to: {output_file}\")\n        \n        \n        print(\"\\nFinal List of Top Neighbors (Ordered by DS):\")\n        cols = ['User_ID', 'Num_Common_Items', 'Discount_Factor', 'Adjusted_Score', 'Discounted_Similarity']\n        display(mc_ds_top20_df[cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:52:10.810658Z","iopub.execute_input":"2025-12-06T14:52:10.811383Z","iopub.status.idle":"2025-12-06T14:52:10.827355Z","shell.execute_reply.started":"2025-12-06T14:52:10.811355Z","shell.execute_reply":"2025-12-06T14:52:10.826568Z"}},"outputs":[{"name":"stdout","text":"Selecting Top 20% Neighbors based on DS (Mean-Centered) for: AAE2DUEMTR30I\nTotal Valid Neighbors (Positive DS): 130\nSelecting Top 20%: 26 neighbors\n\nSaved Mean-Centered DS Top 20% to: /kaggle/working/User_CF_Results_MeanCentered/AAE2DUEMTR30I_MC_DS_Top20.csv\n\nFinal List of Top Neighbors (Ordered by DS):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  Num_Common_Items  Discount_Factor  Adjusted_Score  \\\n0      A9Q28YTLYREO7             70.00             1.00            1.00   \n7159  A1HCCW38EQQBTY             12.00             0.57            0.26   \n2183  A3HU0B9XUEVHIM             14.00             0.67            0.18   \n4206  A24N1BAS3CU27H             12.00             0.57            0.10   \n1516  A200C7YQJ45LRR              7.00             0.33            0.17   \n3257  A23FQRKY8W2MM4              7.00             0.33            0.15   \n5720  A17P4YJ8E81WNX              4.00             0.19            0.25   \n3254  A3PCTD8QM1BIXI              7.00             0.33            0.14   \n14     AD3C29MKDX7V2              8.00             0.38            0.12   \n3385   AE31M52VLKOG6             11.00             0.52            0.08   \n2214  A3OLZXHFGUAMWW              4.00             0.19            0.22   \n5194  A23Y7ESOGEBSZT              4.00             0.19            0.21   \n39    A14GK0E64J0WAS              5.00             0.24            0.17   \n5204  A3BY2QW7T0401N              3.00             0.14            0.25   \n4198  A1IUSWIWF7087C              6.00             0.29            0.11   \n1515  A1HFVQZIDK7UUD              4.00             0.19            0.15   \n4202  A24EXRGZ24WZ22              5.00             0.24            0.12   \n2186  A3RC3AK8UN89I9              4.00             0.19            0.14   \n2185  A1FML9FCUPV6TI              4.00             0.19            0.13   \n5722  A3GS5WAQVO4CFB              2.00             0.10            0.26   \n36     AE9GUE3HHOX3U              4.00             0.19            0.13   \n138   A2A788AUOVBOL2              2.00             0.10            0.25   \n452   A1GN8UJIZLCA59              4.00             0.19            0.12   \n3525  A32XSKO7TOI0BH              2.00             0.10            0.24   \n4205   A70YTUFJY5HXN              2.00             0.10            0.23   \n2000   AHUT55E980RDR              2.00             0.10            0.20   \n\n      Discounted_Similarity  \n0                      1.00  \n7159                   0.15  \n2183                   0.12  \n4206                   0.06  \n1516                   0.06  \n3257                   0.05  \n5720                   0.05  \n3254                   0.05  \n14                     0.04  \n3385                   0.04  \n2214                   0.04  \n5194                   0.04  \n39                     0.04  \n5204                   0.04  \n4198                   0.03  \n1515                   0.03  \n4202                   0.03  \n2186                   0.03  \n2185                   0.03  \n5722                   0.02  \n36                     0.02  \n138                    0.02  \n452                    0.02  \n3525                   0.02  \n4205                   0.02  \n2000                   0.02  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>Num_Common_Items</th>\n      <th>Discount_Factor</th>\n      <th>Adjusted_Score</th>\n      <th>Discounted_Similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>70.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>7159</th>\n      <td>A1HCCW38EQQBTY</td>\n      <td>12.00</td>\n      <td>0.57</td>\n      <td>0.26</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>2183</th>\n      <td>A3HU0B9XUEVHIM</td>\n      <td>14.00</td>\n      <td>0.67</td>\n      <td>0.18</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>4206</th>\n      <td>A24N1BAS3CU27H</td>\n      <td>12.00</td>\n      <td>0.57</td>\n      <td>0.10</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>1516</th>\n      <td>A200C7YQJ45LRR</td>\n      <td>7.00</td>\n      <td>0.33</td>\n      <td>0.17</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>3257</th>\n      <td>A23FQRKY8W2MM4</td>\n      <td>7.00</td>\n      <td>0.33</td>\n      <td>0.15</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>5720</th>\n      <td>A17P4YJ8E81WNX</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.25</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>3254</th>\n      <td>A3PCTD8QM1BIXI</td>\n      <td>7.00</td>\n      <td>0.33</td>\n      <td>0.14</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>AD3C29MKDX7V2</td>\n      <td>8.00</td>\n      <td>0.38</td>\n      <td>0.12</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>3385</th>\n      <td>AE31M52VLKOG6</td>\n      <td>11.00</td>\n      <td>0.52</td>\n      <td>0.08</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>2214</th>\n      <td>A3OLZXHFGUAMWW</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.22</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>5194</th>\n      <td>A23Y7ESOGEBSZT</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.21</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>A14GK0E64J0WAS</td>\n      <td>5.00</td>\n      <td>0.24</td>\n      <td>0.17</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>5204</th>\n      <td>A3BY2QW7T0401N</td>\n      <td>3.00</td>\n      <td>0.14</td>\n      <td>0.25</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>4198</th>\n      <td>A1IUSWIWF7087C</td>\n      <td>6.00</td>\n      <td>0.29</td>\n      <td>0.11</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>1515</th>\n      <td>A1HFVQZIDK7UUD</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.15</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>4202</th>\n      <td>A24EXRGZ24WZ22</td>\n      <td>5.00</td>\n      <td>0.24</td>\n      <td>0.12</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>2186</th>\n      <td>A3RC3AK8UN89I9</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.14</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>2185</th>\n      <td>A1FML9FCUPV6TI</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.13</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>5722</th>\n      <td>A3GS5WAQVO4CFB</td>\n      <td>2.00</td>\n      <td>0.10</td>\n      <td>0.26</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>AE9GUE3HHOX3U</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.13</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>A2A788AUOVBOL2</td>\n      <td>2.00</td>\n      <td>0.10</td>\n      <td>0.25</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>452</th>\n      <td>A1GN8UJIZLCA59</td>\n      <td>4.00</td>\n      <td>0.19</td>\n      <td>0.12</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>3525</th>\n      <td>A32XSKO7TOI0BH</td>\n      <td>2.00</td>\n      <td>0.10</td>\n      <td>0.24</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>4205</th>\n      <td>A70YTUFJY5HXN</td>\n      <td>2.00</td>\n      <td>0.10</td>\n      <td>0.23</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>2000</th>\n      <td>AHUT55E980RDR</td>\n      <td>2.00</td>\n      <td>0.10</td>\n      <td>0.20</td>\n      <td>0.02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"\nWORK_DIR = '/kaggle/working/User_CF_Results_MeanCentered'\nTARGET_USER_ID = 'AAE2DUEMTR30I' \n\nprint(f\"Predicting Ratings using Discounted Mean-Centered Similarity for: {TARGET_USER_ID}\")\n\nif 'mc_ds_top20_df' not in globals() or 'matrix_centered' not in globals() or 'user_means' not in globals():\n    raise ValueError(\"Error: Missing data. Please run Steps 1 and 5 first.\")\n\nif TARGET_USER_ID not in user_to_idx:\n    TARGET_USER_ID = list(user_to_idx.keys())[0]\n    print(f\"Switched to: {TARGET_USER_ID}\")\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\ntarget_mean = user_means[target_idx]\n\nprint(f\"Target User Mean Rating: {target_mean:.4f}\")\nprint(f\"Using {len(mc_ds_top20_df)} DS-weighted neighbors...\")\n\nneighbor_ids = mc_ds_top20_df['User_ID'].values\nneighbor_weights = mc_ds_top20_df['Discounted_Similarity'].values\n\nneighbor_indices = [user_to_idx[uid] for uid in neighbor_ids]\n\nneighbor_matrix_centered = matrix_centered[neighbor_indices]\n\n\nnumerator = neighbor_matrix_centered.T.dot(neighbor_weights)\n\nbinary_matrix = neighbor_matrix_centered.copy()\nbinary_matrix.data[:] = 1\ndenominator = binary_matrix.T.dot(np.abs(neighbor_weights))\n\n\npred_deviation = np.zeros(matrix_centered.shape[1])\nmask = denominator > 0\npred_deviation[mask] = numerator[mask] / denominator[mask]\n\n# Final Prediction = Target Mean + Deviation\nfinal_predictions = pred_deviation + target_mean\n\n\n\nif 'sparse_matrix' in globals():\n    items_rated = sparse_matrix[target_idx].indices\n    final_predictions[items_rated] = 0\n\n\ntop_indices = final_predictions.argsort()[::-1][:50]\n\nrecs_list = []\nfor idx in top_indices:\n    score = final_predictions[idx]\n    if score > 0.001: # Filter out zeros/negatives\n        recs_list.append({\n            'Target_User': TARGET_USER_ID,\n            'Item_ID': idx_to_item[idx],\n            'Predicted_Rating': round(score, 4),\n            'Base_Mean': round(target_mean, 2),\n            'Predicted_Deviation': round(pred_deviation[idx], 4)\n        })\n\nrecs_df = pd.DataFrame(recs_list)\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_MC_DS_Predictions.csv')\nrecs_df.to_csv(output_file, index=False)\n\nprint(f\"\\nPrediction Complete. Results saved to: {output_file}\")\n\nif not recs_df.empty:\n    print(\"\\nTop 10 Recommendations (Mean-Centered + Discounted):\")\n    display(recs_df.head(10))\nelse:\n    print(\"No recommendations found (Neighbors might not have sufficient overlap or ratings).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T14:56:15.427366Z","iopub.execute_input":"2025-12-06T14:56:15.428100Z","iopub.status.idle":"2025-12-06T14:56:15.447447Z","shell.execute_reply.started":"2025-12-06T14:56:15.428070Z","shell.execute_reply":"2025-12-06T14:56:15.446912Z"}},"outputs":[{"name":"stdout","text":"Predicting Ratings using Discounted Mean-Centered Similarity for: AAE2DUEMTR30I\nSwitched to: A9Q28YTLYREO7\nTarget User Mean Rating: 4.1000\nUsing 26 DS-weighted neighbors...\n\nPrediction Complete. Results saved to: /kaggle/working/User_CF_Results_MeanCentered/A9Q28YTLYREO7_MC_DS_Predictions.csv\n\nTop 10 Recommendations (Mean-Centered + Discounted):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     Target_User     Item_ID  Predicted_Rating  Base_Mean  Predicted_Deviation\n0  A9Q28YTLYREO7  B00123IAVK              9.18       4.10                 5.08\n1  A9Q28YTLYREO7  B000WKT6B2              8.95       4.10                 4.85\n2  A9Q28YTLYREO7  B0013DC9TS              8.71       4.10                 4.61\n3  A9Q28YTLYREO7  B00137SPH4              8.71       4.10                 4.61\n4  A9Q28YTLYREO7  B00137QMFG              8.71       4.10                 4.61\n5  A9Q28YTLYREO7  B00137GCI8              8.71       4.10                 4.61\n6  A9Q28YTLYREO7  B00123KDR4              8.71       4.10                 4.61\n7  A9Q28YTLYREO7  B00137GCGK              8.71       4.10                 4.61\n8  A9Q28YTLYREO7  B00136JL8W              8.71       4.10                 4.61\n9  A9Q28YTLYREO7  B000W20FY2              8.26       4.10                 4.16","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Item_ID</th>\n      <th>Predicted_Rating</th>\n      <th>Base_Mean</th>\n      <th>Predicted_Deviation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00123IAVK</td>\n      <td>9.18</td>\n      <td>4.10</td>\n      <td>5.08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B000WKT6B2</td>\n      <td>8.95</td>\n      <td>4.10</td>\n      <td>4.85</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B0013DC9TS</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137SPH4</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137QMFG</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137GCI8</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00123KDR4</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137GCGK</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00136JL8W</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B000W20FY2</td>\n      <td>8.26</td>\n      <td>4.10</td>\n      <td>4.16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":59},{"cell_type":"markdown","source":"# Case Study 3","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport os\n\nWORK_DIR = '/kaggle/working/User_CF_Results_Pearson'\nos.makedirs(WORK_DIR, exist_ok=True)\n\nTARGET_USER_ID = 'AAE2DUEMTR30I'\n\nprint(f\"Case Study 3: Computing Pearson Correlation (PCC) for {TARGET_USER_ID}\")\nif 'sparse_matrix' not in globals() or 'user_to_idx' not in globals():\n    raise ValueError(\"Error: Sparse Matrix or Mappings not found. Please run the Iterative Filtering step.\")\n\nif TARGET_USER_ID not in user_to_idx:\n    TARGET_USER_ID = list(user_to_idx.keys())[0]\n    print(f\"Switched to: {TARGET_USER_ID}\")\n\nprint(\"\\n[1/3] Calculating User Means and Centering Data...\")\n\nuser_sums = sparse_matrix.sum(axis=1).A1\nuser_counts = sparse_matrix.getnnz(axis=1)\n\nuser_means = np.zeros(len(user_ids))\nvalid_mask = user_counts > 0\nuser_means[valid_mask] = user_sums[valid_mask] / user_counts[valid_mask]\n\nmatrix_pearson = sparse_matrix.copy().astype(float)\nrows, cols = matrix_pearson.nonzero()\n\nmatrix_pearson.data -= np.take(user_means, rows)\n\nprint(f\"Matrix Centered. Target User Mean: {user_means[user_to_idx[TARGET_USER_ID]]:.4f}\")\n\nprint(\"\\n[2/3] Computing Pearson Coefficients...\")\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\ntarget_vec_pearson = matrix_pearson[target_idx]\n\npcc_scores = cosine_similarity(target_vec_pearson, matrix_pearson).flatten()\n\nprint(\"\\n[3/3] Saving Results...\")\n\npcc_df = pd.DataFrame({\n    'User_ID': list(user_to_idx.keys()),\n    'PCC_Score': pcc_scores\n})\n\n\npcc_df = pcc_df[pcc_df['User_ID'] != TARGET_USER_ID]\n\n\npcc_df = pcc_df.sort_values(by='PCC_Score', ascending=False)\n\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_PCC_Neighbors.csv')\npcc_df.to_csv(output_file, index=False)\n\nprint(f\"Done. Saved to: {output_file}\")\n\nprint(\"\\nTop 10 Neighbors by Pearson Correlation:\")\ndisplay(pcc_df.head(10))\n\nprint(\"\\nBottom 10 Neighbors (Negative Correlation / Opposite Taste):\")\ndisplay(pcc_df.tail(","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:41:04.768205Z","iopub.execute_input":"2025-12-06T15:41:04.768890Z","iopub.status.idle":"2025-12-06T15:41:04.811234Z","shell.execute_reply.started":"2025-12-06T15:41:04.768864Z","shell.execute_reply":"2025-12-06T15:41:04.810642Z"}},"outputs":[{"name":"stdout","text":"Case Study 3: Computing Pearson Correlation (PCC) for AAE2DUEMTR30I\nSwitched to: A9Q28YTLYREO7\n\n[1/3] Calculating User Means and Centering Data...\nMatrix Centered. Target User Mean: 4.1000\n\n[2/3] Computing Pearson Coefficients...\n\n[3/3] Saving Results...\nDone. Saved to: /kaggle/working/User_CF_Results_Pearson/A9Q28YTLYREO7_PCC_Neighbors.csv\n\nTop 10 Neighbors by Pearson Correlation:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  PCC_Score\n7159  A1HCCW38EQQBTY       0.26\n5722  A3GS5WAQVO4CFB       0.26\n138   A2A788AUOVBOL2       0.25\n5720  A17P4YJ8E81WNX       0.25\n1131  A22WY238ZYNOS1       0.25\n6496  A3J8SZL4IN1D46       0.25\n6500  A1OKLAQJVFREOQ       0.25\n5204  A3BY2QW7T0401N       0.25\n3525  A32XSKO7TOI0BH       0.24\n5723  A3D2VIUT2HWP0Z       0.24","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>PCC_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7159</th>\n      <td>A1HCCW38EQQBTY</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>5722</th>\n      <td>A3GS5WAQVO4CFB</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>A2A788AUOVBOL2</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>5720</th>\n      <td>A17P4YJ8E81WNX</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>1131</th>\n      <td>A22WY238ZYNOS1</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>6496</th>\n      <td>A3J8SZL4IN1D46</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>6500</th>\n      <td>A1OKLAQJVFREOQ</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>5204</th>\n      <td>A3BY2QW7T0401N</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3525</th>\n      <td>A32XSKO7TOI0BH</td>\n      <td>0.24</td>\n    </tr>\n    <tr>\n      <th>5723</th>\n      <td>A3D2VIUT2HWP0Z</td>\n      <td>0.24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nBottom 10 Neighbors (Negative Correlation / Opposite Taste):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  PCC_Score\n13    A20ZVK7L91JS7L      -0.10\n30    A2IJ7JFHB94EKX      -0.13\n42    A2LNEZD3YBO12O      -0.13\n2193  A1O90V9J864L7N      -0.13\n4651  A3V5GY711ZL680      -0.13\n4605  A3I1L5E4LEZ9RV      -0.14\n22    A2A6LKO4CC39S0      -0.16\n3524  A16X18QH3TK8GV      -0.17\n3591  A1XCQVVMDL4KT8      -0.22\n38    A2OAKHL0E0A4YQ      -0.22","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>PCC_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>A20ZVK7L91JS7L</td>\n      <td>-0.10</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>A2IJ7JFHB94EKX</td>\n      <td>-0.13</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>A2LNEZD3YBO12O</td>\n      <td>-0.13</td>\n    </tr>\n    <tr>\n      <th>2193</th>\n      <td>A1O90V9J864L7N</td>\n      <td>-0.13</td>\n    </tr>\n    <tr>\n      <th>4651</th>\n      <td>A3V5GY711ZL680</td>\n      <td>-0.13</td>\n    </tr>\n    <tr>\n      <th>4605</th>\n      <td>A3I1L5E4LEZ9RV</td>\n      <td>-0.14</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>A2A6LKO4CC39S0</td>\n      <td>-0.16</td>\n    </tr>\n    <tr>\n      <th>3524</th>\n      <td>A16X18QH3TK8GV</td>\n      <td>-0.17</td>\n    </tr>\n    <tr>\n      <th>3591</th>\n      <td>A1XCQVVMDL4KT8</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>A2OAKHL0E0A4YQ</td>\n      <td>-0.22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"import pandas as pd\nimport math\nimport os\n\n# Setup\nWORK_DIR = '/kaggle/working/User_CF_Results_Pearson'\nTARGET_USER_ID = 'AAE2DUEMTR30I' # (Or the active user from previous steps)\n\nprint(f\"2. Identifying Top 20% Neighbors (Pearson) for: {TARGET_USER_ID}\")\n\n# ---------------------------------------------------------\n# 1. Load/Check Data\n# ---------------------------------------------------------\nif 'pcc_df' not in globals():\n    try:\n        # Attempt to load from file if variable is missing\n        file_path = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_PCC_Neighbors.csv')\n        pcc_df = pd.read_csv(file_path)\n    except:\n        raise ValueError(\"Error: PCC data not found. Please run the PCC calculation step first.\")\n\npositive_neighbors = positive_neighbors.sort_values(by='PCC_Score', ascending=False)\n\ntotal_valid = len(positive_neighbors)\n\nif total_valid == 0:\n    print(\"No neighbors with positive Pearson correlation found.\")\nelse:\n\n    top_k_count = math.ceil(total_valid * 0.20)\n    \n    print(f\"Total Neighbors with Positive Correlation: {total_valid}\")\n    print(f\"Selecting Top 20%: {top_k_count} neighbors\")\n    \n\n    top_20_pcc_df = positive_neighbors.head(top_k_count)\n    \n    output_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_PCC_Top20_Neighbors.csv')\n    top_20_pcc_df.to_csv(output_file, index=False)\n    \n    print(f\"\\nSaved Top 20% Pearson Neighbors to: {output_file}\")\n    \n    \n    print(\"\\nTop 10 Closest Users (Pearson Correlation):\")\n    display(top_20_pcc_df.head(","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:45:08.525895Z","iopub.execute_input":"2025-12-06T15:45:08.526579Z","iopub.status.idle":"2025-12-06T15:45:08.540187Z","shell.execute_reply.started":"2025-12-06T15:45:08.526555Z","shell.execute_reply":"2025-12-06T15:45:08.539275Z"}},"outputs":[{"name":"stdout","text":"2. Identifying Top 20% Neighbors (Pearson) for: AAE2DUEMTR30I\nTotal Neighbors with Positive Correlation: 648\nSelecting Top 20%: 130 neighbors\n\nSaved Top 20% Pearson Neighbors to: /kaggle/working/User_CF_Results_Pearson/AAE2DUEMTR30I_PCC_Top20_Neighbors.csv\n\nTop 10 Closest Users (Pearson Correlation):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"             User_ID  PCC_Score\n7159  A1HCCW38EQQBTY       0.26\n5722  A3GS5WAQVO4CFB       0.26\n138   A2A788AUOVBOL2       0.25\n5720  A17P4YJ8E81WNX       0.25\n1131  A22WY238ZYNOS1       0.25\n6496  A3J8SZL4IN1D46       0.25\n6500  A1OKLAQJVFREOQ       0.25\n5204  A3BY2QW7T0401N       0.25\n3525  A32XSKO7TOI0BH       0.24\n5723  A3D2VIUT2HWP0Z       0.24","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User_ID</th>\n      <th>PCC_Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7159</th>\n      <td>A1HCCW38EQQBTY</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>5722</th>\n      <td>A3GS5WAQVO4CFB</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>A2A788AUOVBOL2</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>5720</th>\n      <td>A17P4YJ8E81WNX</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>1131</th>\n      <td>A22WY238ZYNOS1</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>6496</th>\n      <td>A3J8SZL4IN1D46</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>6500</th>\n      <td>A1OKLAQJVFREOQ</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>5204</th>\n      <td>A3BY2QW7T0401N</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3525</th>\n      <td>A32XSKO7TOI0BH</td>\n      <td>0.24</td>\n    </tr>\n    <tr>\n      <th>5723</th>\n      <td>A3D2VIUT2HWP0Z</td>\n      <td>0.24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\n\nWORK_DIR = '/kaggle/working/User_CF_Results_Pearson'\nTARGET_USER_ID = 'AAE2DUEMTR30I'\n\nprint(f\"3. Predicting Ratings (Pearson Method) for: {TARGET_USER_ID}\")\n\n\n\nif 'top_20_pcc_df' not in globals() or 'matrix_pearson' not in globals() or 'user_means' not in globals():\n    raise ValueError(\"Error: Missing data (Neighbors, Pearson Matrix, or User Means). Please run previous steps.\")\n\n\nif TARGET_USER_ID not in user_to_idx:\n    TARGET_USER_ID = list(user_to_idx.keys())[0]\n    print(f\"Switched to: {TARGET_USER_ID}\")\n\n\ntarget_idx = user_to_idx[TARGET_USER_ID]\ntarget_mean = user_means[target_idx]\n\nprint(f\"Target User Baseline Average: {target_mean:.4f}\")\nprint(f\"Using {len(top_20_pcc_df)} neighbors...\")\n\n\nneighbor_ids = top_20_pcc_df['User_ID'].values\nneighbor_weights = top_20_pcc_df['PCC_Score'].values\n\n\nneighbor_indices = [user_to_idx[uid] for uid in neighbor_ids]\n\n\nneighbor_deviations_matrix = matrix_pearson[neighbor_indices]\n\n\n\nnumerator = neighbor_deviations_matrix.T.dot(neighbor_weights)\n\n\nbinary_matrix = neighbor_deviations_matrix.copy()\n\nbinary_matrix.data[:] = 1 \n\ndenominator = binary_matrix.T.dot(np.abs(neighbor_weights))\n\n\npred_deviation = np.zeros(matrix_pearson.shape[1])\nmask = denominator > 0\npred_deviation[mask] = numerator[mask] / denominator[mask]\n\n\n\nfinal_predictions = pred_deviation + target_mean\n\n\nif 'sparse_matrix' in globals():\n    items_rated = sparse_matrix[target_idx].indices\n    final_predictions[items_rated] = 0\n\n\ntop_indices = final_predictions.argsort()[::-1][:50]\n\nrecs_list = []\nfor idx in top_indices:\n    score = final_predictions[idx]\n    \n    if score > 0.001: \n        recs_list.append({\n            'Target_User': TARGET_USER_ID,\n            'Item_ID': idx_to_item[idx],\n            'PCC_Rating': round(score, 4),\n            'Baseline': round(target_mean, 2),\n            'Predicted_Lift': round(pred_deviation[idx], 4)\n        })\n\nrecs_df = pd.DataFrame(recs_list)\n\n\noutput_file = os.path.join(WORK_DIR, f'{TARGET_USER_ID}_PCC_Predictions.csv')\nrecs_df.to_csv(output_file, index=False)\n\nprint(f\"\\nPrediction Complete. Saved to: {output_file}\")\n\nif not recs_df.empty:\n    print(\"\\nTop 10 Recommendations (Pearson):\")\n    display(recs_df.head(10))\nelse:\n    print(\"No recommendations generated (Neighbors might not have shared enough unrated items).\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T15:46:40.615458Z","iopub.execute_input":"2025-12-06T15:46:40.616056Z","iopub.status.idle":"2025-12-06T15:46:40.636168Z","shell.execute_reply.started":"2025-12-06T15:46:40.616030Z","shell.execute_reply":"2025-12-06T15:46:40.635388Z"}},"outputs":[{"name":"stdout","text":"3. Predicting Ratings (Pearson Method) for: AAE2DUEMTR30I\nSwitched to: A9Q28YTLYREO7\nTarget User Baseline Average: 4.1000\nUsing 130 neighbors...\n\nPrediction Complete. Saved to: /kaggle/working/User_CF_Results_Pearson/A9Q28YTLYREO7_PCC_Predictions.csv\n\nTop 10 Recommendations (Pearson):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     Target_User     Item_ID  PCC_Rating  Baseline  Predicted_Lift\n0  A9Q28YTLYREO7  B0012CCO0E       13.50      4.10            9.40\n1  A9Q28YTLYREO7  B0012FAUV6        9.93      4.10            5.83\n2  A9Q28YTLYREO7  B000VWMTHE        9.93      4.10            5.83\n3  A9Q28YTLYREO7  B00136LQC6        9.62      4.10            5.52\n4  A9Q28YTLYREO7  B00123IAVK        9.18      4.10            5.08\n5  A9Q28YTLYREO7  B0011Z1D8Q        9.06      4.10            4.96\n6  A9Q28YTLYREO7  B00123KDR4        8.71      4.10            4.61\n7  A9Q28YTLYREO7  B00137GCI8        8.71      4.10            4.61\n8  A9Q28YTLYREO7  B00137SPH4        8.71      4.10            4.61\n9  A9Q28YTLYREO7  B00137QMFG        8.71      4.10            4.61","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target_User</th>\n      <th>Item_ID</th>\n      <th>PCC_Rating</th>\n      <th>Baseline</th>\n      <th>Predicted_Lift</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B0012CCO0E</td>\n      <td>13.50</td>\n      <td>4.10</td>\n      <td>9.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B0012FAUV6</td>\n      <td>9.93</td>\n      <td>4.10</td>\n      <td>5.83</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B000VWMTHE</td>\n      <td>9.93</td>\n      <td>4.10</td>\n      <td>5.83</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00136LQC6</td>\n      <td>9.62</td>\n      <td>4.10</td>\n      <td>5.52</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00123IAVK</td>\n      <td>9.18</td>\n      <td>4.10</td>\n      <td>5.08</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B0011Z1D8Q</td>\n      <td>9.06</td>\n      <td>4.10</td>\n      <td>4.96</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00123KDR4</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137GCI8</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137SPH4</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>A9Q28YTLYREO7</td>\n      <td>B00137QMFG</td>\n      <td>8.71</td>\n      <td>4.10</td>\n      <td>4.61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":64}]}