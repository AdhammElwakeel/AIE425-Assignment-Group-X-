================================================================================
               PART 2: ITEM-BASED COLLABORATIVE FILTERING REPORT
                         Amazon Digital Music Dataset
================================================================================

Author: Adham Mohmed elsaid elwakel
Student ID: 222 100 195

================================================================================
                            1. OVERVIEW
================================================================================

This report presents the implementation and results of Item-Based Collaborative
Filtering (CF) on the Amazon Digital Music dataset following the required
case studies:

• Case Study 1: Cosine Similarity WITH Mean-Centering (Tasks 1-9)
• Case Study 3: Pearson Correlation Coefficient with β threshold (Tasks 1-9)

================================================================================
                         2. DATASET SUMMARY
================================================================================

Dataset: Amazon Digital Music Reviews
┌─────────────────────┬────────────────┐
│ Metric              │ Value          │
├─────────────────────┼────────────────┤
│ Number of Users     │ 840,372        │
│ Number of Items     │ 456,992        │
│ Total Ratings       │ 1,584,082      │
│ Rating Scale        │ 1.0 - 5.0      │
│ Sparsity            │ 99.9996%       │
└─────────────────────┴────────────────┘

================================================================================
                      3. TARGET ITEM SELECTION
================================================================================

Target items selected based on:
• Average rating ≤ 3.0 (lowest rated items)
• Number of ratings ≥ 50 (sufficient data)

Items meeting criteria: 15 (out of 456,992)

┌────────┬──────────────┬────────────────┬─────────────┐
│ Target │ Item ID      │ Average Rating │ Num Ratings │
├────────┼──────────────┼────────────────┼─────────────┤
│ I1     │ B00S33PD6W   │ 1.00           │ 73          │
│ I2     │ B00DO4LN82   │ 1.02           │ 64          │
└────────┴──────────────┴────────────────┴─────────────┘

================================================================================
               CASE STUDY 1: COSINE SIMILARITY WITH MEAN-CENTERING
================================================================================

--------------------------------------------------------------------------------
TASK 1: Apply Item-Based CF using Cosine Similarity with Mean-Centering
--------------------------------------------------------------------------------
• Method: Cosine similarity computed on mean-centered ratings
• Mean-centering: r'_ui = r_ui - r̄_i
• Results:
  - I1: 4 similar items found (73 raters)
  - I2: 3 similar items found (62 raters)

--------------------------------------------------------------------------------
TASK 2: Identify Top 20% of Similar Items
--------------------------------------------------------------------------------
• I1: 1 item selected (20% of 4)
• I2: 1 item selected (20% of 3)

--------------------------------------------------------------------------------
TASK 3: Predict Missing Ratings
--------------------------------------------------------------------------------
• I1: Mean prediction = 1.00
• I2: Mean prediction = 1.84

--------------------------------------------------------------------------------
TASK 4: Compute DF (Decision Function) and DS (Decision Score)
--------------------------------------------------------------------------------
• DF = Similarity score
• DS = Similarity × Average Rating
• Results computed for all similar items

--------------------------------------------------------------------------------
TASK 5: Select Top 20% Items Using DS
--------------------------------------------------------------------------------
• I1: 1 item selected
• I2: 1 item selected

--------------------------------------------------------------------------------
TASK 6: Use DS-Selected Items for Updated Predictions
--------------------------------------------------------------------------------
• I1: Mean prediction = 1.00
• I2: Mean prediction = 1.84

--------------------------------------------------------------------------------
TASK 7: Compare Similarity Lists (Steps 2 and 5)
--------------------------------------------------------------------------------
• I1: 100% overlap (1/1 items identical)
• I2: 100% overlap (1/1 items identical)

ANALYSIS: With limited neighbors, both selection methods yield identical items.

--------------------------------------------------------------------------------
TASK 8: Compare Predicted Ratings (Steps 3 and 6)
--------------------------------------------------------------------------------
• I1: Difference = 0.000 (identical)
• I2: Difference = 0.000 (identical)

ANALYSIS: Identical neighbor selections result in identical predictions.

--------------------------------------------------------------------------------
TASK 9: Comments and Conclusions (Case Study 1)
--------------------------------------------------------------------------------
• Cosine similarity with mean-centering effectively anchors predictions
  to the target item's mean rating
• For low-rated items (avg=1.0), predictions correctly stay low (~1.0-1.8)
• Limited neighbors due to extreme dataset sparsity (99.9996%)

================================================================================
               CASE STUDY 3: PEARSON CORRELATION COEFFICIENT (PCC)
================================================================================

--------------------------------------------------------------------------------
TASK 1: Compute PCC Similarity Between Target Items
--------------------------------------------------------------------------------
• PCC requires minimum 2 common users
• Results:
  - I1: 3 similar items found
  - I2: 2 similar items found

--------------------------------------------------------------------------------
TASK 2: Identify Top 20% Most Similar Items
--------------------------------------------------------------------------------
• I1: 1 item selected
• I2: 1 item selected

--------------------------------------------------------------------------------
TASK 3: Predict Missing Ratings
--------------------------------------------------------------------------------
• I1: Mean prediction = 1.00
• I2: Mean prediction = 1.84

--------------------------------------------------------------------------------
TASK 4: Compute DF and DS Using Threshold β
--------------------------------------------------------------------------------
• β threshold = 5 (minimum common users)
• After filtering:
  - I1: Items meeting β threshold
  - I2: Items meeting β threshold
• DS = PCC × Average Rating

--------------------------------------------------------------------------------
TASK 5: Select Top 20% Items Based on DS (Discounted Similarity)
--------------------------------------------------------------------------------
• I1: 1 item selected by DS
• I2: 1 item selected by DS

--------------------------------------------------------------------------------
TASK 6: Predict Ratings with DS-Selected Items
--------------------------------------------------------------------------------
• I1: Mean prediction (DS-based)
• I2: Mean prediction (DS-based)

--------------------------------------------------------------------------------
TASK 7: Compare Item Lists (Steps 2 and 5)
--------------------------------------------------------------------------------
• I1: Comparison of PCC vs DS selections
• I2: Comparison of PCC vs DS selections

ANALYSIS: With limited items passing β threshold, selections tend to overlap.

--------------------------------------------------------------------------------
TASK 8: Compare Predictions (Steps 3 and 6)
--------------------------------------------------------------------------------
• Predictions compared between PCC-based and DS-based selections
• Due to limited neighbors, differences are minimal

INSIGHTS:
• Limited neighbor pool constrains differentiation between methods
• β threshold adds reliability but reduces available neighbors
• True impact of DS would emerge with larger neighbor sets

--------------------------------------------------------------------------------
TASK 9: Comments and Conclusions (Case Study 3)
--------------------------------------------------------------------------------
• PCC is mathematically equivalent to centered cosine similarity
• β threshold provides reliability filtering but reduces neighbors
• For sparse datasets, PCC and Cosine+MC produce similar results

================================================================================
               FINAL TASK: COMPREHENSIVE COMPARISON
================================================================================

SIMILARITY MEASURES COMPARISON:
┌─────────────────────┬────────────────────┬────────────────────┐
│ Metric              │ CS1 (Cosine+MC)    │ CS3 (PCC)          │
├─────────────────────┼────────────────────┼────────────────────┤
│ I1 Similar Items    │ 4                  │ 3                  │
│ I2 Similar Items    │ 3                  │ 2                  │
│ Min Common Users    │ 1                  │ 2                  │
│ I1 Prediction       │ 1.00               │ 1.00               │
│ I2 Prediction       │ 1.84               │ 1.84               │
└─────────────────────┴────────────────────┴────────────────────┘

KEY FINDINGS:

1. SIMILARITY MEASURES:
   • Both methods produce SIMILAR predictions for low-rated items
   • PCC is more conservative (requires 2+ common users)
   • Cosine+MC finds more neighbors but some may be less reliable

2. IMPACT OF MEAN-CENTERING:
   • Essential for accurate predictions on low-rated items
   • Anchors predictions to target item's actual quality
   • Without it, predictions could be unrealistically high

3. DS vs RAW SIMILARITY:
   • In sparse datasets, both methods often select same items
   • DS becomes valuable with larger neighbor pools
   • DS = Similarity × Avg Rating favors quality items

4. DATASET SPARSITY IMPACT:
   • 99.9996% sparsity severely limits neighbor discovery
   • Only 3-4 similar items per target
   • True method comparison requires denser data

RECOMMENDATIONS:
• Use mean-centering for accurate CF predictions
• Apply β threshold for reliable similarities
• Consider matrix factorization for sparse datasets
• Hybrid approaches may be necessary

================================================================================
                           END OF REPORT
================================================================================

Files:
• Notebook: part2_item_based_cf.ipynb (53 cells)
• Report: report_part2_item_based_cf.txt

================================================================================
